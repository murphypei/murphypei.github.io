---
title: 图像生成基础-DDPM
date: 2024-07-31 17:44:51
update: 2024-07-31 17:44:51
categories: AIGC
tags: [AIGC, DDPM, 图像生成]
mathjax: true
---

目前所采用的扩散模型大都是来自于2020年的工作DDPM。DDPM对之前的扩散模型进行了简化，并通过变分推断（variational inference）来进行建模，这主要是因为扩散模型也是一个隐变量模型（latent variable model），相比VAE这样的隐变量模型，扩散模型的隐变量是和原始数据是同维度的，而且推理过程（即扩散过程）往往是固定的。

<!-- more -->

扩散模型包括两个过程：前向过程（forward process）和反向过程（reverse process），其中前向过程又称为扩散过程（diffusion process），如下图所示。无论是前向过程还是反向过程都是一个参数化的马尔可夫链（Markov chain），其中反向过程可以用来生成数据，这里我们将通过变分推断来进行建模和求解。

![](/images/posts/aigc/ddpm/1.webp)

### 前向扩散过程 (Forward Diffusion Process)

解释扩散之前先介绍一个基本的数学表示：

$$
\mathcal{N}(x_t; \mu, \Sigma)
$$

一个正态分布，其中$\mu$是均值，$\Sigma$是协方差矩阵。在这个过程中，$x_t$服从一个$\mu$为均值、$\Sigma$为协方差矩阵的正态分布。

扩散就是对图像数据进行加噪声的过程，**最核心的数学公式**表示如下：

$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})
$$

$x_0$是原始数据，$x_t$是在$t$时刻的样本，$\mathcal{N}$表示正态分布，$\beta_t$表示在第$t$步的方差（噪音量），它是一个介于0和1之间的值，$\sqrt{1 - \beta_t}$表示输入数据的缩放系数，$\beta_t \mathbf{I}$表示加的噪音的方差。

这个公式表示，给定$x_{t-1}$的情况下，$x_t$是以$\sqrt{1 - \beta_t} x_{t-1}$为均值、$\beta_t \mathbf{I}$为协方差矩阵的正态分布。可以简单理解为，$x_t$是$x_{t-1}$加上高斯噪音后的结果。

前向过程就是这么简单。当我们逐渐加大$\beta_t$时，$x_t$逐渐变得模糊，最终变成一个高斯噪声图像。

$$
q(x_T|x_0) \approx \mathcal{N}(0, I)
$$

这里也有一个推导，就是通过 $x_0$，可以直接表示$x_T$，因为高斯分布可以直接相加。

### 逆向生成过程 (Reverse Generation Process) 

训练过程中，DDPM 学习从噪声生成数据的逆向过程。我们**假设逆向过程也是一个高斯过程**，但参数未知：

$$
p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \sigma_\theta^2(x_t, t) I)
$$

这里，模型的任务是学习 $\mu_\theta$ 和 $\sigma_\theta$ 的参数化形式，使得可以从噪声生成逼真的数据样本。

### 训练目标

训练的目标是最小化前向过程和逆向过程之间的差异。具体来说，训练目标可以表示为以下KL散度的和：

$$
L = \sum_{t=1}^{T} D_{KL}\left(q(x_{t-1}|x_t, x_0) \| p_\theta(x_{t-1}|x_t)\right)
$$

每一个KL项衡量在第$t$个时间步长上真实分布和模型估计分布之间的差异。

### 损失函数

为了简化训练过程，我们可以**重参数化**损失函数为一个去噪过程的预测任务。目标变为预测加入噪声的程度（噪声项）的均值和方差。

> 这里重参数的推导很长，可以网上找一下。

$$
L = \mathbb{E}_{q(x_0, \epsilon)} \left[\|\epsilon - \epsilon_\theta(x_t, t)\|^2\right]
$$

其中 $\epsilon$ 是在前向过程加入的数据噪声，$\epsilon_\theta$ 是通过神经网络预测的噪声。所以神经网络的任务就是抽取一个$t$（1~$T$之间），通过$x_0$和加噪过程，计算得到$x_t$，然后神经网络预测噪声，计算预测的噪声和实际噪声的分布差异。

### 训练步骤

1. **采样数据 $x_0$** 从真实数据分布中。
2. **采样噪声 $\epsilon$** 从标准正态分布中。
3. **计算 $x_t$** 通过前向扩散过程，将噪声加入数据。
4. **计算预测的噪声 $\epsilon_\theta(x_t, t)$** 使用神经网络。
5. **计算损失 $L$** 并通过反向传播更新模型参数。

### 生成步骤

生成数据时，从标准正态分布中采样 $x_T$，然后逐步通过逆向生成过程去噪，生成数据 $x_0$。

在DDPM中，会将原始图像的像素值从[0, 255]范围归一化到[-1, 1]，像素值属于离散化值。

### 背后原理

DDPM 通过一个称为“马尔科夫链”的过程，逐步将噪声转化为数据。其核心思想是分阶段进行去噪，每个阶段只去除一小部分噪声，使得每一步的去噪过程更为简单和稳定。
总的来说，DDPM 在生成任务中表现出色，特别是生成图像和其他复杂结构的数据类型。这是因为它通过多步生成过程有效地捕捉了数据的复杂结构和细节。

DDPM的推导过程中，最重要的就是重参数技巧，这个技巧在很多生成模型中都有应用，比如VAE、GAN等。
