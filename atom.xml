<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>拾荒志</title>
  
  <subtitle>虚怀若谷，大智若愚</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://murphypei.github.io/"/>
  <updated>2025-06-25T08:15:16.815Z</updated>
  <id>https://murphypei.github.io/</id>
  
  <author>
    <name>AngryBirds</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LLM 八股文：PPO 和 DPO</title>
    <link href="https://murphypei.github.io//blog/2025/06/llm-interview-ppo-dpo.html"/>
    <id>https://murphypei.github.io//blog/2025/06/llm-interview-ppo-dpo.html</id>
    <published>2025-06-24T12:44:51.000Z</published>
    <updated>2025-06-25T08:15:16.815Z</updated>
    
    <content type="html"><![CDATA[<p>已经接近 3 年没有更新博客了。今天立下一个 flag，开始准备 LLM 面试知识，主要是八股文为主，想到哪写到哪。第一篇没想到写啥，觉得对 PPO 和 DPO 比较了解，就先直接写这个吧。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在大语言模型（LLM）的训练过程中，RLHF（Reinforcement Learning from Human Feedback）是一个重要的技术，它通过人类反馈来优化模型的行为。在RLHF中，PPO（Proximal Policy Optimization）和DPO（Direct Preference Optimization）是两种主流的算法。本文将详细介绍这两种算法的工作原理、数学推导以及它们之间的区别。</p><h2 id="PPO（Proximal-Policy-Optimization）"><a href="#PPO（Proximal-Policy-Optimization）" class="headerlink" title="PPO（Proximal Policy Optimization）"></a>PPO（Proximal Policy Optimization）</h2><h3 id="PPO-基本原理"><a href="#PPO-基本原理" class="headerlink" title="PPO 基本原理"></a>PPO 基本原理</h3><p>PPO 是一种基于策略梯度的强化学习算法，它的核心思想是通过限制策略更新的步长来保证训练的稳定性。在RLHF中，PPO被用来优化语言模型，使其生成更符合人类偏好的回答。</p><h3 id="PPO-的数学推导"><a href="#PPO-的数学推导" class="headerlink" title="PPO 的数学推导"></a>PPO 的数学推导</h3><h4 id="1-策略梯度定理"><a href="#1-策略梯度定理" class="headerlink" title="1. 策略梯度定理"></a>1. 策略梯度定理</h4><p>首先，我们回顾一下策略梯度定理。对于策略 $\pi_\theta$，目标函数为：</p><script type="math/tex; mode=display">J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} [R(\tau)]</script><p>其中 $\tau$ 是轨迹，$R(\tau)$ 是轨迹的奖励。</p><p><strong>策略梯度定理</strong>是强化学习中的一个核心定理，它告诉我们如何直接优化策略参数 $\theta$ 来最大化期望奖励。这个定理的重要性在于：</p><ol><li><strong>直接优化策略</strong>：不像价值函数方法需要先学习价值函数再推导策略，策略梯度方法直接优化策略参数</li><li><strong>理论基础</strong>：为所有基于策略的强化学习算法提供了数学基础</li><li><strong>适用性广</strong>：适用于连续动作空间和离散动作空间</li></ol><p>策略梯度定理告诉我们：</p><script type="math/tex; mode=display">\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} [\nabla_\theta \log \pi_\theta(\tau) R(\tau)]</script><p>这个公式的含义是：</p><ul><li><strong>左侧</strong>：目标函数 $J(\theta)$ 关于参数 $\theta$ 的梯度</li><li><strong>右侧</strong>：策略对数概率的梯度与奖励的乘积的期望</li></ul><p><strong>直观理解</strong>：</p><ul><li>如果某个轨迹 $\tau$ 的奖励 $R(\tau)$ 很高，我们就增加这个轨迹的概率</li><li>如果某个轨迹 $\tau$ 的奖励 $R(\tau)$ 很低，我们就减少这个轨迹的概率</li><li>$\nabla_\theta \log \pi_\theta(\tau)$ 告诉我们在参数空间中应该朝哪个方向移动</li></ul><p><strong>实际应用中的问题</strong>：</p><ol><li><strong>高方差</strong>：直接使用这个公式会导致训练不稳定</li><li><strong>样本效率低</strong>：需要大量样本来估计期望</li><li><strong>更新步长难以控制</strong>：可能导致策略更新过大或过小</li></ol><p>这就是为什么需要 PPO 等改进算法的原因。</p><h4 id="2-PPO-的目标函数"><a href="#2-PPO-的目标函数" class="headerlink" title="2. PPO 的目标函数"></a>2. PPO 的目标函数</h4><p>PPO 通过引入一个比率项来限制策略更新的幅度：</p><script type="math/tex; mode=display">r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}</script><p><strong>比率项的含义</strong>：</p><ul><li>$\pi_{\theta_{old}}(a_t|s_t)$ 是旧策略（更新前）在状态 $s_t$ 下选择动作 $a_t$ 的概率</li><li>$\pi_\theta(a_t|s_t)$ 是新策略（更新后）在状态 $s_t$ 下选择动作 $a_t$ 的概率</li><li>比率 $r_t(\theta)$ 衡量了新策略相对于旧策略的变化程度</li></ul><p><strong>为什么需要限制策略更新幅度</strong>：</p><ol><li><strong>防止策略崩溃</strong>：如果策略更新过大，可能导致某些动作的概率变为0，失去探索能力</li><li><strong>保证训练稳定性</strong>：过大的更新步长会导致训练不稳定，甚至发散</li><li><strong>避免灾难性遗忘</strong>：防止新策略完全偏离旧策略，丢失之前学到的有用知识</li></ol><p>PPO 的目标函数为：</p><script type="math/tex; mode=display">L^{CLIP}(\theta) = \mathbb{E}_t [\min(r_t(\theta) A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) A_t)]</script><p>这个公式的核心思想是：</p><ul><li>如果 $A_t &gt; 0$（好的动作），我们希望增加这个动作的概率，但最多只能增加到 $(1+\epsilon)$ 倍</li><li>如果 $A_t &lt; 0$（坏的动作），我们希望减少这个动作的概率，但最多只能减少到 $(1-\epsilon)$ 倍</li><li>$\epsilon$ 通常设置为 0.2，意味着策略更新幅度被限制在 ±20% 以内</li></ul><p>其中：</p><ul><li>$A_t$ 是优势函数（Advantage function）</li><li>$\epsilon$ 是裁剪参数，通常设置为 0.2</li><li>$\text{clip}(x, a, b)$ 函数将 $x$ 限制在 $[a, b]$ 范围内</li></ul><h4 id="3-优势函数"><a href="#3-优势函数" class="headerlink" title="3. 优势函数"></a>3. 优势函数</h4><p>优势函数衡量了某个动作相对于平均水平的优势：</p><script type="math/tex; mode=display">A_t = Q(s_t, a_t) - V(s_t)</script><p>其中 $Q(s_t, a_t)$ 是动作价值函数，$V(s_t)$ 是状态价值函数。</p><p><strong>价值函数的基本概念</strong>：</p><p>在强化学习中，价值函数用于评估状态或状态-动作对的价值，帮助我们做出更好的决策。</p><p><strong>状态价值函数 $V(s_t)$</strong>：</p><ul><li><strong>定义</strong>：在状态 $s_t$ 下，遵循策略 $\pi$ 的期望累积奖励</li><li><strong>数学表达式</strong>：<script type="math/tex; mode=display">V^\pi(s_t) = \mathbb{E}_{\pi} [\sum_{k=0}^{\infty} \gamma^k R_{t+k} | S_t = s_t]</script></li><li><strong>含义</strong>：表示从状态 $s_t$ 开始，按照策略 $\pi$ 行动，能够获得的期望总奖励</li><li><strong>特点</strong>：只依赖于状态，不依赖于具体动作</li></ul><p><strong>动作价值函数 $Q(s_t, a_t)$</strong>：</p><ul><li><strong>定义</strong>：在状态 $s_t$ 下采取动作 $a_t$，然后遵循策略 $\pi$ 的期望累积奖励</li><li><strong>数学表达式</strong>：<script type="math/tex; mode=display">Q^\pi(s_t, a_t) = \mathbb{E}_{\pi} [\sum_{k=0}^{\infty} \gamma^k R_{t+k} | S_t = s_t, A_t = a_t]</script></li><li><strong>含义</strong>：表示在状态 $s_t$ 下采取动作 $a_t$，然后按照策略 $\pi$ 行动，能够获得的期望总奖励</li><li><strong>特点</strong>：依赖于状态和动作的组合</li></ul><p><strong>优势函数 $A_t$ 的作用</strong>：</p><ul><li><strong>相对评估</strong>：优势函数衡量了某个动作相对于该状态下所有动作平均水平的优势</li><li><strong>决策指导</strong>：<ul><li>如果 $A_t &gt; 0$，说明动作 $a_t$ 比平均水平好，应该增加其概率</li><li>如果 $A_t &lt; 0$，说明动作 $a_t$ 比平均水平差，应该减少其概率</li><li>如果 $A_t = 0$，说明动作 $a_t$ 处于平均水平</li></ul></li></ul><p><strong>在PPO中的重要性</strong>：</p><ol><li><strong>减少方差</strong>：相比直接使用奖励，优势函数提供了更稳定的学习信号</li><li><strong>基线作用</strong>：状态价值函数作为基线，减少了策略梯度的方差</li><li><strong>相对比较</strong>：通过相对比较而不是绝对奖励，使得训练更加稳定</li></ol><p><strong>实际计算中的挑战</strong>：</p><ul><li>真实的价值函数通常是未知的，需要通过神经网络来估计</li><li>这就是为什么PPO需要Critic模型来估计状态价值函数</li><li>优势函数通常通过时序差分（TD）方法或其他技术来估计</li></ul><h3 id="PPO-在-RLHF-中的应用"><a href="#PPO-在-RLHF-中的应用" class="headerlink" title="PPO 在 RLHF 中的应用"></a>PPO 在 RLHF 中的应用</h3><p>在RLHF中，PPO需要四个模型：</p><ol><li><strong>Actor Model</strong>：被训练的策略模型</li><li><strong>Critic Model</strong>：价值函数模型，用于估计状态价值</li><li><strong>Reward Model</strong>：奖励模型，用于计算即时奖励</li><li><strong>Reference Model</strong>：参考模型，用于防止策略偏离太远</li></ol><p>关于这 4 个模型，可以参考我之前的文章：<a href="https://murphypei.github.io/blog/2024/07/llm-rlhf-ppo.html">大模型RLHF训练中的PPO算法细节</a></p><p><strong>四个模型的作用和特点</strong>：</p><p><strong>Actor Model（策略模型）</strong>：</p><ul><li>这是我们要训练的主要模型，最终用于实际应用</li><li>接收prompt，生成response</li><li>在训练过程中，其参数会不断更新以优化策略</li></ul><p><strong>Critic Model（价值函数模型）</strong>：</p><ul><li>用于估计状态价值函数 $V(s_t)$</li><li>通常用Reward Model初始化，架构与Actor相似</li><li>在最后一层增加Value Head，输出单一的价值估计</li><li>需要更新参数，因为价值估计能力需要不断提升</li></ul><p><strong>Reward Model（奖励模型）</strong>：</p><ul><li>计算即时奖励 $R_t$，评估当前response的好坏</li><li>参数固定不更新，作为客观的评估标准</li><li>只关心当前response的质量，不考虑长期影响</li></ul><p><strong>Reference Model（参考模型）</strong>：</p><ul><li>通常用SFT模型初始化，参数冻结</li><li>主要作用是防止Actor”训歪”，避免过拟合到高分但无意义的回答</li><li>通过KL散度约束，确保新策略与参考策略的输出分布相似</li></ul><p><strong>为什么需要四个模型</strong>：</p><ol><li><strong>Actor</strong>：学习生成符合人类偏好的回答</li><li><strong>Critic</strong>：评估整体价值，减少训练方差</li><li><strong>Reward</strong>：提供客观的即时评估标准</li><li><strong>Reference</strong>：防止策略偏离太远，保持语言能力</li></ol><p>PPO 的损失函数包括三个部分：</p><script type="math/tex; mode=display">L_{PPO} = L^{CLIP} - \alpha L^{KL} + \beta L^{VF}</script><p>其中：</p><ul><li>$L^{CLIP}$ 是 PPO 的主要损失，通过裁剪机制限制策略更新</li><li>$L^{KL}$ 是 KL 散度损失，用于限制与参考模型的差异</li><li>$L^{VF}$ 是价值函数损失，用于训练Critic模型</li><li>$\alpha$ 和 $\beta$ 是权重参数，平衡不同损失项的重要性</li></ul><p><strong>训练流程</strong>：</p><ol><li>Actor接收prompt，生成response</li><li>Reward Model计算即时奖励</li><li>Critic Model估计状态价值</li><li>计算优势函数 $A_t = R_t - V_t$</li><li>使用PPO损失函数更新Actor和Critic参数</li><li>通过KL散度约束确保与Reference Model的相似性</li></ol><h2 id="DPO（Direct-Preference-Optimization）"><a href="#DPO（Direct-Preference-Optimization）" class="headerlink" title="DPO（Direct Preference Optimization）"></a>DPO（Direct Preference Optimization）</h2><h3 id="DPO-基本原理"><a href="#DPO-基本原理" class="headerlink" title="DPO 基本原理"></a>DPO 基本原理</h3><p>DPO 是一种更直接的方法，它不需要显式的奖励模型，而是直接通过人类偏好数据来优化策略。DPO 的核心思想是将偏好学习问题转化为一个分类问题。</p><p><strong>DPO的核心创新</strong>：</p><ol><li><strong>消除奖励模型</strong>：不需要单独训练奖励模型，简化了训练流程</li><li><strong>直接偏好学习</strong>：直接从人类偏好数据中学习，避免了奖励建模的误差</li><li><strong>理论等价性</strong>：证明了DPO与基于奖励模型的RLHF在理论上是等价的</li></ol><h3 id="DPO-的数学推导"><a href="#DPO-的数学推导" class="headerlink" title="DPO 的数学推导"></a>DPO 的数学推导</h3><h4 id="1-偏好学习问题"><a href="#1-偏好学习问题" class="headerlink" title="1. 偏好学习问题"></a>1. 偏好学习问题</h4><p>给定一个提示 $x$ 和两个回答 $y_w$（获胜）和 $y_l$（失败），我们的目标是学习一个策略 $\pi_\theta$，使得：</p><script type="math/tex; mode=display">P(y_w \succ y_l | x) > P(y_l \succ y_w | x)</script><p><strong>偏好数据的含义</strong>：</p><ul><li>$y_w \succ y_l$ 表示在提示 $x$ 下，回答 $y_w$ 比 $y_l$ 更受人类偏好</li><li>这种偏好关系反映了人类的价值判断，是RLHF的核心数据</li></ul><h4 id="2-Bradley-Terry-模型"><a href="#2-Bradley-Terry-模型" class="headerlink" title="2. Bradley-Terry 模型"></a>2. Bradley-Terry 模型</h4><p>DPO 使用 Bradley-Terry 模型来建模偏好。这个模型假设偏好概率与奖励函数之间存在以下关系：</p><script type="math/tex; mode=display">P(y_w \succ y_l | x) = \frac{\exp(r_\theta(x, y_w))}{\exp(r_\theta(x, y_w)) + \exp(r_\theta(x, y_l))}</script><p>其中 $r_\theta(x, y)$ 是奖励函数。</p><p><strong>Bradley-Terry模型的特点</strong>：</p><ul><li><strong>单调性</strong>：奖励越高，被偏好的概率越大</li><li><strong>对称性</strong>：$P(y_w \succ y_l | x) + P(y_l \succ y_w | x) = 1$</li><li><strong>温度控制</strong>：可以通过调整指数函数的温度参数来控制偏好强度</li></ul><h4 id="3-从奖励函数到策略的映射"><a href="#3-从奖励函数到策略的映射" class="headerlink" title="3. 从奖励函数到策略的映射"></a>3. 从奖励函数到策略的映射</h4><p>DPO的关键洞察是：我们可以将奖励函数表示为策略与参考策略的比值：</p><script type="math/tex; mode=display">r_\theta(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}</script><p>其中：</p><ul><li>$\pi_{ref}$ 是参考策略（通常是SFT模型）</li><li>$\beta$ 是温度参数，控制奖励的强度</li></ul><p><strong>这个映射的物理意义</strong>：</p><ul><li>如果 $\pi_\theta(y|x) &gt; \pi_{ref}(y|x)$，说明新策略更倾向于生成回答 $y$，奖励为正</li><li>如果 $\pi_\theta(y|x) &lt; \pi_{ref}(y|x)$，说明新策略不太倾向于生成回答 $y$，奖励为负</li><li>$\beta$ 控制奖励的敏感度，值越大，策略差异对奖励的影响越明显</li></ul><h4 id="4-DPO-的目标函数"><a href="#4-DPO-的目标函数" class="headerlink" title="4. DPO 的目标函数"></a>4. DPO 的目标函数</h4><p>将奖励函数代入Bradley-Terry模型，得到DPO的目标函数：</p><script type="math/tex; mode=display">L_{DPO} = -\mathbb{E}_{(x, y_w, y_l) \sim D} \left[\log \sigma\left(\beta \log \frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}\right)\right]</script><p>其中：</p><ul><li>$\sigma$ 是 sigmoid 函数：$\sigma(x) = \frac{1}{1 + e^{-x}}$</li><li>$\beta$ 是温度参数，通常设置为0.1-0.5</li><li>$\pi_{ref}$ 是参考策略（通常是 SFT 模型）</li></ul><p><strong>目标函数的直观理解</strong>：</p><ul><li>我们希望最大化偏好数据的对数似然</li><li>对于偏好对 $(y_w, y_l)$，我们希望 $P(y_w \succ y_l | x)$ 尽可能大</li><li>这等价于让 $\beta \log \frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}$ 尽可能大</li><li>即让获胜回答相对于参考策略的提升幅度大于失败回答</li></ul><h4 id="5-奖励函数的推导"><a href="#5-奖励函数的推导" class="headerlink" title="5. 奖励函数的推导"></a>5. 奖励函数的推导</h4><p>通过 DPO 的训练，我们可以推导出隐含的奖励函数：</p><script type="math/tex; mode=display">r_\theta(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}</script><p>这个公式表明，DPO 实际上是在学习一个相对于参考策略的奖励函数。</p><p><strong>奖励函数的性质</strong>：</p><ol><li><strong>相对性</strong>：奖励是相对于参考策略定义的，不是绝对奖励</li><li><strong>可解释性</strong>：奖励直接反映了策略相对于参考策略的偏好程度</li><li><strong>一致性</strong>：与人类偏好数据保持一致</li></ol><h3 id="DPO-的训练过程"><a href="#DPO-的训练过程" class="headerlink" title="DPO 的训练过程"></a>DPO 的训练过程</h3><p><strong>训练步骤</strong>：</p><ol><li><strong>数据准备</strong>：收集人类偏好数据 $(x, y_w, y_l)$</li><li><strong>策略初始化</strong>：用SFT模型初始化 $\pi_\theta$ 和 $\pi_{ref}$</li><li><strong>前向传播</strong>：计算 $\pi_\theta(y_w|x)$ 和 $\pi_\theta(y_l|x)$</li><li><strong>损失计算</strong>：使用DPO损失函数计算梯度</li><li><strong>参数更新</strong>：只更新 $\pi_\theta$，保持 $\pi_{ref}$ 固定</li></ol><p><strong>关键超参数</strong>：</p><ul><li><strong>$\beta$（温度参数）</strong>：控制策略更新的强度，值越大更新越激进</li><li><strong>学习率</strong>：控制参数更新的步长</li><li><strong>批次大小</strong>：影响训练的稳定性和效率</li></ul><h3 id="DPO-的优势和局限性"><a href="#DPO-的优势和局限性" class="headerlink" title="DPO 的优势和局限性"></a>DPO 的优势和局限性</h3><p><strong>优势</strong>：</p><ol><li><strong>训练简单</strong>：只需要两个模型，训练流程简单</li><li><strong>数据效率高</strong>：直接使用偏好数据，避免了奖励建模的误差</li><li><strong>理论保证</strong>：在理论上与基于奖励的RLHF等价</li><li><strong>计算效率高</strong>：单轮训练，不需要复杂的优势估计</li></ol><p><strong>局限性</strong>：</p><ol><li><strong>依赖参考策略</strong>：奖励函数是相对于参考策略定义的</li><li><strong>偏好数据质量</strong>：对偏好数据的质量要求较高</li><li><strong>探索能力有限</strong>：可能无法探索到远离参考策略的新策略</li><li><strong>温度参数敏感</strong>：$\beta$ 的选择对性能影响较大</li></ol><h3 id="DPO-与-PPO-的理论联系"><a href="#DPO-与-PPO-的理论联系" class="headerlink" title="DPO 与 PPO 的理论联系"></a>DPO 与 PPO 的理论联系</h3><p><strong>等价性的核心前提</strong>：</p><p>DPO与PPO等价的核心前提是：<strong>奖励函数必须满足特定的形式</strong>。具体来说，奖励函数必须能够表示为：</p><script type="math/tex; mode=display">r(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}</script><p>这个前提条件意味着：</p><ol><li><strong>奖励函数与策略的耦合</strong>：奖励函数不能是任意的，必须与当前策略 $\pi_\theta$ 和参考策略 $\pi_{ref}$ 相关</li><li><strong>相对性</strong>：奖励是相对于参考策略定义的，不是绝对奖励</li><li><strong>策略依赖性</strong>：奖励函数会随着策略的更新而变化</li></ol><p><strong>为什么这个前提很重要</strong>：</p><p>在实际的RLHF中，奖励函数通常是独立训练的，其形式为 $r(x, y) = f_\phi(x, y)$，其中 $f_\phi$ 是一个独立的神经网络。这种形式的奖励函数与DPO假设的形式完全不同。</p><p><strong>等价性的假设前提</strong>：</p><p>DPO与PPO的等价性是在以下关键假设下成立的：</p><ol><li><strong>奖励函数假设</strong>：奖励函数必须满足 $r(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}$ 的形式</li><li><strong>优势函数简化</strong>：忽略价值函数，直接使用奖励作为优势函数，即 $A_t = r_t$</li><li><strong>策略约束方式</strong>：使用KL散度约束而不是PPO的裁剪约束</li><li><strong>单步优化</strong>：假设每次更新都是单步的，不考虑多步交互</li></ol><p><strong>理论背景</strong>：</p><p>这个等价性来自于<strong>奖励函数与策略之间的对偶关系</strong>。在强化学习中，存在一个重要的理论结果：对于任何奖励函数 $r(x, y)$，都存在一个最优策略 $\pi^*(y|x)$，使得：</p><script type="math/tex; mode=display">\pi^*(y|x) \propto \pi_{ref}(y|x) \exp(\frac{r(x, y)}{\beta})</script><p>这个关系表明，奖励函数和策略之间存在一一对应的关系。DPO的关键洞察是：如果我们直接学习策略，就可以隐式地学习到对应的奖励函数。</p><p><strong>等价性证明的局限性</strong>：</p><p>需要注意的是，这种等价性有以下局限性：</p><ol><li><strong>奖励函数形式限制</strong>：只有在特定形式的奖励函数下才成立</li><li><strong>忽略价值函数</strong>：实际PPO中价值函数的作用被简化了</li><li><strong>约束方式不同</strong>：PPO的裁剪约束和DPO的KL散度约束在理论上不等价</li><li><strong>训练稳定性</strong>：虽然理论等价，但实际训练中的稳定性可能不同</li></ol><p><strong>实际应用中的差异</strong>：</p><p>尽管在理论上存在等价性，但在实际应用中：</p><ol><li><strong>PPO</strong>：通过显式奖励模型提供更直接的监督信号</li><li><strong>DPO</strong>：通过偏好数据提供相对比较信号</li><li><strong>训练稳定性</strong>：PPO的裁剪机制可能提供更好的训练稳定性</li><li><strong>探索能力</strong>：PPO可能具有更好的探索能力</li></ol><p><strong>等价性证明</strong>：<br>DPO可以看作是PPO在特定条件下的简化版本。当PPO中的：</p><ul><li>奖励模型 $r(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}$</li><li>优势函数 $A_t = r_t$（忽略价值函数）</li><li>策略约束通过KL散度实现</li></ul><p>此时，PPO的损失函数就退化为DPO的形式。</p><p><strong>主要区别</strong>：</p><ol><li><strong>奖励建模</strong>：PPO需要显式奖励模型，DPO隐含在策略中</li><li><strong>优势估计</strong>：PPO需要复杂的优势估计，DPO直接使用奖励</li><li><strong>约束方式</strong>：PPO使用裁剪约束，DPO使用KL散度约束</li></ol><h2 id="PPO-和-DPO-的区别"><a href="#PPO-和-DPO-的区别" class="headerlink" title="PPO 和 DPO 的区别"></a>PPO 和 DPO 的区别</h2><h3 id="1-训练复杂度"><a href="#1-训练复杂度" class="headerlink" title="1. 训练复杂度"></a>1. 训练复杂度</h3><ul><li><strong>PPO</strong>：需要四个模型（Actor、Critic、Reward、Reference），训练过程复杂</li><li><strong>DPO</strong>：只需要两个模型（策略模型和参考模型），训练过程简单</li></ul><h3 id="2-数据需求"><a href="#2-数据需求" class="headerlink" title="2. 数据需求"></a>2. 数据需求</h3><ul><li><strong>PPO</strong>：需要显式的奖励信号或奖励模型</li><li><strong>DPO</strong>：只需要偏好数据（哪个更好），不需要显式奖励</li></ul><h3 id="3-计算效率"><a href="#3-计算效率" class="headerlink" title="3. 计算效率"></a>3. 计算效率</h3><ul><li><strong>PPO</strong>：需要多轮交互和复杂的优势估计</li><li><strong>DPO</strong>：单轮训练，计算效率更高</li></ul><h3 id="4-稳定性"><a href="#4-稳定性" class="headerlink" title="4. 稳定性"></a>4. 稳定性</h3><ul><li><strong>PPO</strong>：通过裁剪机制保证训练稳定性</li><li><strong>DPO</strong>：通过 KL 散度约束保证稳定性</li></ul><h3 id="5-适用场景"><a href="#5-适用场景" class="headerlink" title="5. 适用场景"></a>5. 适用场景</h3><ul><li><strong>PPO</strong>：适用于有明确奖励信号或可以训练奖励模型的场景</li><li><strong>DPO</strong>：适用于只有人类偏好数据的场景</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>PPO 和 DPO 都是 RLHF 中的重要算法，它们各有优缺点：</p><ul><li><strong>PPO</strong> 更加成熟和稳定，但训练复杂度高</li><li><strong>DPO</strong> 更加简单和高效，但可能在某些场景下效果不如 PPO</li></ul><p>选择哪种算法主要取决于具体的应用场景和可用的数据。在实际应用中，可以根据需求选择合适的算法，或者将两种算法结合使用。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Schulman, J., et al. “Proximal policy optimization algorithms.” arXiv preprint arXiv:1707.06347 (2017).</li><li>Rafailov, R., et al. “Direct preference optimization: Your language model is secretly a reward model.” arXiv preprint arXiv:2305.18290 (2023).</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;已经接近 3 年没有更新博客了。今天立下一个 flag，开始准备 LLM 面试知识，主要是八股文为主，想到哪写到哪。第一篇没想到写啥，觉得对 PPO 和 DPO 比较了解，就先直接写这个吧。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="面试" scheme="https://murphypei.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
      <category term="rlhf" scheme="https://murphypei.github.io/tags/rlhf/"/>
    
      <category term="ppo" scheme="https://murphypei.github.io/tags/ppo/"/>
    
      <category term="dpo" scheme="https://murphypei.github.io/tags/dpo/"/>
    
  </entry>
  
  <entry>
    <title>图像生成基础-DDPM</title>
    <link href="https://murphypei.github.io//blog/2024/07/aigc-ddpm.html"/>
    <id>https://murphypei.github.io//blog/2024/07/aigc-ddpm.html</id>
    <published>2024-07-31T09:44:51.000Z</published>
    <updated>2025-06-25T02:00:04.086Z</updated>
    
    <content type="html"><![CDATA[<p>目前所采用的扩散模型大都是来自于2020年的工作DDPM。DDPM对之前的扩散模型进行了简化，并通过变分推断（variational inference）来进行建模，这主要是因为扩散模型也是一个隐变量模型（latent variable model），相比VAE这样的隐变量模型，扩散模型的隐变量是和原始数据是同维度的，而且推理过程（即扩散过程）往往是固定的。</p><a id="more"></a><p>扩散模型包括两个过程：前向过程（forward process）和反向过程（reverse process），其中前向过程又称为扩散过程（diffusion process），如下图所示。无论是前向过程还是反向过程都是一个参数化的马尔可夫链（Markov chain），其中反向过程可以用来生成数据，这里我们将通过变分推断来进行建模和求解。</p><p><img src="/images/posts/aigc/ddpm/1.webp" alt></p><h3 id="前向扩散过程-Forward-Diffusion-Process"><a href="#前向扩散过程-Forward-Diffusion-Process" class="headerlink" title="前向扩散过程 (Forward Diffusion Process)"></a>前向扩散过程 (Forward Diffusion Process)</h3><p>解释扩散之前先介绍一个基本的数学表示：</p><script type="math/tex; mode=display">\mathcal{N}(x_t; \mu, \Sigma)</script><p>一个正态分布，其中$\mu$是均值，$\Sigma$是协方差矩阵。在这个过程中，$x_t$服从一个$\mu$为均值、$\Sigma$为协方差矩阵的正态分布。</p><p>扩散就是对图像数据进行加噪声的过程，<strong>最核心的数学公式</strong>表示如下：</p><script type="math/tex; mode=display">q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})</script><p>$x_0$是原始数据，$x_t$是在$t$时刻的样本，$\mathcal{N}$表示正态分布，$\beta_t$表示在第$t$步的方差（噪音量），它是一个介于0和1之间的值，$\sqrt{1 - \beta_t}$表示输入数据的缩放系数，$\beta_t \mathbf{I}$表示加的噪音的方差。</p><p>这个公式表示，给定$x_{t-1}$的情况下，$x_t$是以$\sqrt{1 - \beta_t} x_{t-1}$为均值、$\beta_t \mathbf{I}$为协方差矩阵的正态分布。可以简单理解为，$x_t$是$x_{t-1}$加上高斯噪音后的结果。</p><p>前向过程就是这么简单。当我们逐渐加大$\beta_t$时，$x_t$逐渐变得模糊，最终变成一个高斯噪声图像。</p><script type="math/tex; mode=display">q(x_T|x_0) \approx \mathcal{N}(0, I)</script><p>这里也有一个推导，就是通过 $x_0$，可以直接表示$x_T$，因为高斯分布可以直接相加。</p><h3 id="逆向生成过程-Reverse-Generation-Process"><a href="#逆向生成过程-Reverse-Generation-Process" class="headerlink" title="逆向生成过程 (Reverse Generation Process)"></a>逆向生成过程 (Reverse Generation Process)</h3><p>训练过程中，DDPM 学习从噪声生成数据的逆向过程。我们<strong>假设逆向过程也是一个高斯过程</strong>，但参数未知：</p><script type="math/tex; mode=display">p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \sigma_\theta^2(x_t, t) I)</script><p>这里，模型的任务是学习 $\mu_\theta$ 和 $\sigma_\theta$ 的参数化形式，使得可以从噪声生成逼真的数据样本。</p><h3 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h3><p>训练的目标是最小化前向过程和逆向过程之间的差异。具体来说，训练目标可以表示为以下KL散度的和：</p><script type="math/tex; mode=display">L = \sum_{t=1}^{T} D_{KL}\left(q(x_{t-1}|x_t, x_0) \| p_\theta(x_{t-1}|x_t)\right)</script><p>每一个KL项衡量在第$t$个时间步长上真实分布和模型估计分布之间的差异。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>为了简化训练过程，我们可以<strong>重参数化</strong>损失函数为一个去噪过程的预测任务。目标变为预测加入噪声的程度（噪声项）的均值和方差。</p><blockquote><p>这里重参数的推导很长，可以网上找一下。</p></blockquote><script type="math/tex; mode=display">L = \mathbb{E}_{q(x_0, \epsilon)} \left[\|\epsilon - \epsilon_\theta(x_t, t)\|^2\right]</script><p>其中 $\epsilon$ 是在前向过程加入的数据噪声，$\epsilon_\theta$ 是通过神经网络预测的噪声。所以神经网络的任务就是抽取一个$t$（1~$T$之间），通过$x_0$和加噪过程，计算得到$x_t$，然后神经网络预测噪声，计算预测的噪声和实际噪声的分布差异。</p><h3 id="训练步骤"><a href="#训练步骤" class="headerlink" title="训练步骤"></a>训练步骤</h3><ol><li><strong>采样数据 $x_0$</strong> 从真实数据分布中。</li><li><strong>采样噪声 $\epsilon$</strong> 从标准正态分布中。</li><li><strong>计算 $x_t$</strong> 通过前向扩散过程，将噪声加入数据。</li><li><strong>计算预测的噪声 $\epsilon_\theta(x_t, t)$</strong> 使用神经网络。</li><li><strong>计算损失 $L$</strong> 并通过反向传播更新模型参数。</li></ol><h3 id="生成步骤"><a href="#生成步骤" class="headerlink" title="生成步骤"></a>生成步骤</h3><p>生成数据时，从标准正态分布中采样 $x_T$，然后逐步通过逆向生成过程去噪，生成数据 $x_0$。</p><p>在DDPM中，会将原始图像的像素值从[0, 255]范围归一化到[-1, 1]，像素值属于离散化值。</p><h3 id="背后原理"><a href="#背后原理" class="headerlink" title="背后原理"></a>背后原理</h3><p>DDPM 通过一个称为“马尔科夫链”的过程，逐步将噪声转化为数据。其核心思想是分阶段进行去噪，每个阶段只去除一小部分噪声，使得每一步的去噪过程更为简单和稳定。<br>总的来说，DDPM 在生成任务中表现出色，特别是生成图像和其他复杂结构的数据类型。这是因为它通过多步生成过程有效地捕捉了数据的复杂结构和细节。</p><p>DDPM的推导过程中，最重要的就是重参数技巧，这个技巧在很多生成模型中都有应用，比如VAE、GAN等。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前所采用的扩散模型大都是来自于2020年的工作DDPM。DDPM对之前的扩散模型进行了简化，并通过变分推断（variational inference）来进行建模，这主要是因为扩散模型也是一个隐变量模型（latent variable model），相比VAE这样的隐变量模型，扩散模型的隐变量是和原始数据是同维度的，而且推理过程（即扩散过程）往往是固定的。&lt;/p&gt;
    
    </summary>
    
      <category term="AIGC" scheme="https://murphypei.github.io/categories/AIGC/"/>
    
    
      <category term="AIGC" scheme="https://murphypei.github.io/tags/AIGC/"/>
    
      <category term="DDPM" scheme="https://murphypei.github.io/tags/DDPM/"/>
    
      <category term="图像生成" scheme="https://murphypei.github.io/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>大模型RLHF训练中的PPO算法细节</title>
    <link href="https://murphypei.github.io//blog/2024/07/llm-rlhf-ppo.html"/>
    <id>https://murphypei.github.io//blog/2024/07/llm-rlhf-ppo.html</id>
    <published>2024-07-25T09:15:51.000Z</published>
    <updated>2025-06-25T02:00:04.086Z</updated>
    
    <content type="html"><![CDATA[<p>虽然了解大模型训练中的RLHF训练，但是都是有点不够深刻，特别是PPO算法的细节。</p><a id="more"></a><p>看到一篇好文章，转载并重新编辑，加入个人理解，以便日后查阅。有兴趣可以参考<a href="https://zhuanlan.zhihu.com/p/677607581" target="_blank" rel="noopener">原文</a></p><h2 id="强化学习"><a href="#强化学习" class="headerlink" title="强化学习"></a>强化学习</h2><p>强化学习属于机器学习的一个分支，区别于有监督学习。关键点在于：</p><ol><li>无监督，没有标签，通过试错和奖励来优化行为和策略。</li><li>与环境有交互。（抽象概念，不要深究）</li><li>没有明确的反馈（无标签），反馈是通过奖励信号传递的，可以是延迟的，需要考虑长期回报。</li></ol><p>强化学习的简化图：<br><img src="/images/posts/llm/ppo/rl.webp" alt></p><p>强化学习的两个实体：<strong>智能体（Agent）</strong>与<strong>环境（Environment）</strong>。强化学习中两个实体的交互：</p><ul><li><strong>状态空间S</strong>：S即为State，指环境中所有可能状态的集合</li><li><strong>动作空间A</strong>：A即为Action，指智能体所有可能动作的集合</li><li><strong>奖励R</strong>：R即为Reward，指智能体在环境的某一状态下所获得的奖励。</li></ul><p>一个交互过程可以表示为：</p><ol><li>在$t$时刻，智能体处于状态$S_t$，在该状态下，得到的奖励为$R_t$；</li><li>根据$S_t$、$R_t$以及策略智能体选择动作$A_t$；</li><li>执行动作$A_t$后环境转移到状态$S_{t+1}$，智能体获得奖励$R_{t+1}$。</li></ol><p>智能体在这个过程中学习，它的最终目标是：<strong>找到一个策略，这个策略根据当前观测到的环境状态和奖励反馈，来选择最佳的动作</strong>。</p><h3 id="价值函数"><a href="#价值函数" class="headerlink" title="价值函数"></a>价值函数</h3><p>奖励$R$是一个标量，但是在实际问题中，一个动作，既有即时奖励，也要考虑<strong>长期回报</strong>。为了解决这个问题，引入了<strong>价值函数</strong>的概念。</p><script type="math/tex; mode=display">V_t = R_t + \gamma V_{t+1}</script><p>其中：</p><ul><li>$V_t$：表示在$t$时刻的状态$S_t$下的价值（包含了即时和未来的奖励）。</li><li>$R_t$：$t$时刻的即时收益。</li><li>$\gamma$：是折扣因子，用于平衡当前奖励和未来奖励。</li></ul><p>这里最需要注意的是：$V_{t+1}$同样包含了现在和未来的奖励，但是对于$V_{t}$来说，它就相当于未来潜在收益。</p><h2 id="NLP和强化学习"><a href="#NLP和强化学习" class="headerlink" title="NLP和强化学习"></a>NLP和强化学习</h2><p><img src="/images/posts/llm/ppo/nlp-rl.webp" alt></p><p>这里的NLP是特质生成模型。</p><p>生成模型的推理执行过程：给模型一个prompt，让模型能生成符合人类喜好的response。再回想一下gpt模型做推理的过程：每个时刻$t$只产生一个token，即token是一个一个蹦出来的，先有上一个token，再有下一个token。</p><p>结合上面的图，分解一下这个过程：</p><ol><li>智能体就是生成模型。</li><li>在$t$时刻，有上下文context（$S_t$），模型产出一个token，对应RL中的动作，记为$A_t$。动作空间就是词表。</li><li>在$t$时刻，有了$A_t$动作，<strong>即时</strong>收益为$R_t$，总收益为$V_t$（注意二者不一样）。对于生成模型，收益是什么？人类喜好。</li><li>状态变化，$S_{t+1}$变为$S_t$和新生成的token。</li><li><strong>忽略图中的下表，主要理解过程和对应的东西</strong>。</li></ol><p>$A_t$是产出一个新token，$S_t$是词表空间，$R_t$和$V_t$是什么？答案是通过模型产生的分数，这里不要在意命名，你叫评价模型，叫奖励模型都行，只不过是两个打分模型而已。</p><p>记住，到此已经有了<strong>3个模型</strong>了啊，$A_t$模型表示智能体的动作，$R_t$和$V_t$是两个打分模型，分别表示即时奖励和未来长期奖励。</p><p>还有一个重要的点：不是生成一个token，也就是有一个动作，我们就要计算奖励、打分，可以等生成模型回答完毕（也就是eos token）再打分。</p><h2 id="RLHF中的4个模型"><a href="#RLHF中的4个模型" class="headerlink" title="RLHF中的4个模型"></a>RLHF中的4个模型</h2><p>OpenAI的示意图：</p><p><img src="/images/posts/llm/ppo/ppo.png" alt></p><p>RLHF中使用的模型示意图：</p><p><img src="/images/posts/llm/ppo/rlhf.webp" alt></p><p>现在大家都知道PPO有4个模型，上面我们说了3个，还有1个，这里将4个模型都列出来：</p><ul><li>Actor Model：PPO训练的模型，也是我们最终要用于应用的模型。</li><li>Critic Model：懒得翻译了，我以前就是太纠结这个名字，一直理解不上去。实际上就是一个整体收益的打分模型，也是上面的$V_t$。</li><li>Reward Model：即时收益$R_t$。</li><li>Reference Model：这个模型是额外增加的，主要是在RLHF阶段给语言模型增加一些“约束”，防止语言模型训歪（朝不受控制的方向更新，效果可能越来越差）。这个看Loss就能明白了。</li></ul><h3 id="哪些模型需要更新参数？"><a href="#哪些模型需要更新参数？" class="headerlink" title="哪些模型需要更新参数？"></a>哪些模型需要更新参数？</h3><p>Actor Model 和 Critic Model。Actor肯定是很好理解的，所以不多说了，Critic Model 为什么也要更新？主要是这里存在一个难点：怎么评估总体收益呢？我们自己随口一说评估总体收益，但是这个是很难的，因为没有真的标签（有监督）。所以我们需要通过一个模型来判断，而且更重要的是，这个判断模型的能力，<strong>要不断提升能力</strong>，才能做好这件事。</p><h3 id="Actor-Model"><a href="#Actor-Model" class="headerlink" title="Actor Model"></a>Actor Model</h3><p><img src="/images/posts/llm/ppo/actor.webp" alt></p><p>我们的最终目的是让Actor模型能产生符合人类喜好的response。所以我们的策略是，先喂给Actor一条prompt （这里假设batch_size = 1，所以是1条prompt），让它生成对应的response。然后，我们再将“prompt + response”送入我们的“奖励-loss”计算体系中去算得最后的loss，用于更新actor。</p><h3 id="Reference-Model"><a href="#Reference-Model" class="headerlink" title="Reference Model"></a>Reference Model</h3><p>Reference Model一般也用SFT阶段得到的SFT模型做初始化，在训练过程中，它的参数是冻结的。Ref模型的主要作用是防止Actor”训歪”，那么它具体是怎么做到这一点的呢？</p><p><img src="/images/posts/llm/ppo/ref.webp" alt></p><p>“防止模型训歪”换一个更详细的解释是：我们希望训练出来的Actor模型既能达到符合人类喜好的目的，又尽量让它和SFT模型不要差异太大。简言之，我们希望两个模型的输出分布尽量相似。那什么指标能用来衡量输出分布的相似度呢？我们自然而然想到了<strong>KL散度</strong>。</p><blockquote><p>简单来说就是防止模型“高分低能”，过拟合到乱七八糟但是得分高的回答上。</p></blockquote><p>关于KL散度和ref模型的计算，这里不需要展开，网上资料特别多。</p><h3 id="Critic-Model"><a href="#Critic-Model" class="headerlink" title="Critic Model"></a>Critic Model</h3><p><img src="/images/posts/llm/ppo/critic.webp" alt></p><p>前面已经讲了这个模型的作用以及为什么要更新参数。简单讲一下这个模型怎么训练的：一般都是采用了Reward模型作为它的初始化，所以这里我们也按Reward模型的架构来简单画画它。你可以简单理解成，Reward/Critic模型和Actor模型的架构是很相似的（毕竟输入都一样），同时，它在最后一层增加了一个Value Head层，该层是个简单的线形层，用于将原始输出结果映射成单一的$V_t$值。</p><h3 id="Reward-Model"><a href="#Reward-Model" class="headerlink" title="Reward Model"></a>Reward Model</h3><p><img src="/images/posts/llm/ppo/reward.webp" alt></p><p>计算即时收益，也没啥好讲的，提前训练好的（RLHF第二阶段做的事情），这里重点讲一下为啥reward模型不需要更新参数呢？</p><p>其实我觉得不要深入去纠结，我感觉PPO这么做的原因就是为了引入一个客观的、绝对的标准。这个模型最重要的区别在于，<strong>它只关心当前这个response的好坏</strong>。Critic隐含了综合考虑所有response的好坏的含义（需要才需要更新参数）。</p><h2 id="RLHF的Loss计算"><a href="#RLHF的Loss计算" class="headerlink" title="RLHF的Loss计算"></a>RLHF的Loss计算</h2><p>我已经看过太多次了，所以不想重新写这个了，直接看原文或者网上搜一下就知道了。注意每一项对应ref、critic、reward模型，结合前面讲解的各个模型的作用，应该能很好地理解这个Loss的含义。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;虽然了解大模型训练中的RLHF训练，但是都是有点不够深刻，特别是PPO算法的细节。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="RLHF" scheme="https://murphypei.github.io/tags/RLHF/"/>
    
      <category term="PPO" scheme="https://murphypei.github.io/tags/PPO/"/>
    
      <category term="大模型" scheme="https://murphypei.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>STL 旋转序列算法 rotate</title>
    <link href="https://murphypei.github.io//blog/2022/12/stl-rotate.html"/>
    <id>https://murphypei.github.io//blog/2022/12/stl-rotate.html</id>
    <published>2022-12-07T03:35:51.000Z</published>
    <updated>2025-06-25T02:00:04.078Z</updated>
    
    <content type="html"><![CDATA[<p>最近开发需要不管刷新缓冲区，发现了一个有用的 STL 算法。</p><a id="more"></a><p>先说明应用场景：我有一块缓冲区 vector，不断接收数据和消费数据（生产消费模型），接收数据就放在末尾，消费头部数据，消费完删除。之前用 realloc 和 memmove 来操作，改为 vector 之后如果每次搬移数据就很麻烦了，查了一下发现 <a href="https://en.cppreference.com/w/cpp/algorithm/rotate" target="_blank" rel="noopener">rotate</a> 配合 resize 可以搞定。</p><p>std::rotate() 的第一个参数是这个序列的开始迭代器；第二个参数是指向新的第一个元素的迭代器，<strong>它必定在序列之内</strong>。第三个参数是这个序列的结束迭代器。意思是将第二个参数的元素旋转到第一个参数的位置，旋转的序列是第一个参数到第三个参数的范围。</p><p>你可以想象第一个参数 ~ 第三个参数之间的元素序列组成一个圆盘，左转就是逆时针旋转，直到第二个参数转到第一个参数的位置，旋转结束。</p><p>可以参数<a href="http://c.biancheng.net/view/609.html" target="_blank" rel="noopener">图解</a></p><p>旋转完成后，头部就变到 vector 末尾了，用 resize 可以标记删除掉这些元素。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近开发需要不管刷新缓冲区，发现了一个有用的 STL 算法。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="STL" scheme="https://murphypei.github.io/tags/STL/"/>
    
      <category term="stl" scheme="https://murphypei.github.io/tags/stl/"/>
    
      <category term="rotate" scheme="https://murphypei.github.io/tags/rotate/"/>
    
  </entry>
  
  <entry>
    <title>vscode C++ 开发之使用 clangd、C/C++、clang-format</title>
    <link href="https://murphypei.github.io//blog/2022/12/vscode-clang-format.html"/>
    <id>https://murphypei.github.io//blog/2022/12/vscode-clang-format.html</id>
    <published>2022-12-07T03:25:55.000Z</published>
    <updated>2025-06-25T02:00:04.082Z</updated>
    
    <content type="html"><![CDATA[<p>最近比较忙，废话少说，vscode 开发 C/C++ 需要很繁琐的配置，之前也说过 launch 和 tasks 的配置。这篇文章主要结合自身使用经历讲讲 C++ 相关插件。</p><a id="more"></a><p>vscode 最常用的几个 C++ 插件（不包含 cmake）就是微软的 C/C++、LLVM 的 clangd，以前我也使用 C/C++，但是智能补全和提示、include 路径都太差劲了，转投 clangd 了，确实好用。所以不废话，直接推荐使用 clangd，不过 C/C++ 也在用，为了二者不冲突，需要配置如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">"C_Cpp.autocomplete": "Disabled",</span><br><span class="line">"C_Cpp.clang_format_fallbackStyle": "Visual Studio",</span><br><span class="line">"C_Cpp.clang_format_sortIncludes": true,</span><br><span class="line">"C_Cpp.clang_format_style": "file",</span><br><span class="line">"C_Cpp.default.compilerPath": "/usr/bin/g++",</span><br><span class="line">"C_Cpp.default.configurationProvider": "ms-vscode.cmake-tools",</span><br><span class="line">"C_Cpp.default.cppStandard": "c++11",</span><br><span class="line">"C_Cpp.default.cStandard": "c99",</span><br><span class="line">"C_Cpp.default.intelliSenseMode": "gcc-x64",</span><br><span class="line">"C_Cpp.errorSquiggles": "Disabled",</span><br><span class="line">"C_Cpp.intelliSenseEngine": "Disabled",</span><br><span class="line">"clangd.arguments": [</span><br><span class="line">// 在后台自动分析文件（基于complie_commands)</span><br><span class="line">"--background-index",</span><br><span class="line">"--compile-commands-dir=$&#123;workspaceFolder&#125;/build",</span><br><span class="line">"-j=8",</span><br><span class="line">// 支持 .clangd 配置</span><br><span class="line">"--enable-config",</span><br><span class="line">"--clang-tidy",</span><br><span class="line">"--clang-tidy-checks=performance-*,bugprone-*",</span><br><span class="line">"--log=verbose",</span><br><span class="line">"--pretty",</span><br><span class="line">// 全局补全（会自动补充头文件）</span><br><span class="line">"--all-scopes-completion",</span><br><span class="line">// 更详细的补全内容</span><br><span class="line">"--completion-style=detailed",</span><br><span class="line">// 补充头文件的形式</span><br><span class="line">"--header-insertion=iwyu",</span><br><span class="line">// pch优化的位置</span><br><span class="line">"--pch-storage=memory",</span><br><span class="line">"--function-arg-placeholders",</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>clangd 的 include 可以通过如下配置：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">"clangd.fallbackFlags": [</span><br><span class="line">    "-std=c++11",</span><br><span class="line">    "-I/usr/include/c++/9",</span><br><span class="line">    "-I/usr/include/opencv4",</span><br><span class="line">    "-I$&#123;workspaceFolder&#125;/src/",</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>clangd 虽然很香，但是有个明显的缺点，就是它一定要使用自身的 clang-format 来格式化，而且无法配置使用 .clang-format 文件。为此，需要安装另一个插件 xaver clang-format。安装完成后配置格式化的程序：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">"[cpp]": &#123;</span><br><span class="line">// "editor.defaultFormatter": "llvm-vs-code-extensions.vscode-clangd"</span><br><span class="line">"editor.defaultFormatter": "xaver.clang-format"</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>这个插件可以直接调用项目根目录下的 .clang-format 文件来格式化。</p><p>最后，有条件的推荐使用 clion 来开发和调试 C++。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近比较忙，废话少说，vscode 开发 C/C++ 需要很繁琐的配置，之前也说过 launch 和 tasks 的配置。这篇文章主要结合自身使用经历讲讲 C++ 相关插件。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="vscode" scheme="https://murphypei.github.io/tags/vscode/"/>
    
      <category term="clangd" scheme="https://murphypei.github.io/tags/clangd/"/>
    
      <category term="clang-format" scheme="https://murphypei.github.io/tags/clang-format/"/>
    
  </entry>
  
  <entry>
    <title>golang select 机制和超时</title>
    <link href="https://murphypei.github.io//blog/2022/06/go-select-timeout.html"/>
    <id>https://murphypei.github.io//blog/2022/06/go-select-timeout.html</id>
    <published>2022-06-25T06:24:59.000Z</published>
    <updated>2025-06-25T02:00:04.078Z</updated>
    
    <content type="html"><![CDATA[<p>golang 中的协程使用非常方便，但是协程什么时候结束是一个控制问题，可以用 select 配合使用。</p><a id="more"></a><p>首先声明，golang 使用并不熟悉，本文仅仅是记录使用过程中遇到的一些坑。</p><p>子协程和父协程的通信通常用 context 或者 chan。我遇到一个通常的使用场景，在子协程中尝试多次处理，父协程等待一段时间超时，我选择用 chan 实现。我以为 select 和 C++ 中 switch 类似，所以最开始代码类似如下：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">            <span class="comment">// process ctx done</span></span><br><span class="line">        <span class="keyword">case</span> &lt;-time.After(time.Second * <span class="number">3</span>):</span><br><span class="line">            <span class="comment">// process after</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="comment">// process code</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试发现无法实现 timeout，又仔细查看文档，才发现 golang 中 select 另有玄机。废话少说，直接总结要点：</p><ul><li>select 中的 case 必须是进行 chan 的手法操作，也就是只能在 case 中操作 chan，并且是<strong>非阻塞接收</strong>。</li><li>select 中的 case 是同时监听的，多个 case 同时操作，并未 switch 中一个个顺序判断。如果多个 case 满足要求，随机执行一个，如果一个没有则阻塞当前的协程（没有 default 情况下）。<strong>很类似 Linux 文件符操作的 select 语义</strong>。</li><li>上面说的阻塞是没有 default 的情况下，如果有 default，则执行 default，然后退出 select，也就是不会阻塞当前协程。</li></ul><p>回到上述代码，我这个 select 会一直不断的执行 default，<code>time.After</code> 生成的 chan 并不会被阻塞判断，所以根本无法完成我想要的效果。理解了之后重新修改代码：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">done := <span class="built_in">make</span>(char <span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(c <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="comment">// process code</span></span><br><span class="line">        <span class="keyword">if</span> &#123;</span><br><span class="line">            c &lt;- <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    c &lt;- <span class="number">0</span></span><br><span class="line">&#125;(done)</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">        <span class="comment">// process ctx done</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-time.After(time.Second * <span class="number">3</span>):</span><br><span class="line">        <span class="comment">// process after</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-done:</span><br><span class="line">        <span class="comment">// process code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>开一个新的协程去不断尝试，在外的三个 case 有一个满足，则会执行。但是这里有一个问题非常需要注意：<strong>子协程什么时候退出？</strong>。</p><p>因为 gorountine 不能被强制 kill，所以在上述超时的情况下，select 语句执行 <code>case time.After</code> 之后退出，<code>done</code> 这个 chan 已经没有接受方了，因此既没有接受者，又没有缓冲区，结合 chan 的特性，则子协程会一直阻塞无法退出，所以本质上这个实现会导致子协程累积下去，也就是<strong>协程泄露</strong>，可能会使资源耗尽。</p><p>如何避免上述问题呢？一个很简单的想法就是提供缓冲区，<code>done := make(char int, 1)</code>，这样即使没有接收方，子协程也能完成发送，不会被阻塞。</p><p>还要一种办法，上面说了，select 操作 chan，并且可以指定 default，那是不是有思路了呢？</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> done &lt;- <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们尝试往 chan 中发送，如果发不出去，则就退出，也实现了目的。</p><p>最后总结一下，goroutine 泄露的防范条例：</p><ul><li>创建 goroutine 时就要想好该 goroutine 该如何结束。</li><li>使用 chan 时，要考虑到 chan 阻塞时协程可能的行为。</li><li>实现循环语句时注意循环的退出条件，避免死循环。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;golang 中的协程使用非常方便，但是协程什么时候结束是一个控制问题，可以用 select 配合使用。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="https://murphypei.github.io/categories/Golang/"/>
    
    
      <category term="select" scheme="https://murphypei.github.io/tags/select/"/>
    
      <category term="golang" scheme="https://murphypei.github.io/tags/golang/"/>
    
      <category term="case" scheme="https://murphypei.github.io/tags/case/"/>
    
      <category term="timeout" scheme="https://murphypei.github.io/tags/timeout/"/>
    
      <category term="after" scheme="https://murphypei.github.io/tags/after/"/>
    
      <category term="chan" scheme="https://murphypei.github.io/tags/chan/"/>
    
  </entry>
  
  <entry>
    <title>C++ 链接一个不需要的库(--no-as-needed)</title>
    <link href="https://murphypei.github.io//blog/2022/04/link-noneed-lib.html"/>
    <id>https://murphypei.github.io//blog/2022/04/link-noneed-lib.html</id>
    <published>2022-04-18T09:16:49.000Z</published>
    <updated>2025-06-25T02:00:04.074Z</updated>
    
    <content type="html"><![CDATA[<p>使用 libtorch 的 C++ 动态链接库遇到了一个非常诡异的问题…</p><a id="more"></a><p>我使用 libtorch 的库编译了一个语音识别程序，使用 CPU 推理，能够完美运行，然后在 go 中对这个程序封装了一层 GRPC，也都 OK。</p><p>但是当我想用 GPU 推理的时候，我直接下载了 libtorch 的 <a href="https://download.pytorch.org/libtorch/cu113/libtorch-cxx11-abi-shared-with-deps-1.11.0%2Bcu113.zip" target="_blank" rel="noopener">GPU 库</a>，然后直接编译语音程序（需要修改 <code>torch::Device</code>），可以直接跑在 GPU 上了，很开心。</p><p>但是我用第二次编译出来的库放到 go 程序中，则出现了诡异的错误，运行加载模型的时候，<code>model-&gt;to_device</code>，而且 <code>device_count</code> 为 0，很明显，程序没找到 GPU。</p><p>利用 ldd 查看 go 编译出来的可执行文件，发现没有链接到 <code>torch_cuda_*</code> 这些库，怎么会这么奇怪呢？我明明把这些库放到编译的 flags 中了。为此我反复调整了链接的 flag，包括库的顺序，库的路径等等，但是都无济于事。</p><p>几经辗转，终于找到一个和我类似的错误了。<a href="https://github.com/pytorch/pytorch/issues/72396" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/72396</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">Could not run &apos;aten::empty_strided&apos; with arguments from the &apos;CUDA&apos; backend. This could be because the operator doesn&apos;t exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. &apos;aten::empty_strided&apos; is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].</span><br><span class="line"></span><br><span class="line">CPU: registered at aten\src\ATen\RegisterCPU.cpp:18433 [kernel]</span><br><span class="line">Meta: registered at aten\src\ATen\RegisterMeta.cpp:12703 [kernel]</span><br><span class="line">BackendSelect: registered at aten\src\ATen\RegisterBackendSelect.cpp:665 [kernel]</span><br><span class="line">Python: registered at ..\..\aten\src\ATen\core\PythonFallbackKernel.cpp:47 [backend fallback]</span><br><span class="line">Named: registered at ..\..\aten\src\ATen\core\NamedRegistrations.cpp:7 [backend fallback]</span><br><span class="line">Conjugate: fallthrough registered at ..\..\aten\src\ATen\ConjugateFallback.cpp:22 [kernel]</span><br><span class="line">Negative: fallthrough registered at ..\..\aten\src\ATen\native\NegateFallback.cpp:22 [kernel]</span><br><span class="line">ADInplaceOrView: fallthrough registered at ..\..\aten\src\ATen\core\VariableFallbackKernel.cpp:64 [backend fallback]</span><br><span class="line">AutogradOther: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradCPU: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradCUDA: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradXLA: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradLazy: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradXPU: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradMLC: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradHPU: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradNestedTensor: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradPrivateUse1: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradPrivateUse2: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradPrivateUse3: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">Tracer: registered at ..\..\torch\csrc\autograd\generated\TraceType_2.cpp:11423 [kernel]</span><br><span class="line">UNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ..\..\aten\src\ATen\autocast_mode.cpp:466 [backend fallback]</span><br><span class="line">Autocast: fallthrough registered at ..\..\aten\src\ATen\autocast_mode.cpp:305 [backend fallback]</span><br><span class="line">Batched: registered at ..\..\aten\src\ATen\BatchingRegistrations.cpp:1016 [backend fallback]</span><br><span class="line">VmapMode: fallthrough registered at ..\..\aten\src\ATen\VmapModeRegistrations.cpp:33 [backend fallback]</span><br><span class="line"></span><br><span class="line">Exception raised from reportError at ..\..\aten\src\ATen\core\dispatch\OperatorEntry.cpp:431 (most recent call first):</span><br><span class="line">00007FFEE7CAA29200007FFEE7CAA230 c10.dll!c10::Error::Error [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFEE7C843C500007FFEE7C84350 c10.dll!c10::NotImplementedError::NotImplementedError [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F015C7100007FFD5F015AA0 torch_cpu.dll!c10::impl::OperatorEntry::reportError [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F6C6AF000007FFD5F66DBB0 torch_cpu.dll!at::_ops::xlogy_Tensor::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8E73F100007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8E3F7400007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F6EB6E800007FFD5F6EB520 torch_cpu.dll!at::_ops::empty_strided::call [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5EF259CB00007FFD5EF258D0 torch_cpu.dll!at::empty_strided [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F2C24D100007FFD5F2C2130 torch_cpu.dll!at::native::_to_copy [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FA7C3D600007FFD5FA7BF10 torch_cpu.dll!at::compositeexplicitautograd::xlogy_ [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FA5A8FB00007FFD5FA3F310 torch_cpu.dll!at::compositeexplicitautograd::bitwise_xor_outf [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F4EB5AD00007FFD5F45B290 torch_cpu.dll!at::TensorMaker::make_tensor [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8DED7700007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8E36EB00007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F4EB5AD00007FFD5F45B290 torch_cpu.dll!at::TensorMaker::make_tensor [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F56326800007FFD5F563190 torch_cpu.dll!at::_ops::_to_copy::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD60A27F0000007FFD60A27A30 torch_cpu.dll!at::redispatch::_thnn_fused_lstm_cell_backward [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD60A4031D00007FFD60A34930 torch_cpu.dll!torch::jit::Node::c_ [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F50C12B00007FFD5F50BF70 torch_cpu.dll!at::_ops::_to_copy::call [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F2C2E7900007FFD5F2C2BD0 torch_cpu.dll!at::native::to_dense_backward [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F2C2B0C00007FFD5F2C29E0 torch_cpu.dll!at::native::to [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FB6A66800007FFD5FB63F10 torch_cpu.dll!at::compositeimplicitautograd::where [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FB4DB5D00007FFD5FB1BE50 torch_cpu.dll!at::compositeimplicitautograd::broadcast_to [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F7E6F4600007FFD5F7E6D70 torch_cpu.dll!at::_ops::to_dtype_layout::call [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5EF4AA8800007FFD5EF4A970 torch_cpu.dll!at::Tensor::to [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5EF9EAE900007FFD5EF9E9F0 torch_cpu.dll!at::tensor [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FF7714295A200007FF7714294B0 SplinterlandsSimulator.exe!main [C:\Users\xargo\source\repos\SplinterlandsSimulator\SplinterlandsSimulator\SplinterlandsSimulator.cpp @ 390]</span><br><span class="line">00007FF77144164C00007FF771441540 SplinterlandsSimulator.exe!__scrt_common_main_seh [d:\a01\_work\20\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl @ 288]</span><br><span class="line">00007FFF47C554E000007FFF47C554D0 KERNEL32.DLL!BaseThreadInitThunk [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFF48DA485B00007FFF48DA4830 ntdll.dll!RtlUserThreadStart [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br></pre></td></tr></table></figure><p>上述报错跟我的很像，而且从下面的回复来看，也是没能链接到 cuda 相应的库。下面的回复给我了启发：<strong>如果我的 go 程序没用到 libtorch 的 cuda 接口，是不是不会主动链接到 libtorch 相应的 cuda 的库</strong>？</p><p>前面说了，ldd 查看的确实没有，那怎么让编译器强制链接到 libtorch 的 cuda 相应的库呢？显然是的，编译器默认使用了 <code>--as-needed</code> 编译参数，这也是合理的，我们没必要链接所有的动态库，动态库本来就是按需链接，但是在我们的这个使用场景中，会遇到这种特殊情况，使用 <code>--no-as-needed</code> 强制链接到 libtorch cuda 的相应库，结果就没有问题了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--as-needed</span><br><span class="line">--no-as-needed</span><br><span class="line">This option affects ELF DT_NEEDED tags for dynamic libraries mentioned on the command line after the --as-needed option. Normally the linker will add a DT_NEEDED tag for each dynamic library mentioned on the command line, regardless of whether the library is actually needed or not. --as-needed causes a DT_NEEDED tag to only be emitted for a library that satisfies an undefined symbol reference from a regular object file or, if the library is not found in the DT_NEEDED lists of other libraries linked up to that point, an undefined symbol reference from another dynamic library. --no-as-needed restores the default behaviour.</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 libtorch 的 C++ 动态链接库遇到了一个非常诡异的问题…&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="link" scheme="https://murphypei.github.io/tags/link/"/>
    
      <category term="no-as-needed" scheme="https://murphypei.github.io/tags/no-as-needed/"/>
    
      <category term="undef" scheme="https://murphypei.github.io/tags/undef/"/>
    
  </entry>
  
  <entry>
    <title>shared_ptr 和 unique_ptr 深入探秘</title>
    <link href="https://murphypei.github.io//blog/2022/03/shared-unique-ptr.html"/>
    <id>https://murphypei.github.io//blog/2022/03/shared-unique-ptr.html</id>
    <published>2022-03-24T02:52:47.000Z</published>
    <updated>2025-06-25T02:00:04.070Z</updated>
    
    <content type="html"><![CDATA[<p>C++ 中 <code>shared_ptr</code> 和 <code>unique_ptr</code> 是 C++11 之后被广泛使用的两个智能指针，但是其实他们在使用上还是有一些“秘密”的，我根据平时遇到的两个问题，总结记录一些知识。</p><a id="more"></a><h3 id="为什么-unique-ptr-需要明确知道类型的析构函数"><a href="#为什么-unique-ptr-需要明确知道类型的析构函数" class="headerlink" title="为什么 unique_ptr 需要明确知道类型的析构函数"></a>为什么 unique_ptr 需要明确知道类型的析构函数</h3><p>这个问题是我写 <code>unique_ptr</code> 调试接口的时候才注意到的，之前确实不知道。为什么会这样呢？首先我们必须要知道 <code>unique_ptr</code> 到底封装了什么？通常 <code>unique_ptr</code> 就是简单的对裸指针封装，并且禁用拷贝和赋值：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">T</span>,</span></span><br><span class="line"><span class="class">    <span class="title">class</span> <span class="title">Deleter</span> = <span class="title">std</span>:</span>:default_delete&lt;T&gt;</span><br><span class="line">&gt; <span class="class"><span class="keyword">class</span> <span class="title">unique_ptr</span>;</span></span><br></pre></td></tr></table></figure><p>可以看到，<code>Deleter</code> 的类型是 <code>unique_ptr</code> 类型的一部分。在 <code>unique_ptr</code> 内部会保存类型为 <code>T*</code> 和 <code>Deleter</code> 的成员 ，分别表示保存的裸指针和删除器。假设内部是这么实现的 (一般会运用空基类优化把 <code>Deleter</code> 的空间优化掉，<code>libstdc++</code> 里把他们放进了一个 tuple。这里是简化了)：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T* p;</span><br><span class="line">    Deleter del;</span><br></pre></td></tr></table></figure><p>然后析构的时候就会这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~<span class="built_in">unique_ptr</span>()</span><br><span class="line">&#123;</span><br><span class="line">    del(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当 <code>Deleter</code> 是默认的 <code>std::default_delete</code> 时，<code>del(p)</code> 就会 <code>delete p</code>，<code>delete</code> 会调用析构函数。而 <code>delete</code> 一个不完整类型的指针是 ub(undefined behavior)。在典型的实现中都会在 <code>delete</code> 前通过 <code>static_assert(sizeof(T) &gt; 0)</code> 做检查。 <code>sizeof</code> 对 incomplete type 求值会直接编译出错。</p><blockquote><p>incomplete type 是指当定义一个变量的时候，不知道应该分配多少内存。C++ 声明和定义最大的区别就是是否发生内存分配，当发生内存分配的时候，必须知道要分配多少内存，通常一个未定义的 struct，未指定长度的数组类型，都会引发 incomplete type 的问题。参考：<a href="https://docs.microsoft.com/en-us/cpp/c-language/incomplete-types?view=msvc-170" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/cpp/c-language/incomplete-types?view=msvc-170</a></p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">student</span>;</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="keyword">sizeof</span>(student) &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><p>上述代码执行会报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prog.cc:17:18: error: invalid application of &apos;sizeof&apos; to an incomplete type &apos;student&apos;</span><br><span class="line">    std::cout &lt;&lt; sizeof(student) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>只声明了结构体 <code>student</code>，但是并没有定义，所以是一个 incomplete type，所以 <code>sizeof</code> 无法执行。</p><p>回到 <code>unique_ptr</code>，现在我们知道 <code>unique_ptr</code> 的报错链路是 <code>unique_ptr</code>-&gt;<code>delete</code>-&gt;<code>sizoef</code>，也就是 <code>sizeof</code> 才是罪魁祸首。所以当 <code>Deleter</code> 非默认时，就不一定需要知道类型的析构函数。比如下面这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A is incomplete type</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>;</span></span><br><span class="line"><span class="keyword">auto</span> Del = [] (A*) &#123; &#125;;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;A, <span class="keyword">decltype</span>(Del)&gt; ptr;</span><br></pre></td></tr></table></figure><p>因此可以对这个问题做定性：<strong>并不是 <code>unique_ptr</code> 需要知道析构函数，而是 <code>unique_ptr</code> 的默认删除器 <code>Deleter</code> 需要明确知道类型的析构函数</strong>。</p><p>继续深挖一下，这个问题会出现在 <code>shared_ptr</code> 吗？答案是<strong>不会</strong>。这又引入了另一个问题，shared_ptr 和 unique_ptr 的封装有什么不同？</p><h3 id="shared-ptr-的封装"><a href="#shared-ptr-的封装" class="headerlink" title="shared_ptr 的封装"></a>shared_ptr 的封装</h3><p>按理说 <code>shared_ptr.reset</code> 的时候需要 <code>delete</code> ptr 就需要 ptr 的类型（错了请指正），而 <code>shared_ptr</code> 的 template type 可以是 incomplete type（错误请指正）。cppreference 是这么描述的：</p><blockquote><p><code>std::shared_ptr</code> may be used with an incomplete typeT. However, the constructor from a raw pointer (template<class y> shared_ptr(Y<em>)) and the template<class y>void reset(Y</class></em>) member function may only be called with a pointer to a complete type (note that std::unique_ptr may be constructed from a raw pointer to an incomplete type).</class></p></blockquote><p><code>reset</code> 的时候需要类型完整。默认构造的时候允许是不完整类型。为什么会这样呢？<code>shared_ptr</code> 怎么处理 <code>Deleter</code> 呢？(还记得吧， Deleter 就是智能指针析构时候的删除操作)</p><p>在常见编译器的实现里，<code>shared_ptr</code> 把 <code>Deleter</code>（包括默认情况下的 operator delete）放进一个叫做 <strong>control block</strong> 的结构里，相当于做了一次 type erasure，把 <code>Deleter</code> 的类型从 <code>shared_ptr</code> 类型本身里面擦下去。<code>Deleter</code> 的类型在 control block 的具体类型上，<code>shared_ptr</code> 本身只<strong>持有一个 <code>control block</code> 基类的指针</strong>，通过虚函数来调用 <code>Deleter</code>。而因为 <code>shared_ptr</code> 构造的时候要求必须是 complete type，control block已经知道怎么析构了，<code>shared_ptr</code> 析构的时候就调用个虚函数，具体事情它不管的。</p><p>这下我们明白了，<code>unique_ptr</code> 的封装太简单了，没有 control block，<code>Deleter</code>（包括默认的std::default_delete）直接做在 <code>unique_ptr</code> 一起了，这就导致 <code>unique_ptr</code> 的析构函数需要亲手析构被管理的类型，因此析构函数必须看到 complete type。然而反过来，因为<strong>构建的时候只需要保存下指针，所以 <code>unique_ptr</code> 构造的时候不需要看到 complete type</strong>。这俩正好是反的。C++ 标准并没有规定这些实现细节，但是规定函数签名和特性的时候，是考虑着比较合理的实现方式来写标准的，到最后标准落下来之后也差不多只能这么实现了。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><code>unique_ptr</code> 只保存了类型指针 ptr 和这个指针的析构方法，调用 delete ptr，就需要ptr的完整类型，为了防止这个问题出现，直接通过 assert sizeof 排除掉了这种风险。<strong><code>unique_ptr</code> 相当于在编译时绑定了删除器</strong>。</li><li><code>shared_ptr</code> 保存的是一个控制块的指针。控制块包含的就是一个引用计数和一个原来对象的裸指针。控制块中初始化的指针是 <code>nullptr</code>，在运行时为其赋值，也可以通过 <code>reset</code> 修改。类似于虚函数，<strong><code>shared_ptr</code> 相当于在运行时绑定了删除器</strong>。</li></ul><p>虽然只是一个小小的知识点，但是也帮助我深入理解了 <code>shared_ptr</code> 和 <code>unique_ptr</code> 在设计上的区别，对于不同使用场景下选择不同智能指针的体会也更加深刻。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++ 中 &lt;code&gt;shared_ptr&lt;/code&gt; 和 &lt;code&gt;unique_ptr&lt;/code&gt; 是 C++11 之后被广泛使用的两个智能指针，但是其实他们在使用上还是有一些“秘密”的，我根据平时遇到的两个问题，总结记录一些知识。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="delete" scheme="https://murphypei.github.io/tags/delete/"/>
    
      <category term="c++" scheme="https://murphypei.github.io/tags/c/"/>
    
      <category term="shared_ptr" scheme="https://murphypei.github.io/tags/shared-ptr/"/>
    
      <category term="unique_ptr" scheme="https://murphypei.github.io/tags/unique-ptr/"/>
    
      <category term="template" scheme="https://murphypei.github.io/tags/template/"/>
    
  </entry>
  
  <entry>
    <title>使用 pyenv 搭建任意 python 环境</title>
    <link href="https://murphypei.github.io//blog/2022/01/pyenv-virtualenv.html"/>
    <id>https://murphypei.github.io//blog/2022/01/pyenv-virtualenv.html</id>
    <published>2022-01-13T02:47:20.000Z</published>
    <updated>2025-06-25T02:00:04.070Z</updated>
    
    <content type="html"><![CDATA[<p>开发和部署的过程中，常常遇到 python 版本和环境导致的冲突不兼容问题，pyenv 能够完美解决。</p><a id="more"></a><p>virtualenv 可以搭建虚拟且独立的 python 环境，可以使每个项目环境与其他项目独立开来，保持环境的干净，解决包冲突问题。但是这个依赖于已安装的 python 版本，相当于<strong>同一版本的不同环境</strong>。</p><p>pyenv 可以帮助你在一台开发机上建立多个版本的 python 环境，并提供方便的切换方法，可以搭配 virtualenv，完美解决 python 环境冲突，自由搭建任意版本的 python 环境。</p><h3 id="pyenv-安装"><a href="#pyenv-安装" class="headerlink" title="pyenv 安装"></a>pyenv 安装</h3><p><strong>安装 pyenv 之前建议卸载本机的 virtualenv 和 virtualenvwrapper 等相关虚拟环境</strong>，因为我从没用过 conda， 所以不清楚 conda 是否需要卸载。</p><ul><li><p>下载最新 pyenv </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/yyuu/pyenv.git ~/.pyenv</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.bashrc</span><br><span class="line">echo 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><blockquote><p>用 zsh 的改为 ~/.zshrc，下同</p></blockquote><ul><li>添加 pyenv 初始化到你的 shell</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 'eval "$(pyenv init -)"' &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><ul><li>重新启动你的 shell 使更改生效</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">exec $SHELL</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="安装某个版本的-python"><a href="#安装某个版本的-python" class="headerlink" title="安装某个版本的 python"></a>安装某个版本的 python</h3><p>首先我们可以查看一下有哪些版本的 python 可以安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv install --list</span><br></pre></td></tr></table></figure><p>一般情况下，几乎所有的 python 版本都可以安装，这也是 pyenv 强大之处。</p><ul><li>安装指定版本：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv install -v 3.9.9</span><br></pre></td></tr></table></figure><ul><li>安装完成后可以查看安装情况：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv versions</span><br></pre></td></tr></table></figure><p>一般输出如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* system (set by ~/.pyenv/version)</span><br><span class="line">3.9.9</span><br></pre></td></tr></table></figure><p>system 代表当前系统的 python 版本, 3.9.9 是我们用pyenv安装的, *表示当前的 python 版本， 可以看到，我们还在使用的是默认的 system 自带的 python 版本。</p><ul><li>切换 python 版本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pyenv global 3.9.9</span><br><span class="line"><span class="meta">#</span><span class="bash"> pyenv <span class="built_in">local</span> 3.9.9</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> pyenv shell 3.9.9</span></span><br></pre></td></tr></table></figure><p>上面三条命令都可以切换 python 版本，区别简单解释如下：</p><ul><li><code>pyenv global</code> 读写 <code>~/.python-version</code> 文件，基本来说你在当前 shell 和今后打开的 shell 中，默认都是用这个版本的 python。</li><li><code>pyenv local</code> 读写<strong>当前目录</strong>的 <code>.python-version</code> 文件，相当于覆盖了 <code>~/.python-version</code> 的版本。</li><li><code>pyenv shell</code> 指定当前 shell 使用的 python 版本，相当于覆盖了前面两个。</li></ul><p>此外设置 <code>PYENV_VERSION</code> 变量也可以修改 python 版本，看上去很杂很乱，但是多用几次就明白了。详细命令文档看这里：<a href="https://github.com/pyenv/pyenv/blob/master/COMMANDS.md" target="_blank" rel="noopener">pyenv commands</a></p><ul><li>卸载 python 版本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv uninstall 3.9.9</span><br></pre></td></tr></table></figure><h3 id="pyenv-中使用-virtualenv"><a href="#pyenv-中使用-virtualenv" class="headerlink" title="pyenv 中使用 virtualenv"></a>pyenv 中使用 virtualenv</h3><p>pyenv virtualenv 是 pyenv 的插件，为 UNIX 系统提供 pyenv virtualenv 命令。</p><ul><li>安装 pyenv-virtualenv</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv</span><br><span class="line">echo 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><ul><li>创建虚拟环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv virtualenv 3.9.9 env399</span><br></pre></td></tr></table></figure><blockquote><p>创建虚拟环境的 python 版本需要提前装好</p></blockquote><ul><li>激活环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv activate env399</span><br></pre></td></tr></table></figure><p>切换后查看一下 python 版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  system</span><br><span class="line">  3.9.9</span><br><span class="line">  3.9.9/envs/env399</span><br><span class="line">* env399 (set by PYENV_VERSION environment variable)</span><br></pre></td></tr></table></figure><ul><li>退出虚拟环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv deactivate</span><br></pre></td></tr></table></figure><ul><li>删除虚拟环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ~/.pyenv/versions/env399</span><br></pre></td></tr></table></figure><h3 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h3><ul><li>安装依赖</li></ul><p>自己谷歌查依赖的安装，我测试没遇到过。</p><ul><li>activate 激活不生效</li></ul><p>简单来说就是激活后 <code>pyenv versions</code> 显示生效了，<code>python version</code> 还是系统版本，暂时没找到具体原因，手动指定激活可以解决 <code>source ~/.pyenv/version/env399/bin/activate</code>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开发和部署的过程中，常常遇到 python 版本和环境导致的冲突不兼容问题，pyenv 能够完美解决。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://murphypei.github.io/categories/Python/"/>
    
    
      <category term="python" scheme="https://murphypei.github.io/tags/python/"/>
    
      <category term="virtualenv" scheme="https://murphypei.github.io/tags/virtualenv/"/>
    
      <category term="pyenv" scheme="https://murphypei.github.io/tags/pyenv/"/>
    
      <category term="activate" scheme="https://murphypei.github.io/tags/activate/"/>
    
  </entry>
  
  <entry>
    <title>SSH 穿越多个跳板机的连接方法</title>
    <link href="https://murphypei.github.io//blog/2021/12/ssh-proxyjump.html"/>
    <id>https://murphypei.github.io//blog/2021/12/ssh-proxyjump.html</id>
    <published>2021-12-27T02:40:42.000Z</published>
    <updated>2025-06-25T02:00:04.066Z</updated>
    
    <content type="html"><![CDATA[<p>鉴于安全原因，工作需要使用跳板机登录；鉴于服务器环境老旧，我需要在服务器上使用 docker 来搞个开发环境，所以需要有一种方法穿越层层阻隔，让我的 vscode 直接连过去。</p><a id="more"></a><h2 id="SSH-公钥和私钥"><a href="#SSH-公钥和私钥" class="headerlink" title="SSH 公钥和私钥"></a>SSH 公钥和私钥</h2><ul><li>首先搞清楚一些基本关系，一般使用密钥登录，<code>ssh-keygen -t rsa</code> 运行此命令产生公钥私钥（id_rsa 和 id_rsa.pub），一路回车可以不设置保护密码，假设要登录的机器是 server，登录的终端是 client，那么将公钥 id_rsa.pub 的内容记录在 server 的 authorized_keys 中，然后 client 使用私钥 id_rsa 登录。</li><li>每一个被登录的机器都开启的 ssh 服务，并配置了 ssh 密钥登录功能。对于我的需求来说，公司的跳板机和服务器一定是已经配置的，否则无法登录服务器，因此我还需要在 docker 中配置 ssh 密钥登录服务。</li><li>client 设置登录的层层专跳（这是重点）</li></ul><blockquote><p>ssh 相关的文件如果没有特殊说明，都是在 <code>~/.ssh</code> 文件夹中，ssh 服务的配置文件在 <code>/etc/ssh/sshd_config</code> 中。</p></blockquote><h2 id="openssh-的-ProxyJump"><a href="#openssh-的-ProxyJump" class="headerlink" title="openssh 的 ProxyJump"></a>openssh 的 ProxyJump</h2><p>在 openssh7.5 之后（ubuntu18.04），支持 ProxyJump 语句，非常方便。windows 不支持。</p><p>假设我们登录路径是这样的：</p><p>client-&gt;jump_server-&gt;server-&gt;dev_docker</p><p>那么 client 的 <code>~/.ssh/config</code> 文件应该如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Host jump</span><br><span class="line">    HostName &lt;jump_server ip&gt;</span><br><span class="line">    Port &lt;jump_server port&gt;</span><br><span class="line">    User &lt;jump_server username&gt;</span><br><span class="line">    IdentityFile &lt;jump_server id_rsa&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Host server</span><br><span class="line">    HostName &lt;server ip&gt;</span><br><span class="line">    Port &lt;server port&gt;</span><br><span class="line">    User &lt;server username&gt;</span><br><span class="line">    IdentityFile &lt;server id_rsa&gt;</span><br><span class="line">    ProxyJump jump</span><br><span class="line"></span><br><span class="line">Host dev_docker</span><br><span class="line">    HostName &lt;dev_docker ip&gt;</span><br><span class="line">    Port &lt;dev_docker port&gt;</span><br><span class="line">    User &lt;dev_docker username&gt;</span><br><span class="line">    IdentityFile &lt;dev_docker id_rsa&gt;</span><br><span class="line">    ProxyJump server</span><br></pre></td></tr></table></figure><p>然后在 client 中，直接使用 <code>ssh dev_docker</code> 命令，ssh 就会一步步登录过去。使用 <code>-v</code> 可以看到每一步的登录过程。</p><p>vscode 会自动读取 config 文件，就可以直接打开 docker 中的文件夹了。真的很方便。</p><p>还有两个比较实用的配置，同样是配置在客户端：</p><ul><li><code>ServerAliveInterval 60</code>：每隔 60s 服务器发送一个包看客户端是否有响应。</li><li><code>ServerAliveCountMax 600</code>：服务器发出请求后客户端没有响应的次数达到一定值，就自动断开，正常情况下，客户端不会不响应。</li></ul><p>这两个配置组合就可以保持 ssh 的长连接了，不用一直手动连接。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;鉴于安全原因，工作需要使用跳板机登录；鉴于服务器环境老旧，我需要在服务器上使用 docker 来搞个开发环境，所以需要有一种方法穿越层层阻隔，让我的 vscode 直接连过去。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://murphypei.github.io/categories/Linux/"/>
    
    
      <category term="linux" scheme="https://murphypei.github.io/tags/linux/"/>
    
      <category term="ssh" scheme="https://murphypei.github.io/tags/ssh/"/>
    
      <category term="proxy" scheme="https://murphypei.github.io/tags/proxy/"/>
    
      <category term="proxyjump" scheme="https://murphypei.github.io/tags/proxyjump/"/>
    
      <category term="jump" scheme="https://murphypei.github.io/tags/jump/"/>
    
  </entry>
  
  <entry>
    <title>C++ 使用 protobuf 踩坑的一次记录</title>
    <link href="https://murphypei.github.io//blog/2021/12/protobuf-debug.html"/>
    <id>https://murphypei.github.io//blog/2021/12/protobuf-debug.html</id>
    <published>2021-12-01T02:40:42.000Z</published>
    <updated>2025-06-25T02:00:04.062Z</updated>
    
    <content type="html"><![CDATA[<p>之前用 protobuf 都比较随意，直到用 protobuf 发布 SDK，遇到了一个坑，恰好遇到了手机的一些问题，导致连环坑。</p><a id="more"></a><h2 id="坑1："><a href="#坑1：" class="headerlink" title="坑1："></a>坑1：</h2><p>这个坑很常见，不仅仅对于我，大概情况如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[libprotobuf ERROR /home/murphy/code/github/protobuf/src/google/protobuf/descriptor_database.cc:58] File already exists <span class="keyword">in</span> database: speech_ai.capt.proto[libprotobuf FATAL /home/murphy/code/github/protobuf/src/google/protobuf/descriptor.cc:1358] CHECK failed: GeneratedDatabase()-&gt;Add(encoded_file_descriptor, size): terminating with uncaught exception of <span class="built_in">type</span> google::protobuf::FatalException: CHECK failed: GeneratedDatabase()-&gt;Add(encoded_file_descriptor, size)</span><br></pre></td></tr></table></figure><p>这个错误原因是因为在两个编译目标（共享库或者可执行文件）中都引入了相同的 <code>*.pb.cc</code> 文件。举个例子：</p><ul><li>我们有个 <code>example.proto</code>，生成了 <code>example.pb.h</code> 和 <code>example.pb.cc</code> 两个文件。</li><li>首先编译一个共享库 <code>A.so</code>，编译的时候需要加入 <code>example.pb.cc</code> 文件，因为其中包含了函数定义。</li><li>编译一个可执行文件 <code>B.out</code>，用来测试 <code>A.so</code> 的接口是否合适，因为 <code>B.out</code> 中也用到了 <code>example.pb.cc</code> 中的函数定义，所以按照常规的想法，也需要加入到其中编译（不然会报 undefined reference 错误），并且 <code>B.out</code> 需要链接 <code>A.so</code>。</li></ul><p>如果这种常规做法，就会报上面类似的错误，我查询的原因可以总结如下（也怪我学艺不精，不太了解 protobuf 的内部机制）：<strong>protobuf 本身有一个 global 的 registry。每个 message type 都需要去那里注册一下，而且不能重复注册</strong>。上述的 <code>Add</code> 错误就是因为注册失败，原因就是因为 <code>A.so</code> 和 <code>B.out</code> 中重复注册了（两份 <code>pb.cc</code> 实现）。</p><ul><li>据说换成 protobuf-lite 就能避免这个问题，但是 Google 官方并没有对此表态。</li></ul><p>最常规的解决办法就是把所有 <code>pb.cc</code> 文件编译成一个共享库 <code>p.so</code>，然后 <code>A.so</code> 和 <code>B.out</code> 都去链接这个共享库。这里需要注意，编译的时候需要设置 <code>visibility=default</code>，把符号都打开（一般 SDK 都会隐藏符号）。</p><h2 id="坑2："><a href="#坑2：" class="headerlink" title="坑2："></a>坑2：</h2><p>这个坑很奇怪，大概如下：我使用 ndk 和 protobuf v3.6.1 编译了 android 的 <code>libprotobuf.so</code>，然后用这个共享库编译 android native 测序程序，运行遇到 Version verification failed，大概如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[libprotobuf FATAL /home/murphy/code/github/protobuf/src/google/protobuf/stubs/common.cc:79] This program was compiled against version 3.0.0 of the Protocol Buffer runtime library, <span class="built_in">which</span> is not compatible with the installed version (3.6.1).  Contact the program author <span class="keyword">for</span> an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed <span class="keyword">in</span> <span class="string">"external/protobuf/src/google/protobuf/any.pb.cc"</span>.)terminating with uncaught exception of <span class="built_in">type</span> google::protobuf::FatalException: This program was compiled against version 3.0.0 of the Protocol Buffer runtime library, <span class="built_in">which</span> is not compatible with the installed version (3.6.1).  Contact the program author <span class="keyword">for</span> an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed <span class="keyword">in</span> <span class="string">"external/protobuf/src/google/protobuf/any.pb.cc"</span>.)</span><br></pre></td></tr></table></figure><p>在 android 使用 gdbserver 调试发现（<a href="https://murphypei.github.io/blog/2021/09/android-gdbserver.html">教程</a>），<code>/system/lib64/</code> 下面有个 <code>protobuf.so</code>，这个 so 的版本是 v3.0.0，但是我们编译的程序理论上是用 v3.6.1 编译的。看上去这里运行的时候，链接的是 v3.6.1，但是 v3.6.1 的符号没有覆盖默认的 v3.0.0 的符号，导致 <code>GOOGLE_PROTOBUF_VERSION</code> 这个符号变成了 <code>3000000</code> 而不是 <code>3006001</code>，所以就会失败。</p><p>这个问题没有找到解决方案，我换了一个测试手机，没有复现这个问题，所以猜测可能是之前的测试手机有一些问题，如果遇到这个问题，建议换个测试手机试试。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前用 protobuf 都比较随意，直到用 protobuf 发布 SDK，遇到了一个坑，恰好遇到了手机的一些问题，导致连环坑。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="registry" scheme="https://murphypei.github.io/tags/registry/"/>
    
      <category term="protobuf" scheme="https://murphypei.github.io/tags/protobuf/"/>
    
      <category term="共享库" scheme="https://murphypei.github.io/tags/%E5%85%B1%E4%BA%AB%E5%BA%93/"/>
    
      <category term="protoc" scheme="https://murphypei.github.io/tags/protoc/"/>
    
  </entry>
  
  <entry>
    <title>使用 vscode 调试 C++ 程序</title>
    <link href="https://murphypei.github.io//blog/2021/11/vscode-cpp.html"/>
    <id>https://murphypei.github.io//blog/2021/11/vscode-cpp.html</id>
    <published>2021-11-04T03:00:28.000Z</published>
    <updated>2025-06-25T02:00:04.062Z</updated>
    
    <content type="html"><![CDATA[<p>vscode 远程比 clion 好用太多了，就是 C++ 调试功能不如 clion，不过简单配置一下，也可以实现单步调试，比简陋的 GDB 还是好用多了。</p><a id="more"></a><p>下面的配置是我的某个项目的配置，仅仅作为参考和自己的记录，因为国内大部分的教程都只写单独的文件，没啥参考价值。</p><h3 id="c-cpp-properties-json"><a href="#c-cpp-properties-json" class="headerlink" title="c_cpp_properties.json"></a>c_cpp_properties.json</h3><p>这个文件主要是配置一些头文件路径，不过现在 vscode 对于头文件的支持还是不太行，配置了还有很多波浪线，头疼。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"configurations"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"Linux"</span>,</span><br><span class="line">            <span class="attr">"includePath"</span>: [</span><br><span class="line">                <span class="string">"$&#123;workspaceFolder&#125;/**"</span>,</span><br><span class="line">                <span class="string">"$&#123;workspaceFolder&#125;/build"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"defines"</span>: [],</span><br><span class="line">            <span class="attr">"configurationProvider"</span>: <span class="string">"ms-vscode.cmake-tools"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"version"</span>: <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="tasks-json"><a href="#tasks-json" class="headerlink" title="tasks.json"></a>tasks.json</h3><p>这个文件是执行真正的任务，主要是编译任务。以前我以为只支持 g++ 命令（坑爹的国内教程），后来想通了，这个文件其实就是执行 linux 命令，你可以放 cmake、make 甚至编译脚本的命令，我通常喜欢写一个编译脚本来编译。</p><p>下面的例子，cmake 和 make 执行编译，build 通过脚本编译。make 任务可以不需要 cmake 重新生成（关闭 dependsOn），方便快速增量编译。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"version"</span>: <span class="string">"2.0.0"</span>,</span><br><span class="line">    <span class="attr">"tasks"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"label"</span>: <span class="string">"cmake"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="attr">"options"</span>: &#123;</span><br><span class="line">                <span class="attr">"cwd"</span>: <span class="string">"$&#123;workspaceFolder&#125;/build"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"command"</span>: <span class="string">"cmake -DCMAKE_BUILD_TYPE=Debug -DBUILD_ANDROID=OFF -DBUILD_UNIT_TESTS=ON -DBUILD_SHARED_LIBS=ON -DCUDA_ENABLE=OFF .. "</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"label"</span>: <span class="string">"make"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="attr">"options"</span>: &#123;</span><br><span class="line">                <span class="attr">"cwd"</span>: <span class="string">"$&#123;workspaceFolder&#125;/build"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"command"</span>: <span class="string">"make -j8"</span>,</span><br><span class="line">            // "dependsOn": [</span><br><span class="line">            //     "cmake"</span><br><span class="line">            // ],</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"label"</span>: <span class="string">"build"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="attr">"command"</span>: <span class="string">"source $&#123;workspaceFolder&#125;/linux.sh"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="launch-json"><a href="#launch-json" class="headerlink" title="launch.json"></a>launch.json</h3><p>用 GDB 执行可执行文件，没啥说的，注意 preLaunchTask 根据需要选择（tasks.json 中配置的 build 彻底重新编译，make 只编译改动的头文件）。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    // 使用 IntelliSense 了解相关属性。 </span><br><span class="line">    // 悬停以查看现有属性的描述。</span><br><span class="line">    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span><br><span class="line">    "version": "0.2.0",</span><br><span class="line">    "configurations": [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"capt_test"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"cppdbg"</span>,</span><br><span class="line">            <span class="attr">"request"</span>: <span class="string">"launch"</span>,</span><br><span class="line">            <span class="attr">"program"</span>: <span class="string">"$&#123;workspaceFolder&#125;/build/capt_test"</span>,</span><br><span class="line">            <span class="attr">"args"</span>: [],</span><br><span class="line">            <span class="attr">"stopAtEntry"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"cwd"</span>: <span class="string">"$&#123;workspaceFolder&#125;"</span>,</span><br><span class="line">            <span class="attr">"environment"</span>: [],</span><br><span class="line">            <span class="attr">"externalConsole"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"MIMode"</span>: <span class="string">"gdb"</span>,</span><br><span class="line">            <span class="attr">"setupCommands"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">"description"</span>: <span class="string">"为 gdb 启用整齐打印"</span>,</span><br><span class="line">                    <span class="attr">"text"</span>: <span class="string">"-enable-pretty-printing"</span>,</span><br><span class="line">                    <span class="attr">"ignoreFailures"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            // "preLaunchTask": "make"</span><br><span class="line">            "preLaunchTask": "build"</span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;vscode 远程比 clion 好用太多了，就是 C++ 调试功能不如 clion，不过简单配置一下，也可以实现单步调试，比简陋的 GDB 还是好用多了。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="c++" scheme="https://murphypei.github.io/tags/c/"/>
    
      <category term="vscode" scheme="https://murphypei.github.io/tags/vscode/"/>
    
      <category term="tasks" scheme="https://murphypei.github.io/tags/tasks/"/>
    
      <category term="launch" scheme="https://murphypei.github.io/tags/launch/"/>
    
      <category term="c_cpp_properties" scheme="https://murphypei.github.io/tags/c-cpp-properties/"/>
    
  </entry>
  
  <entry>
    <title>语音识别 FBank 和 MFCC 特征</title>
    <link href="https://murphypei.github.io//blog/2021/10/asr-fbank-mfcc.html"/>
    <id>https://murphypei.github.io//blog/2021/10/asr-fbank-mfcc.html</id>
    <published>2021-10-13T04:21:07.000Z</published>
    <updated>2025-06-25T02:00:04.058Z</updated>
    
    <content type="html"><![CDATA[<p>ASR 流程中，音频特征提取是第一步。和 CV 不同，图片本身的 RGB 数值就是一种特征，但是音频本身无法被用于分析，常常是将一段音频提取 FBank 和 MFCC 特征然后作为模型的输入。</p><a id="more"></a><p>语音参数提取特征的步骤：预增强-&gt;分帧-&gt;加窗-&gt;添加噪声-&gt;FFT-&gt;Mel滤波-&gt;对数运算-&gt;DCT。其中 FFT 和 DCT 是快速傅里叶变换和离散余弦变换。</p><h2 id="音频预处理"><a href="#音频预处理" class="headerlink" title="音频预处理"></a>音频预处理</h2><h3 id="预增强（Pre-Emphasis）"><a href="#预增强（Pre-Emphasis）" class="headerlink" title="预增强（Pre-Emphasis）"></a>预增强（Pre-Emphasis）</h3><p>预增强一般是数字语音信号处理的第一步。语音信号往往会有频谱倾斜（Spectral Tilt）现象，即高频部分的幅度会比低频部分的小，预增强在这里就是起到一个平衡频谱的作用，增大高频部分的幅度。它使用如下的一阶滤波器来实现：</p><script type="math/tex; mode=display">y(t) = x(t) - \alpha * x(t-1), 0.95 < \alpha < 0.99</script><h3 id="分帧（Framing）"><a href="#分帧（Framing）" class="headerlink" title="分帧（Framing）"></a>分帧（Framing）</h3><p>输入的音频信号是一段连续，一般流式的有几百毫秒，非流式的有几秒或者更长，需要将信号分成短时帧。做这一步的原因是：信号中的频率会随时间变化（不稳定的），一些信号处理算法（比如傅里叶变换）通常希望信号是稳定，也就是说对整个信号进行处理是没有意义的，因为信号的频率轮廓会随着时间的推移而丢失。为了避免这种情况，需要对信号进行分帧处理，认为每一帧之内的信号是短时不变的。一般设置帧长取 20ms~40ms，相邻帧之间 50\%（+/-10\%）的覆盖。对于 ASR 而言，通常取帧长为 25ms，帧移为 10ms（不重叠部分）。</p><h3 id="加窗"><a href="#加窗" class="headerlink" title="加窗"></a>加窗</h3><p>在分帧之后，通常需要对每帧的信号进行加窗处理。目的是让帧两端平滑地衰减，这样可以降低后续傅里叶变换后旁瓣的强度，取得更高质量的频谱。常用的窗有：矩形窗、汉明（Hamming）窗、汉宁窗（Hanning），以汉明窗为例，其窗函数为：</p><script type="math/tex; mode=display">w(n)=0.54-0.46cos(\frac{2\pi n}{N-1}), 0\le n\le N-1</script><h3 id="随机添加噪声（可选）"><a href="#随机添加噪声（可选）" class="headerlink" title="随机添加噪声（可选）"></a>随机添加噪声（可选）</h3><p>有时候我们需要进行数据增强，会手动合成一些音频。某些人工合成的音频可能会造成一些数字错误，诸如 underflow 或者 overflow。 这种情况下，通过添加随机噪声可以解决这一类问题。公式如下：</p><script type="math/tex; mode=display">s(n)=s(n)+q∗rand()</script><p>$q$ 用于控制添加噪声的强度，$rand()$ 产生 $[-1.0, 1.0)$ 的随机数。</p><p>注意：Kaldi 中是在分帧之后的下一步添加随机噪声</p><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p>人耳对声音频谱的响应是非线性的，经验表明：如果我们能够设计一种前端处理算法，以类似于人耳的方式对音频进行处理，可以提高语音识别的性能。FilterBank就是这样的一种算法。FBank 特征提取要在预处理之后进行，这时语音已经分帧，我们需要逐帧提取 FBank 特征。</p><h3 id="快速傅里叶变换（FFT）"><a href="#快速傅里叶变换（FFT）" class="headerlink" title="快速傅里叶变换（FFT）"></a>快速傅里叶变换（FFT）</h3><p>我们分帧之后得到的仍然是时域信号，为了提取 FBank 特征，首先需要<strong>将时域信号转换为频域信号</strong>。傅里叶变换可以将信号从时域转到频域。傅里叶变换可以分为连续傅里叶变换和离散傅里叶变换，因为我们用的是数字音频（而非模拟音频），所以我们用到的是离散傅里叶变换。数学公式如下：</p><script type="math/tex; mode=display">X(k)=\sum_{j=1}^{N} x(j)w_{N}^{(j-1)(k-1)}</script><p>对每一帧加窗后的音频信号做 N 点的 FFT 变换，也称短时傅里叶变换（STFT），N通常取256或512，然后用如下的公式<strong>计算能量谱</strong>：</p><script type="math/tex; mode=display">P=\frac{|FFT(x_i)|^2}{N}</script><h3 id="FBank-Filter-Banks-特征"><a href="#FBank-Filter-Banks-特征" class="headerlink" title="FBank(Filter Banks)特征"></a>FBank(Filter Banks)特征</h3><p>经过上面的步骤之后，在能量谱上应用 Mel 滤波器组，就能提取到FBank特征。</p><p>在介绍Mel滤波器组之前，先介绍一下 Mel 刻度，这是一个能模拟人耳接收声音规律的刻度，人耳在接收声音时呈现非线性状态，对高频的更不敏感，因此 Mel 刻度在低频区分辨度较高，在高频区分辨度较低，与频率之间的换算关系为：</p><script type="math/tex; mode=display">m=2595log_{10}(1+\frac{f}{700})</script><p>Mel 滤波器组就是一系列的三角形滤波器，通常有 40 个或 80 个，在中心频率点响应值为 1，在两边的滤波器中心点线性衰减到 0，如下图：</p><p><img src="/images/posts/asr/fbank_mfcc/mel.jpg" alt></p><p>具体公式就不写了，网上可查。</p><p>在能量谱上应用 Mel 滤波器组，其公式为：</p><script type="math/tex; mode=display">Y_{t}(m)=\sum_{k=1}^{N} H_{m}(k)|X_t(k)|^2</script><p>其中，$k$ 表示 FFT 变换后的编号，$m$ 表示 Mel 滤波器的编号。</p><h3 id="MFCC-Mel-frequency-Cepstral-Coefficients-特征"><a href="#MFCC-Mel-frequency-Cepstral-Coefficients-特征" class="headerlink" title="MFCC(Mel-frequency Cepstral Coefficients)特征"></a>MFCC(Mel-frequency Cepstral Coefficients)特征</h3><p>前面提取到的 FBank 特征，往往是高度相关的。因此可以继续用 DCT 变换，将这些相关的滤波器组系数进行压缩。对于 ASR 来说，通常取 2~13 维，扔掉的信息里面包含滤波器组系数快速变化部分，这些细节信息在 ASR 任务上可能没有帮助。</p><p><strong>DCT 变换其实是逆傅里叶变换的等价替代</strong>：</p><script type="math/tex; mode=display">y_t(n)=\sum_{m=0}^{M-1}log(Y_{t}(m))cos(n(m+0.5)\frac{\pi }{M}), n=0,...,J</script><p>所以 MFCC 名字里面有倒谱（Cepstral）。</p><p>一般对于ASR来说，对 MFCC 进行一个正弦提升（sinusoidal liftering）操作，可以提升在噪声信号中最后的识别率：</p><script type="math/tex; mode=display">MFCC_i^{'}=w_iMFCC_i</script><script type="math/tex; mode=display">w_i=\frac{D}{2}sin(\frac{\pi * i}{D})</script><p>从公式看，猜测原因可能是对频谱做一个平滑，如果 $D$ 取值较大时，会加重高频部分，使得噪声被弱化。</p><h3 id="python-实现"><a href="#python-实现" class="headerlink" title="python 实现"></a>python 实现</h3><p><a href="https://gist.github.com/murphypei/dcae63c9de780586a70a89603bd0f2c2" target="_blank" rel="noopener">https://gist.github.com/murphypei/dcae63c9de780586a70a89603bd0f2c2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ASR 流程中，音频特征提取是第一步。和 CV 不同，图片本身的 RGB 数值就是一种特征，但是音频本身无法被用于分析，常常是将一段音频提取 FBank 和 MFCC 特征然后作为模型的输入。&lt;/p&gt;
    
    </summary>
    
      <category term="ASR" scheme="https://murphypei.github.io/categories/ASR/"/>
    
    
      <category term="fbank" scheme="https://murphypei.github.io/tags/fbank/"/>
    
      <category term="mfcc" scheme="https://murphypei.github.io/tags/mfcc/"/>
    
      <category term="asr" scheme="https://murphypei.github.io/tags/asr/"/>
    
      <category term="fft" scheme="https://murphypei.github.io/tags/fft/"/>
    
  </entry>
  
  <entry>
    <title>使用 gdbserver 调试 Android Native 程序</title>
    <link href="https://murphypei.github.io//blog/2021/09/android-gdbserver.html"/>
    <id>https://murphypei.github.io//blog/2021/09/android-gdbserver.html</id>
    <published>2021-09-06T09:40:10.000Z</published>
    <updated>2025-06-25T02:00:04.054Z</updated>
    
    <content type="html"><![CDATA[<p>使用 Android NDK 编译得到 Android native program，可以直接 push 到手机上运行，但是没办法直接用 gdb debug。</p><a id="more"></a><p>为此，我们需要使用 gdbserver，也就是 gdb 远程调试功能。原理就不讲了，我自己尝试的过程中发现网上写的教程都是相互转载的，乱七八糟，不知所云。本文写原理（谷歌可查），仅仅记录下我已经确认可行的调试过程。</p><ol><li>首先，把 <code>$NDK/prebuilt/android-arm64/gdbserver/gdbserver</code> 以及要调试的程序 push 到手机上（任意文件夹）。</li><li>在手机上启动 gdbserver。<code>gdbserver :9090 &lt;exec&gt;</code>。其中 <code>:9090</code> 表示 gdbserver 监听手机的 9090 端口。会显示 <code>Listening on port 9090</code> 类似信息。如果有本地 lib，记得设置 <code>LD_LIBRARY_PATH</code> 环境变量。</li><li>设置端口转发。<code>adb forward tcp:9090 tcp:9090</code>，表示将本地 9090 端口转发到手机的 9090 端口。</li><li>本地启动 gdb。<code>$NDK/prebuilt/linux-x86_64/bin/gdb</code>。进入 gdb 调试页面。</li><li>设置调试对象。<code>target remote :9090</code>。调试本地的 9090 端口，同时也是手机的 9090 端口，也就是 gdbserver，连接成功之后， gdbserver 那边会显示 <code>Remote debugging from host 127.0.0.1</code> 字样。</li></ol><p>Android gdbserver 和 Linux gdb 有一些命令不太一样，但是很多还是相同的。启动程序不用 r，用 continue。</p><p>用 vscode 也可以，把上述流程弄到 vscode 的 task.json 中就行，只是觉得更麻烦了，所以没必要。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 Android NDK 编译得到 Android native program，可以直接 push 到手机上运行，但是没办法直接用 gdb debug。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="gdbserver" scheme="https://murphypei.github.io/tags/gdbserver/"/>
    
      <category term="gdb remote" scheme="https://murphypei.github.io/tags/gdb-remote/"/>
    
      <category term="android" scheme="https://murphypei.github.io/tags/android/"/>
    
      <category term="native" scheme="https://murphypei.github.io/tags/native/"/>
    
  </entry>
  
  <entry>
    <title>LRU 缓存算法</title>
    <link href="https://murphypei.github.io//blog/2021/07/lru.html"/>
    <id>https://murphypei.github.io//blog/2021/07/lru.html</id>
    <published>2021-07-07T10:49:24.000Z</published>
    <updated>2025-06-25T02:00:04.054Z</updated>
    
    <content type="html"><![CDATA[<p>看到 lc 上有一道题是设计 LRU 算法，简单了解了一下作为记录。</p><a id="more"></a><p>LRU 算法实际上是让你设计数据结构：首先要接收一个 capacity 参数作为缓存的最大容量，然后实现两个 API，一个是 <code>put(key, val)</code> 方法存入键值对，另一个是 <code>get(key)</code> 方法获取 key 对应的 val，如果 key 不存在则返回 -1。</p><p>注意哦，get 和 put 方法必须都是 O(1) 的时间复杂度，我们举个具体例子来看看 LRU 算法怎么工作。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 缓存容量为 2 */</span></span><br><span class="line">LRUCache cache = <span class="keyword">new</span> LRUCache(<span class="number">2</span>);</span><br><span class="line"><span class="comment">// 你可以把 cache 理解成一个队列</span></span><br><span class="line"><span class="comment">// 假设左边是队头，右边是队尾</span></span><br><span class="line"><span class="comment">// 最近使用的排在队头，久未使用的排在队尾</span></span><br><span class="line"><span class="comment">// 圆括号表示键值对 (key, val)</span></span><br><span class="line"></span><br><span class="line">cache.put(<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// cache = [(1, 1)]</span></span><br><span class="line">cache.put(<span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line"><span class="comment">// cache = [(2, 2), (1, 1)]</span></span><br><span class="line">cache.get(<span class="number">1</span>);       <span class="comment">// 返回 1</span></span><br><span class="line"><span class="comment">// cache = [(1, 1), (2, 2)]</span></span><br><span class="line"><span class="comment">// 解释：因为最近访问了键 1，所以提前至队头</span></span><br><span class="line"><span class="comment">// 返回键 1 对应的值 1</span></span><br><span class="line">cache.put(<span class="number">3</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">// cache = [(3, 3), (1, 1)]</span></span><br><span class="line"><span class="comment">// 解释：缓存容量已满，需要删除内容空出位置</span></span><br><span class="line"><span class="comment">// 优先删除久未使用的数据，也就是队尾的数据</span></span><br><span class="line"><span class="comment">// 然后把新的数据插入队头</span></span><br><span class="line">cache.get(<span class="number">2</span>);       <span class="comment">// 返回 -1 (未找到)</span></span><br><span class="line"><span class="comment">// cache = [(3, 3), (1, 1)]</span></span><br><span class="line"><span class="comment">// 解释：cache 中不存在键为 2 的数据</span></span><br><span class="line">cache.put(<span class="number">1</span>, <span class="number">4</span>);    </span><br><span class="line"><span class="comment">// cache = [(1, 4), (3, 3)]</span></span><br><span class="line"><span class="comment">// 解释：键 1 已存在，把原始值 1 覆盖为 4</span></span><br><span class="line"><span class="comment">// 不要忘了也要将键值对提前到队头</span></span><br></pre></td></tr></table></figure><p>我们分析一下这个实现要求。查询和插入都需要 O(1)，那不用说了，只能是哈希表。C++ 可以用 <code>std::unordered_map</code> 实现。再看这个缓存满的时候，需要删除最久为使用的，所以每个元素必须在每次操作之后保持其顺序。这个实现比较灵活了，但是因为涉及 O(1) 插入，所以 <code>std::list</code> 是最合适的。总结：</p><ul><li>通过 key 查询和插入 O(1)，哈希表，但是哈希表无顺序。</li><li>链表可保持顺序，插入和删除 O(1)，但是查询慢。</li></ul><p>因此就需要将二者结合使用，也就是<strong>哈希链表</strong>。具体实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;list&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    LRUCache(<span class="keyword">int</span> capacity) : capacity(capacity) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hashTable.find(key) == hashTable.end())</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 更新到表头</span></span><br><span class="line">            <span class="keyword">auto</span> iter = hashTable[key]; <span class="comment">// 找到对应地址</span></span><br><span class="line">            cache.splice(cache.begin(), cache, iter); <span class="comment">// 移动到表头</span></span><br><span class="line">            <span class="keyword">return</span> cache.begin()-&gt;second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hashTable.find(key) == hashTable.end())</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (cache.size() == capacity)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// 删除表尾</span></span><br><span class="line">                hashTable.erase(cache.back().first);</span><br><span class="line">                cache.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 在表头添加</span></span><br><span class="line">            cache.push_front(<span class="built_in">std</span>::make_pair(key, value));</span><br><span class="line">            hashTable[key] = cache.begin();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">auto</span> iter    = hashTable[key];</span><br><span class="line">            iter-&gt;second = value; <span class="comment">// 更新元素</span></span><br><span class="line">            cache.splice(cache.begin(), cache, iter); <span class="comment">// 移动到表头</span></span><br><span class="line">            hashTable[key] = cache.begin(); <span class="comment">// 更新地址</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;::iterator&gt; hashTable;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;                                    cache; <span class="comment">// key, value</span></span><br><span class="line">    <span class="keyword">int</span>                                                               capacity = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>具体操作就很简单了，无非是哈希表和链表的查询、删除和移动。主要看成员变量 <code>hashTable</code> 和 <code>cache</code>。<code>cache</code> 保存的就是实际数据的 key 和 value，<code>hashTable</code> 保存链表的 key 和地址。</p><p>通过哈希表，我们能够弥补链表查询慢的特点，直取链表中 key 所在节点的位置。而通过链表，我们可以很容易的维持每次操作后元素的顺序。这里有一个需要注意的，<strong>链表中必须也存有 key</strong>，因为哈希表删除是需要 key 的，链表如果只能提供 value，哈希表将无法删除。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看到 lc 上有一道题是设计 LRU 算法，简单了解了一下作为记录。&lt;/p&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://murphypei.github.io/categories/Algorithm/"/>
    
    
      <category term="algorithm" scheme="https://murphypei.github.io/tags/algorithm/"/>
    
      <category term="LRU" scheme="https://murphypei.github.io/tags/LRU/"/>
    
      <category term="缓存" scheme="https://murphypei.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
      <category term="哈希表" scheme="https://murphypei.github.io/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    
      <category term="链表" scheme="https://murphypei.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
  <entry>
    <title>Floyd 环形算法</title>
    <link href="https://murphypei.github.io//blog/2021/07/floyd-circle.html"/>
    <id>https://murphypei.github.io//blog/2021/07/floyd-circle.html</id>
    <published>2021-07-06T03:01:04.000Z</published>
    <updated>2025-06-25T02:00:04.050Z</updated>
    
    <content type="html"><![CDATA[<p>题目来自 leetcode 142. 环形链表 II，判断一个链表是否有环，如果有，找到环形起点。</p><a id="more"></a><p>首先是链表判断是否有环，刷过题的都知道快慢指针，快指针一次移动两步，慢指针一次移动一步，如果两个指针最终相遇则有环，如果快指针到达终点，则无环。</p><p>计算环形起点一般使用 Floyld 算法。接上面，两指针相遇之后，将慢指针移动到链表头部，然后两个指针每次移动一步，再次相遇就是环形起点。这个算法简洁明了，非常简单，但是需要思考一下证明方法。</p><p>假设链表头到环形起点的距离是 $m$，也就是非环部分；链表环长度为 $n$；相遇的时候距离环形起点的位置为 $k$。</p><p>慢指针相遇的时候移动距离：$m + A \cdot n + k$，快指针相遇的时候移动距离：$m + B \cdot n + k$。</p><p>因为快指针是慢指针的二倍，因此：</p><script type="math/tex; mode=display">S = (B - A) \cdot n = m + B \cdot n + k</script><p>$B$ 和 $A$ 都是正整数，因此<strong>相遇时慢指针移动的总长度是环形的整倍数</strong>，快指针是慢指针的 2 倍，因此快指针走过的总长度也是环形的整倍数。</p><p>现在把慢指针移动到链表头部，然后移动 $m$ 步，到达了环形的起点，慢指针移动 $S + m$，快指针移动 $2 \cdot S + m$，$S$ 是环形长度的整倍数，因此快指针此时也一定是到达了环形的起点，两个指针相遇。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;题目来自 leetcode 142. 环形链表 II，判断一个链表是否有环，如果有，找到环形起点。&lt;/p&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://murphypei.github.io/categories/Algorithm/"/>
    
    
      <category term="algorithm" scheme="https://murphypei.github.io/tags/algorithm/"/>
    
      <category term="floyld" scheme="https://murphypei.github.io/tags/floyld/"/>
    
      <category term="环形算法" scheme="https://murphypei.github.io/tags/%E7%8E%AF%E5%BD%A2%E7%AE%97%E6%B3%95/"/>
    
      <category term="快慢指针" scheme="https://murphypei.github.io/tags/%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88/"/>
    
      <category term="弗洛伊德" scheme="https://murphypei.github.io/tags/%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7/"/>
    
  </entry>
  
  <entry>
    <title>Golang 中 context 的使用方式</title>
    <link href="https://murphypei.github.io//blog/2021/06/go-context.html"/>
    <id>https://murphypei.github.io//blog/2021/06/go-context.html</id>
    <published>2021-06-06T18:45:28.000Z</published>
    <updated>2025-06-25T02:00:04.046Z</updated>
    
    <content type="html"><![CDATA[<p>context 是 go 中控制协程的一种比较方便的方式。</p><a id="more"></a><h3 id="Select-Chan"><a href="#Select-Chan" class="headerlink" title="Select + Chan"></a>Select + Chan</h3><p>我们都知道一个 goroutine 启动后，我们是无法控制他的，大部分情况是等待它自己结束，那么如果这个 goroutine 是一个不会自己结束的后台 goroutine 呢？比如监控等，会一直运行的。</p><p>这种情况下比较笨的办法是全局变量，其他地方通过修改这个变量完成结束通知，然后后台 goroutine 不停的检查这个变量，如果发现被通知关闭了，就自我结束。这种方式首先我们要保证这个变量在多线程下的安全，基于此，有一种经典的处理方式：<code>chan</code> + <code>select</code> 。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">stop := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">bool</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-stop:    <span class="comment">// 收到了停滞信号</span></span><br><span class="line">fmt.Println(<span class="string">"监控退出，停止了..."</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">fmt.Println(<span class="string">"goroutine监控中..."</span>)</span><br><span class="line">time.Sleep(<span class="number">2</span> * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line">time.Sleep(<span class="number">10</span> * time.Second)</span><br><span class="line">fmt.Println(<span class="string">"可以了，通知监控停止"</span>)</span><br><span class="line">stop&lt;- <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//为了检测监控过是否停止，如果没有监控输出，就表示停止了</span></span><br><span class="line">time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>这里还有一个额外的知识，go 中通道的接收是有阻塞和非阻塞的（发送只有阻塞），这里 select 中的 case 语句接收通道数据其实是非阻塞的。非阻塞接收通道数据的 CPU 消耗较高，但是可以获取是否通道中有数据的状态。但是当 case 上读一个通道时，如果这个通道是 nil，则该 case 永远阻塞</p></blockquote><p>例子中我们定义一个 stop 的 chan，通知他结束后台 goroutine。实现也非常简单，在后台 goroutine 中，使用 select 判断 stop 是否可以接收到值，如果可以接收到，就表示可以退出停止了；如果没有接收到，就会执行 default 里的监控逻辑，继续监控，只到收到 stop 的通知。</p><p>有了以上的逻辑，我们就可以在其他 goroutine 中，给 stop chan 发送值了，例子中是在 main goroutine 中发送的，控制让这个监控的 goroutine 结束。</p><p>发送了 <code>stop&lt;-true</code> 结束的指令后，我这里使用 <code>time.Sleep(5 * time.Second)</code> 故意停顿5秒来检测我们结束监控 goroutine 是否成功。如果成功的话，不会再有 <code>goroutine监控中...</code> 的输出了；如果没有成功，监控 goroutine 就会继续打印 <code>goroutine监控中...</code> 输出。</p><p>这种 chan+select 的方式，是比较优雅的结束一个 goroutine 的方式，不过这种方式也有局限性，如果有很多 goroutine 都需要控制结束怎么办呢？如果这些 goroutine 又衍生了其他更多的 goroutine 怎么办呢？如果一层层的无穷尽的 goroutine 呢？这就非常复杂了，即使我们定义很多 chan 也很难解决这个问题，因为 goroutine 的关系链就导致了这种场景非常复杂。</p><h3 id="Context"><a href="#Context" class="headerlink" title="Context"></a>Context</h3><p>上面说的这种场景是存在的，比如一个网络请求 Request，每个 Request 都需要开启一个 goroutine 做一些事情，这些 goroutine 又可能会开启其他的 goroutine。所以我们需要一种可以跟踪 goroutine 的方案，才可以达到控制他们的目的，这就是 Go 语言为我们提供的 Context，称之为上下文非常贴切，它就是 goroutine 的上下文。</p><p>下面我们就使用 Go Context 重写上面的示例。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(ctx context.Context)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">fmt.Println(<span class="string">"监控退出，停止了..."</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">fmt.Println(<span class="string">"goroutine监控中..."</span>)</span><br><span class="line">time.Sleep(<span class="number">2</span> * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;(ctx)</span><br><span class="line"></span><br><span class="line">time.Sleep(<span class="number">10</span> * time.Second)</span><br><span class="line">fmt.Println(<span class="string">"可以了，通知监控停止"</span>)</span><br><span class="line">cancel()</span><br><span class="line"><span class="comment">//为了检测监控过是否停止，如果没有监控输出，就表示停止了</span></span><br><span class="line">time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重写也很简单，把之前使用 select+chan 控制的协程改为 Context 控制即可：</p><p><code>context.Background()</code> 返回一个空的 Context，这个空的 Context 一般用于整个 Context 树的根节点。然后我们使用 <code>context.WithCancel(parent)</code> 函数，创建一个可取消的子 Context，然后当作参数传给 goroutine 使用，这样就可以使用这个子 Context 跟踪这个 goroutine。</p><p>在 goroutine 中，使用 select 调用 <code>&lt;-ctx.Done()</code> 判断是否要结束，如果接受到值的话，就可以返回结束 goroutine 了；如果接收不到，就会继续进行监控。</p><p>那么 Context 是如何发送结束指令的呢？这就是示例中的 <code>cancel</code> 函数啦，它是我们调用 <code>context.WithCancel(parent)</code> 函数生成子 Context 的时候返回的，第二个返回值就是这个取消函数，它是 <code>CancelFunc</code> 类型的。我们调用它就可以发出取消指令，然后我们的监控 goroutine 就会收到信号，就会返回结束。</p><h3 id="Context-控制多个-goroutine"><a href="#Context-控制多个-goroutine" class="headerlink" title="Context 控制多个 goroutine"></a>Context 控制多个 goroutine</h3><p>使用 Context 控制一个 goroutine 的例子如上，非常简单，下面我们看看控制多个 goroutine 的例子，其实也比较简单。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line"><span class="keyword">go</span> watch(ctx,<span class="string">"【监控1】"</span>)</span><br><span class="line"><span class="keyword">go</span> watch(ctx,<span class="string">"【监控2】"</span>)</span><br><span class="line"><span class="keyword">go</span> watch(ctx,<span class="string">"【监控3】"</span>)</span><br><span class="line"></span><br><span class="line">time.Sleep(<span class="number">10</span> * time.Second)</span><br><span class="line">fmt.Println(<span class="string">"可以了，通知监控停止"</span>)</span><br><span class="line">cancel()</span><br><span class="line"><span class="comment">//为了检测监控过是否停止，如果没有监控输出，就表示停止了</span></span><br><span class="line">time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">watch</span><span class="params">(ctx context.Context, name <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">fmt.Println(name,<span class="string">"监控退出，停止了..."</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">fmt.Println(name,<span class="string">"goroutine监控中..."</span>)</span><br><span class="line">time.Sleep(<span class="number">2</span> * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>示例中启动了 3 个监控 goroutine 进行不断的监控，每一个都使用了 Context 进行跟踪，<strong>当我们使用 cancel 函数通知取消时，这 3 个 goroutine 都会被结束</strong>。这就是 Context 的控制能力，它就像一个控制器一样，按下开关后，<strong>所有基于这个 Context 或者衍生的子 Context 都会收到通知</strong>，这时就可以进行清理操作了，最终释放 goroutine，这就优雅的解决了 goroutine 启动后不可控的问题。</p><h3 id="Context-接口"><a href="#Context-接口" class="headerlink" title="Context 接口"></a>Context 接口</h3><p>Context 的接口定义的比较简洁，我们看下这个接口的方法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Context <span class="keyword">interface</span> &#123;</span><br><span class="line">Deadline() (deadline time.Time, ok <span class="keyword">bool</span>)</span><br><span class="line"></span><br><span class="line">Done() &lt;-<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">Err() error</span><br><span class="line"></span><br><span class="line">Value(key <span class="keyword">interface</span>&#123;&#125;) <span class="keyword">interface</span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个接口共有 4 个方法，了解这些方法的意思非常重要，这样我们才可以更好的使用他们。</p><p><code>Deadline</code> 方法是获取设置的截止时间的意思，第一个返回式是截止时间，到了这个时间点，Context 会自动发起取消请求；第二个返回值 <code>ok</code> 表示是否设置截止时间，如果没有设置时间，当需要取消的时候，需要调用取消函数进行取消。</p><p><code>Done</code> 方法返回一个只读的 chan，类型为 struct{}，我们在 goroutine 中，如果该方法返回的 chan 可以读取，则意味着 parent context 已经发起了取消请求，我们通过 Done 方法收到这个信号后，就应该做清理操作，然后退出 goroutine，释放资源。</p><p><code>Err</code> 方法返回取消的错误原因，因为什么 Context 被取消。</p><p><code>Value</code> 方法获取该 Context 上绑定的值，是一个键值对，所以要通过一个 Key 才可以获取对应的值，这个值一般是线程安全的。</p><p>以上四个方法中常用的就是 <code>Done</code> 了，如果 Context 取消的时候，我们就可以得到一个关闭的 chan，关闭的 chan 是可以读取的，所以<strong>只要 <code>ctx.Done()</code> 可以读取的时候，就意味着收到 Context 取消的信号了</strong>，以下是这个方法的经典用法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Stream</span><span class="params">(ctx context.Context, out <span class="keyword">chan</span>&lt;- Value)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">v, err := DoSomething(ctx)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line"><span class="keyword">return</span> ctx.Err()</span><br><span class="line"><span class="keyword">case</span> out &lt;- v:</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Context 接口并不需要我们实现，Go 内置已经帮我们实现了 2 个，我们代码中最开始都是以这两个内置的作为最顶层的 partent context，衍生出更多的子 Context。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">background = <span class="built_in">new</span>(emptyCtx)</span><br><span class="line">todo       = <span class="built_in">new</span>(emptyCtx)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Background</span><span class="params">()</span> <span class="title">Context</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> background</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">TODO</span><span class="params">()</span> <span class="title">Context</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> todo</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一个是 <code>Background</code>，主要用于 main 函数、初始化以及测试代码中，作为 Context 这个树结构的最顶层的 Context，也就是根 Context。</p><p>一个是 <code>TODO</code>，它目前还不知道具体的使用场景，如果我们不知道该使用什么 Context 的时候，可以使用这个。</p><p>他们两个本质上都是 emptyCtx 结构体类型，是一个不可取消，没有设置截止时间，没有携带任何值的 Context。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> emptyCtx <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Deadline</span><span class="params">()</span> <span class="params">(deadline time.Time, ok <span class="keyword">bool</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Done</span><span class="params">()</span> &lt;-<span class="title">chan</span> <span class="title">struct</span></span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Err</span><span class="params">()</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(*emptyCtx)</span> <span class="title">Value</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">interface</span></span>&#123;&#125; &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Context-的继承衍生"><a href="#Context-的继承衍生" class="headerlink" title="Context 的继承衍生"></a>Context 的继承衍生</h3><p>有了如上的根 Context，那么是如何衍生更多的子 Context 的呢？这就要靠 context 包为我们提供的 With 系列的函数了。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">WithCancel</span><span class="params">(parent Context)</span> <span class="params">(ctx Context, cancel CancelFunc)</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">WithDeadline</span><span class="params">(parent Context, deadline time.Time)</span> <span class="params">(Context, CancelFunc)</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">WithTimeout</span><span class="params">(parent Context, timeout time.Duration)</span> <span class="params">(Context, CancelFunc)</span></span></span><br><span class="line"><span class="function"><span class="title">func</span> <span class="title">WithValue</span><span class="params">(parent Context, key, val <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">Context</span></span></span><br></pre></td></tr></table></figure><p>这四个 With 函数，接收的都有一个 <code>partent</code> 参数，就是父 Context，我们要基于这个父 Context 创建出子 Context 的意思，这种方式可以理解为子 Context 对父 Context 的继承，也可以理解为基于父 Context 的衍生。</p><p>通过这些函数，就创建了一颗 Context 树，树的每个节点都可以有任意多个子节点，节点层级可以有任意多个。每个父节点可以控制自己所有的子节点。</p><ul><li><code>WithCancel</code> 函数，传递一个父 Context 作为参数，返回子 Context，以及一个取消函数用来取消 Context。 </li><li><code>WithDeadline</code> 函数，和 <code>WithCancel</code> 差不多，它会多传递一个截止时间参数，意味着到了这个时间点，会自动取消 Context，当然我们也可以不等到这个时候，可以提前通过取消函数进行取消。</li><li><code>WithTimeout</code> 和 <code>WithDeadline</code> 基本上一样，这个表示是超时自动取消，是多少时间后自动取消 Context 的意思。</li><li><code>WithValue</code> 函数和取消 Context 无关，它是为了生成一个绑定了一个键值对数据的 Context，这个绑定的数据可以通过 Context.Value方法访问到，后面我们会专门讲。</li></ul><p>大家可能留意到，前三个函数都返回一个取消函数 CancelFunc，这是一个函数类型，它的定义非常简单。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> CancelFunc <span class="function"><span class="keyword">func</span><span class="params">()</span></span></span><br></pre></td></tr></table></figure><p>这就是取消函数的类型，该函数可以取消一个 Context，以及这个节点 Context 下所有的所有的 Context，不管有多少层级。</p><h3 id="WithValue-传递元数据"><a href="#WithValue-传递元数据" class="headerlink" title="WithValue 传递元数据"></a>WithValue 传递元数据</h3><p>通过 Context 我们也可以传递一些必须的元数据，这些数据会附加在 Context 上以供使用。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> key <span class="keyword">string</span>=<span class="string">"name"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">ctx, cancel := context.WithCancel(context.Background())</span><br><span class="line"><span class="comment">//附加值</span></span><br><span class="line">valueCtx:=context.WithValue(ctx,key,<span class="string">"【监控1】"</span>)</span><br><span class="line"><span class="keyword">go</span> watch(valueCtx)</span><br><span class="line">time.Sleep(<span class="number">10</span> * time.Second)</span><br><span class="line">fmt.Println(<span class="string">"可以了，通知监控停止"</span>)</span><br><span class="line">cancel()</span><br><span class="line"><span class="comment">//为了检测监控过是否停止，如果没有监控输出，就表示停止了</span></span><br><span class="line">time.Sleep(<span class="number">5</span> * time.Second)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">watch</span><span class="params">(ctx context.Context)</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line"><span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line"><span class="comment">//取出值</span></span><br><span class="line">fmt.Println(ctx.Value(key),<span class="string">"监控退出，停止了..."</span>)</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="comment">//取出值</span></span><br><span class="line">fmt.Println(ctx.Value(key),<span class="string">"goroutine监控中..."</span>)</span><br><span class="line">time.Sleep(<span class="number">2</span> * time.Second)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在前面的例子，我们通过传递参数的方式，把 <code>name</code> 的值传递给监控函数。在这个例子里，我们实现一样的效果，但是通过的是 Context 的 Value 的方式。</p><p>我们可以使用 <code>context.WithValue</code> 方法附加一对 K-V 的键值对，这里 Key 必须是等价性的，也就是具有可比性；Value 值要是线程安全的。</p><p>这样我们就生成了一个新的 Context，这个新的 Context 带有这个键值对，在使用的时候，可以通过 Value 方法读取 <code>ctx.Value(key)</code>。</p><p>记住，使用 WithValue 传值，一般是必须的值，不要什么值都传递。</p><h3 id="Context-使用原则"><a href="#Context-使用原则" class="headerlink" title="Context 使用原则"></a>Context 使用原则</h3><ul><li>不要把 Context 放在结构体中，要以参数的方式传递。</li><li>以 Context 作为参数的函数方法，应该把 Context 作为第一个参数，放在第一位。</li><li>给一个函数方法传递 Context 的时候，不要传递 nil，如果不知道传递什么，就使用 <code>context.TODO</code>。</li><li>Context 的 Value 相关方法应该传递必须的数据，不要什么数据都使用这个传递。</li><li>Context 是线程安全的，可以放心的在多个 goroutine 中传递。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;context 是 go 中控制协程的一种比较方便的方式。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="https://murphypei.github.io/categories/Golang/"/>
    
    
      <category term="golang" scheme="https://murphypei.github.io/tags/golang/"/>
    
      <category term="context" scheme="https://murphypei.github.io/tags/context/"/>
    
      <category term="goroutine" scheme="https://murphypei.github.io/tags/goroutine/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch distributed barrier 引发的陷阱</title>
    <link href="https://murphypei.github.io//blog/2021/05/torch-barrier-trap.html"/>
    <id>https://murphypei.github.io//blog/2021/05/torch-barrier-trap.html</id>
    <published>2021-05-20T07:17:19.000Z</published>
    <updated>2025-06-25T02:00:04.046Z</updated>
    
    <content type="html"><![CDATA[<p>Pytorch 中 <code>torch.distributed.barrier</code> 函数通常用于分布式进程同步，但是使用也存在一个陷阱。</p><a id="more"></a><p>记录一个最近使用 Pytorch 分布式遇到的一个问题。</p><p>熟悉 Pytorch 的同学一定知道 <code>torch.distributed.barrier</code> 是用于不同进程间的同步，其原理很简单，就是<strong>每个进程进入这个函数后都会被阻塞，当所有进程都进入这个函数后，阻塞解除</strong>，继续向下执行。废话不多说，直接说重点：<strong>所有进程都执行到这一步</strong>。也就是说如果有些代码是某个进程单独执行，并且不小心包含了这条语句，那么这个进程陷入无限等待。</p><p>直接看我的<strong>错误例子</strong>：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_dataloader = create_dataloader(rank, ...)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> rank <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">0</span>]:</span><br><span class="line">    val_dataloader = create_dataloader(rank, ...)</span><br></pre></td></tr></table></figure><p><code>create_dataloader</code> 内部：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_dataloader</span><span class="params">(rank, ...)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> torch_distributed_zero_first(rank):</span><br><span class="line">        dataset = Dataset(...)</span><br><span class="line">    </span><br><span class="line">    dataloader = foo(dataset)</span><br><span class="line">    <span class="keyword">return</span> dataloader</span><br></pre></td></tr></table></figure></p><p><code>torch_distributed_zero_first(rank)</code> 是一个 contextmanager，其用法就是用 <code>@contextmanager</code> 语法糖修饰一个生成器，使其能够按照 <code>with ...</code> 形式执行。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@contextmanager</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">torch_distributed_zero_first</span><span class="params">(rank)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> rank <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">-1</span>, <span class="number">0</span>]:</span><br><span class="line">        torch.distributed.barrier()</span><br><span class="line">    <span class="keyword">yield</span></span><br><span class="line">    <span class="keyword">if</span> rank == <span class="number">0</span>:</span><br><span class="line">        torch.distributed.barrier()</span><br></pre></td></tr></table></figure></p><p>contextmanager，其用法就是用执行顺序是：</p><ol><li>首先<code>with</code> 语句先执行生成器内部代码，遇到 <code>yield</code> 之后返回（如果有返回值则就是 <code>with ... as ...</code> 中 as 的值）。</li><li>继续执行 <code>with</code> 嵌套的语句（如上就是创建 Dataset），执行完毕回到生成器。</li><li>执行 <code>yield</code> 后面的语句。</li></ol><p>首先说明一下，使用 <code>torch_distributed_zero_first</code> 的目的是执行创建 dataloader 的时候，期望主进程能够先执行，这样可以创建一些缓存之类的文件，让后续进程直接读取缓存，加快顺序，这是出发点。我们看一下运行原理：首先 <code>create_dataloader</code> 中 <code>with torch_distributed_zero_first(rank):</code> 调用会让除了主进程以外的其他进程进入阻塞，只有主进程会继续在 <code>yield</code> 执行的时候返回，执行嵌套语句，创建 Dataset，然后再次进入生成器，调用 barrier。这时候所有进程进入了 barrier 函数，因此所有一起被唤醒，继续向下执行。因此这样确保所有进程中主进程最先执行了嵌套语句。</p><p>弄明白了上述的工作原理，再看 <code>val_dataloader</code> 的创建过程，其问题出在<strong>只有主进程执行了这个调用</strong>。因此按照上述分析，主进程创建完 Dataset 之后，被阻塞，此时其他进程并未被阻塞，因此主进程陷入无限阻塞（后续如果恰好其他进程执行到 barrier 或许可以解除）。因此这里应该传入 <code>rank=-1</code>，跳过 if 后面的 barrier。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Pytorch 中 &lt;code&gt;torch.distributed.barrier&lt;/code&gt; 函数通常用于分布式进程同步，但是使用也存在一个陷阱。&lt;/p&gt;
    
    </summary>
    
      <category term="PyTorch" scheme="https://murphypei.github.io/categories/PyTorch/"/>
    
    
      <category term="pytorch" scheme="https://murphypei.github.io/tags/pytorch/"/>
    
      <category term="distribute" scheme="https://murphypei.github.io/tags/distribute/"/>
    
      <category term="barrier" scheme="https://murphypei.github.io/tags/barrier/"/>
    
      <category term="DDP" scheme="https://murphypei.github.io/tags/DDP/"/>
    
  </entry>
  
  <entry>
    <title>C++ sizeof 总结</title>
    <link href="https://murphypei.github.io//blog/2021/03/cpp-sizeof.html"/>
    <id>https://murphypei.github.io//blog/2021/03/cpp-sizeof.html</id>
    <published>2021-03-09T09:02:13.000Z</published>
    <updated>2025-06-25T02:00:04.038Z</updated>
    
    <content type="html"><![CDATA[<p>sizeof 是很老的知识，从笔记移到博文中。</p><a id="more"></a><p>计算机取数据最低一个字节，基本都是双字，因此如果数据没有对齐，有时候一个数可能分布在多个字节中，内存对齐是为了加快计算机的取数速度，否则就得多花指令周期。关于内存对齐，可以参考<a href="https://murphypei.github.io/blog/2020/04/memory-align.html">浅谈内存对齐</a>。下面是 sizeof 的一些对齐知识。</p><h4 id="对齐基本规则"><a href="#对齐基本规则" class="headerlink" title="对齐基本规则"></a>对齐基本规则</h4><ul><li>结构体变量的首地址能够被其最宽基本类型成员的大小所整除。</li><li>结构体每个成员相对于结构体首地址的偏移量（offset）都是成员大小的整数倍，如有需要编译器会在成员之间加上填充字节（internal adding）。</li><li>结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节（trailing padding）。</li></ul><h4 id="sizeof-类或者结构体"><a href="#sizeof-类或者结构体" class="headerlink" title="sizeof 类或者结构体"></a>sizeof 类或者结构体</h4><ul><li>sizeof 结构体以及类的实例是同一结果，sizeof 类本质上就是计算类的实例大小。</li><li>sizeof 一个空类（或者空结构体），结果是 1。空类，没有任何成员变量或函数，即没有存储任何内容，所以大小为 0，但是由于空类仍然可以实例化，一个类能够实例化，编译器就需给它分配内存空间，来指示类实例的地址，所以编译器就为类默认添加了一个隐藏的字节。</li><li>sizeof 只考虑类的成员变量，不需要考虑成员函数，<strong>但是虚函数会增加虚表指针的空间（虚表指针在对象内存的首位置）。</strong></li><li>类的静态成员变量不计入 sizeof 大小。</li><li>子类继承了父类的私有成员，子类虽然不能访问，但是 sizeof 仍需要计算这一部分。<ul><li>子类继承一个空类，sizeof 则大小为子类的大小（子类也是空类，则 sizeof 为 1）</li></ul></li><li>当上述的类<strong>虚继承</strong>一个空类（是不是空都无所谓），那么虚继承的子类中需要<strong>添加一个虚基类指针</strong>（虚继承就是类似虚函数的实现来实现基类共享）</li><li>多继承中如果多个父类有虚函数，则会有多个虚函数表，子类自己定义的虚函数不会生成虚函数表，单继承时并入父类的虚表，多继承时并入继承的第一个父类的虚表中。</li></ul><h4 id="sizeof-数组"><a href="#sizeof-数组" class="headerlink" title="sizeof 数组"></a>sizeof 数组</h4><ul><li>sizeof 数组和指针是不一样的，sizeof 计算的是数组的大小。</li><li>C 风格的 char 数组，如果不指定数组的长度，计算结果是字符个数 +1，包含 \0 的结束位。    </li></ul><h4 id="sizeof-union"><a href="#sizeof-union" class="headerlink" title="sizeof union"></a>sizeof union</h4><p>联合体的内存是重叠的，则 sizeof 就是最大数据成员的大小。</p><h4 id="利用-sizeof-获取结构体某个成员的偏移量"><a href="#利用-sizeof-获取结构体某个成员的偏移量" class="headerlink" title="利用 sizeof 获取结构体某个成员的偏移量"></a>利用 sizeof 获取结构体某个成员的偏移量</h4><p>思路：将 0 地址转换为结构体的指针，然后获取成员的地址即偏移量</p><p><code>#define offsetof(s,m) (size_t)&amp;(((s *)0)-&gt;m)</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;sizeof 是很老的知识，从笔记移到博文中。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="sizeof" scheme="https://murphypei.github.io/tags/sizeof/"/>
    
  </entry>
  
  <entry>
    <title>C++ 中 malloc 和 new 的区别</title>
    <link href="https://murphypei.github.io//blog/2021/03/malloc-new-diff.html"/>
    <id>https://murphypei.github.io//blog/2021/03/malloc-new-diff.html</id>
    <published>2021-03-09T08:58:07.000Z</published>
    <updated>2025-06-25T02:00:04.042Z</updated>
    
    <content type="html"><![CDATA[<p>C++ 中 malloc 和 new 都能开辟内存，这篇笔记记录 C++ 中 malloc 和 new 开辟新内存的区别。</p><a id="more"></a><h4 id="申请内存的位置不同："><a href="#申请内存的位置不同：" class="headerlink" title="申请内存的位置不同："></a>申请内存的位置不同：</h4><ul><li><strong>new 操作符从自由存储区（free store）上为对象动态分配内存空间</strong>，自由存储区是 C++ 基于 new 操作符的一个抽象概念，凡是通过 new 操作符进行内存申请，该内存即为自由存储区。自由存储区不仅可以是堆，还可以是静态存储区，这都    看 operator new 在哪里为对象分配内存。</li><li><strong>malloc 函数从堆上动态分配内存</strong>。</li></ul><h4 id="返回类型的安全性"><a href="#返回类型的安全性" class="headerlink" title="返回类型的安全性"></a>返回类型的安全性</h4><ul><li>new 操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故 new 是符合类型安全性的操作符。</li><li>malloc 内存分配成功则是返回 void 指针 ，需要通过强制类型转换将 void 指针转换成我们需要的类型。</li></ul><h4 id="内存分配失败时的返回值"><a href="#内存分配失败时的返回值" class="headerlink" title="内存分配失败时的返回值"></a>内存分配失败时的返回值</h4><ul><li>new 内存分配失败时，会抛出 bac_alloc 异常，它不会返回 NULL。</li><li>malloc 分配失败时返回 NULL。</li></ul><h4 id="分配内存大小"><a href="#分配内存大小" class="headerlink" title="分配内存大小"></a>分配内存大小</h4><ul><li>使用 new 操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。</li><li>malloc 则需要明确指出所需内存的尺寸。</li></ul><h4 id="是否调用构造函数-析构函数"><a href="#是否调用构造函数-析构函数" class="headerlink" title="是否调用构造函数/析构函数"></a>是否调用构造函数/析构函数</h4><ul><li>使用 new 操作符来分配对象内存时会经历三个步骤：<ol><li>调用 operator new 函数（对于数组是 operator new[]）分配一块足够大的，原始的，未命名的内存空间以便存储特定类型的对象。</li><li>编译器运行相应的构造函数以构造对象，并为其传入初值。</li><li>对象构造完成后，返回一个指向该对象的指针。</li></ol></li><li>使用 delete 操作符来释放对象内存时会经历两个步骤：<ol><li>调用对象的析构函数。</li><li>编译器调用operator delete(或operator delete[])函数释放内存空间。</li></ol></li><li>malloc不会调用构造函数，free也不会调用析构函数。</li></ul><h4 id="对于数组的处理"><a href="#对于数组的处理" class="headerlink" title="对于数组的处理"></a>对于数组的处理</h4><ul><li>C++ 提供了 new[] 与 delete[] 来专门处理数组类型的分配。new 对数组的支持体现在它会分别调用构造函数函数初始化每一个数组元素，释放对象时为每个对象调用析构函数。</li><li>注意 delete[] 要与 new[] 配套使用，不然会找出数组对象部分释放的现象，造成内存泄漏。</li><li>malloc 并知道你在这块内存上要放的数组还是啥别的东西，反正它就给你一块原始的内存，在给你个内存的地址就完事。所以如果要动态分配一个数组的内存，还需要我们手动自定数组的大小</li></ul><h4 id="是否可以被重载"><a href="#是否可以被重载" class="headerlink" title="是否可以被重载"></a>是否可以被重载</h4><p>opeartor new /operator delete 可以被重载。注意，new 表达式和 operator new 是不同的，前者调用后者，严格来说，我们区分的是 new 表达式和 malloc 表达式，所以应该都不支持重载。</p><h4 id="是否支持内存扩充"><a href="#是否支持内存扩充" class="headerlink" title="是否支持内存扩充"></a>是否支持内存扩充</h4><ul><li>new 不支持内存扩充</li><li>malloc 在分配内存后，如果内存不足，可以<strong>使用 realloc 进行内存重新分配</strong>，实现扩充。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++ 中 malloc 和 new 都能开辟内存，这篇笔记记录 C++ 中 malloc 和 new 开辟新内存的区别。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="delete" scheme="https://murphypei.github.io/tags/delete/"/>
    
      <category term="new" scheme="https://murphypei.github.io/tags/new/"/>
    
      <category term="malloc" scheme="https://murphypei.github.io/tags/malloc/"/>
    
      <category term="operator new" scheme="https://murphypei.github.io/tags/operator-new/"/>
    
      <category term="free" scheme="https://murphypei.github.io/tags/free/"/>
    
  </entry>
  
</feed>
