<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>拾荒志</title>
  
  <subtitle>虚怀若谷，大智若愚</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://murphypei.github.io/"/>
  <updated>2025-07-23T12:02:52.150Z</updated>
  <id>https://murphypei.github.io/</id>
  
  <author>
    <name>AngryBirds</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LLM 训练：ZeRO 技术详解</title>
    <link href="https://murphypei.github.io//blog/2025/07/llm-zero.html"/>
    <id>https://murphypei.github.io//blog/2025/07/llm-zero.html</id>
    <published>2025-07-22T22:08:12.000Z</published>
    <updated>2025-07-23T12:02:52.150Z</updated>
    
    <content type="html"><![CDATA[<p>在大语言模型（LLM）训练中，显存不足是一个普遍存在的问题。随着模型规模的不断增长，单个 GPU 的显存容量成为了训练大规模模型的主要瓶颈。DeepSpeed ZeRO（Zero Redundancy Optimizer）技术通过创新的数据分片策略，有效解决了这一问题，使得我们能够训练远超单卡显存上限的超大规模模型。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>随着大语言模型规模的快速增长，显存需求呈指数级增长。传统的分布式训练方法虽然能够利用多 GPU 进行训练，但每个 GPU 仍然需要存储完整的模型参数、梯度和优化器状态，这严重限制了可训练的模型规模。</p><p>ZeRO 技术通过<strong>数据并行</strong>与<strong>内存优化</strong>的结合，将模型训练中的大块数据（优化器状态、梯度和模型参数）分散到不同的 GPU 上，而非在每个 GPU 上都完整存储一份，从而显著降低了每个 GPU 的显存需求。</p><h2 id="ZeRO-技术原理"><a href="#ZeRO-技术原理" class="headerlink" title="ZeRO 技术原理"></a>ZeRO 技术原理</h2><h3 id="传统数据并行的问题"><a href="#传统数据并行的问题" class="headerlink" title="传统数据并行的问题"></a>传统数据并行的问题</h3><p>在传统的数据并行训练中，每个 GPU 都需要存储：</p><ol><li><strong>模型参数</strong>：完整的模型权重</li><li><strong>梯度</strong>：完整的梯度信息</li><li><strong>优化器状态</strong>：如 Adam 优化器的动量、方差等状态</li></ol><p>对于大规模模型，这些数据占用的显存非常庞大。例如，一个 175B 参数的模型使用 Adam 优化器时，仅优化器状态就需要约 700GB 显存（每个参数需要 4 个 float32 值）。</p><h3 id="ZeRO-的核心思想"><a href="#ZeRO-的核心思想" class="headerlink" title="ZeRO 的核心思想"></a>ZeRO 的核心思想</h3><p>ZeRO 的核心思想是<strong>消除冗余存储</strong>，通过分片技术将原本每个 GPU 都需要存储的完整数据分散到多个 GPU 上，实现显存的线性扩展。</p><p><strong>关键洞察</strong>：</p><ul><li>在数据并行中，不同 GPU 上的模型参数是相同的</li><li>梯度在反向传播后需要进行 All-Reduce 操作</li><li>优化器状态与参数一一对应</li></ul><p>基于这些观察，ZeRO 提出了分阶段的内存优化策略。</p><h2 id="ZeRO-的三个阶段"><a href="#ZeRO-的三个阶段" class="headerlink" title="ZeRO 的三个阶段"></a>ZeRO 的三个阶段</h2><h3 id="ZeRO-Stage-1：优化器状态分片（Optimizer-State-Sharding）"><a href="#ZeRO-Stage-1：优化器状态分片（Optimizer-State-Sharding）" class="headerlink" title="ZeRO-Stage 1：优化器状态分片（Optimizer State Sharding）"></a>ZeRO-Stage 1：优化器状态分片（Optimizer State Sharding）</h3><p><strong>原理</strong>：<br>将优化器状态分片存储在不同的 GPU 上，每个 GPU 只存储部分优化器状态。</p><p><strong>具体做法</strong>：</p><ul><li>假设有 $N$ 个 GPU，模型参数为 $P$</li><li>将优化器状态分成 $N$ 个分片，每个 GPU 存储 $P/N$ 个参数对应的优化器状态</li><li>在参数更新时，每个 GPU 只更新自己负责的那部分参数</li></ul><p><strong>内存节省</strong>：</p><ul><li>优化器状态内存减少 $N$ 倍</li><li>对于 Adam 优化器，每个参数需要 4 个 float32 值，节省效果显著</li></ul><h3 id="ZeRO-Stage-2：梯度分片（Gradient-Sharding）"><a href="#ZeRO-Stage-2：梯度分片（Gradient-Sharding）" class="headerlink" title="ZeRO-Stage 2：梯度分片（Gradient Sharding）"></a>ZeRO-Stage 2：梯度分片（Gradient Sharding）</h3><p><strong>原理</strong>：<br>在 Stage 1 的基础上，进一步将梯度分片存储。</p><p><strong>具体做法</strong>：</p><ul><li>每个 GPU 只计算和存储部分梯度</li><li>在反向传播结束时，通过 All-Reduce 操作收集完整的梯度</li><li>然后每个 GPU 只更新自己负责的参数部分</li></ul><p><strong>内存节省</strong>：</p><ul><li>梯度内存减少 $N$ 倍</li><li>与 Stage 1 结合，总内存节省更加显著</li></ul><h3 id="ZeRO-Stage-3：参数分片（Parameter-Sharding）"><a href="#ZeRO-Stage-3：参数分片（Parameter-Sharding）" class="headerlink" title="ZeRO-Stage 3：参数分片（Parameter Sharding）"></a>ZeRO-Stage 3：参数分片（Parameter Sharding）</h3><p><strong>原理</strong>：<br>在 Stage 1 和 Stage 2 的基础上，进一步将模型参数分片存储。</p><p><strong>具体做法</strong>：</p><ul><li>模型参数也被分片存储在不同的 GPU 上</li><li>在训练过程中，当需要某个层的所有参数时，通过 All-Gather 操作将所需参数动态地收集到当前 GPU</li><li>这意味着在任何给定时间点，每个 GPU 上只完整存在模型参数的一部分</li></ul><p><strong>内存节省</strong>：</p><ul><li>模型参数内存减少 $N$ 倍</li><li>实现了最大程度的内存优化</li></ul><h2 id="ZeRO-的具体实现"><a href="#ZeRO-的具体实现" class="headerlink" title="ZeRO 的具体实现"></a>ZeRO 的具体实现</h2><h3 id="通信模式"><a href="#通信模式" class="headerlink" title="通信模式"></a>通信模式</h3><p>ZeRO 使用了两种主要的通信模式：</p><ol><li><p><strong>All-Gather</strong>：用于参数收集</p><ul><li>当需要某个层的完整参数时，从所有 GPU 收集该层的参数分片</li><li>通信开销：$O(P)$，其中 $P$ 是参数数量</li></ul></li><li><p><strong>All-Reduce</strong>：用于梯度聚合</p><ul><li>在反向传播后，聚合所有 GPU 上的梯度分片</li><li>通信开销：$O(P)$</li></ul></li></ol><h3 id="内存管理策略"><a href="#内存管理策略" class="headerlink" title="内存管理策略"></a>内存管理策略</h3><p><strong>按需加载机制</strong>：</p><ul><li>参数只在需要时才加载到 GPU 显存</li><li>使用完毕后立即释放，避免长期占用显存</li></ul><p><strong>分片存储策略</strong>：</p><ul><li>优化器状态：静态分片，训练过程中保持不变</li><li>梯度：动态分片，每次反向传播后重新分配</li><li>参数：动态分片，根据计算需求动态加载</li></ul><h3 id="计算流程"><a href="#计算流程" class="headerlink" title="计算流程"></a>计算流程</h3><p><strong>前向传播</strong>：</p><ol><li>通过 All-Gather 收集当前层需要的参数</li><li>执行前向计算</li><li>释放不需要的参数</li></ol><p><strong>反向传播</strong>：</p><ol><li>通过 All-Gather 收集当前层需要的参数</li><li>计算梯度</li><li>将梯度分片存储</li><li>释放参数</li></ol><p><strong>参数更新</strong>：</p><ol><li>通过 All-Reduce 聚合所有梯度分片</li><li>每个 GPU 更新自己负责的参数部分</li><li>更新对应的优化器状态</li></ol><h2 id="ZeRO-的变体技术"><a href="#ZeRO-的变体技术" class="headerlink" title="ZeRO 的变体技术"></a>ZeRO 的变体技术</h2><h3 id="ZeRO-Offload"><a href="#ZeRO-Offload" class="headerlink" title="ZeRO-Offload"></a>ZeRO-Offload</h3><p><strong>原理</strong>：<br>对于模型训练中一些对性能不那么敏感，但内存占用大的部分（如优化器状态、甚至梯度），将其从 GPU 显存转移到 CPU 内存或硬盘（NVMe SSD）。</p><p><strong>具体做法</strong>：</p><ul><li>优化器状态存储在 CPU 内存中</li><li>梯度可以存储在 CPU 内存或 NVMe SSD 中</li><li>在需要时通过 PCIe 总线传输数据</li></ul><p><strong>优势</strong>：</p><ul><li>进一步减少 GPU 显存需求</li><li>能够训练更大的模型</li><li>成本相对较低</li></ul><p><strong>劣势</strong>：</p><ul><li>增加了 CPU-GPU 数据传输开销</li><li>训练速度可能有所下降</li></ul><h3 id="ZeRO-FSDP（Fully-Sharded-Data-Parallelism）"><a href="#ZeRO-FSDP（Fully-Sharded-Data-Parallelism）" class="headerlink" title="ZeRO-FSDP（Fully Sharded Data Parallelism）"></a>ZeRO-FSDP（Fully Sharded Data Parallelism）</h3><p><strong>原理</strong>：<br>ZeRO-FSDP 是 ZeRO-Stage 3 的完整实现，实现了优化器状态、梯度和模型参数的全面分片。</p><p><strong>特点</strong>：</p><ul><li>最大程度的内存优化</li><li>支持任意大小的模型训练</li><li>通信开销相对较高</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在大语言模型（LLM）训练中，显存不足是一个普遍存在的问题。随着模型规模的不断增长，单个 GPU 的显存容量成为了训练大规模模型的主要瓶颈。DeepSpeed ZeRO（Zero Redundancy Optimizer）技术通过创新的数据分片策略，有效解决了这一问题，使得我们能够训练远超单卡显存上限的超大规模模型。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="training" scheme="https://murphypei.github.io/tags/training/"/>
    
      <category term="zero" scheme="https://murphypei.github.io/tags/zero/"/>
    
      <category term="deepspeed" scheme="https://murphypei.github.io/tags/deepspeed/"/>
    
      <category term="memory" scheme="https://murphypei.github.io/tags/memory/"/>
    
  </entry>
  
  <entry>
    <title>LLM 训练：GRPO 算法详解</title>
    <link href="https://murphypei.github.io//blog/2025/07/llm-grpo.html"/>
    <id>https://murphypei.github.io//blog/2025/07/llm-grpo.html</id>
    <published>2025-07-22T17:43:43.000Z</published>
    <updated>2025-07-23T12:04:59.989Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇博客中，我们详细介绍了 PPO 和 DPO 算法。今天我们来深入探讨 GRPO（Group Relative Policy Optimization）算法，这是 PPO 的一个重要改进版本。GRPO 的核心创新在于改进了优势函数的计算方式，使得训练更加稳定和高效。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在 RLHF（Reinforcement Learning from Human Feedback）训练中，PPO 算法虽然表现良好，但在优势函数计算方面存在一些局限性。GRPO 算法通过引入分组相对优势计算，解决了 PPO 中的一些问题，特别是在处理长序列生成任务时表现更加稳定。</p><h2 id="PPO-计算过程详解"><a href="#PPO-计算过程详解" class="headerlink" title="PPO 计算过程详解"></a>PPO 计算过程详解</h2><p>在深入 GRPO 之前，我们先详细回顾 PPO 的计算过程，特别是优势函数的计算，这是理解 GRPO 改进的关键。</p><h3 id="PPO-的两阶段训练过程"><a href="#PPO-的两阶段训练过程" class="headerlink" title="PPO 的两阶段训练过程"></a>PPO 的两阶段训练过程</h3><p>PPO 的训练过程分为两个阶段：<strong>Rollout 阶段</strong>（经验收集）和<strong>Optimization 阶段</strong>（参数优化）。</p><h4 id="阶段一：Rollout（经验收集-前向传播阶段）"><a href="#阶段一：Rollout（经验收集-前向传播阶段）" class="headerlink" title="阶段一：Rollout（经验收集/前向传播阶段）"></a>阶段一：Rollout（经验收集/前向传播阶段）</h4><p>这个阶段的目标是让 Actor 模型与环境交互，生成完整的回答，并收集所有必要的数据。<strong>此阶段只有前向传播，没有反向传播。</strong></p><p>对于<strong>每一个 token</strong>的生成，都会进行以下计算：</p><ol><li><p><strong>Actor（策略模型）计算</strong>：</p><ul><li><strong>输入</strong>：<code>Prompt</code> + 已经生成的 <code>token_1, ..., token_{t-1}</code></li><li><strong>计算</strong>：Actor 模型进行一次前向传播，输出下一个 token 的概率分布（logits）</li><li><strong>动作</strong>：从这个分布中<strong>采样</strong>出一个 <code>token_t</code></li><li><strong>记录</strong>：保存此时的 <code>log_probs</code>（选择 <code>token_t</code> 的对数概率）和 Actor 的内部状态</li></ul></li><li><p><strong>Critic（价值模型）计算</strong>：</p><ul><li><strong>输入</strong>：与 Actor 相同的输入，即 <code>Prompt</code> + <code>token_1, ..., token_{t-1}</code></li><li><strong>计算</strong>：Critic 模型也进行一次前向传播</li><li><strong>输出</strong>：得到一个<strong>标量值 <code>V_t</code></strong>，这个值是 Critic 对当前状态未来能获得的总奖励的<strong>预测</strong></li><li><strong>记录</strong>：保存这个价值 <code>V_t</code></li></ul></li></ol><p>这个过程会循环往复，直到生成一个完整的回答（例如，遇到 <code>[EOS]</code> 标记或达到最大长度）。</p><p><strong>阶段一结束后，我们得到了一整条”轨迹”（Trajectory），包含以下信息：</strong></p><ul><li>完整的生成序列（<code>token_1, ..., token_n</code>）</li><li>每一步的对数概率（<code>log_probs_1, ..., log_probs_n</code>）</li><li>每一步的价值预测（<code>V_1, ..., V_n</code>）</li></ul><h4 id="阶段二：Optimization（优化-反向传播阶段）"><a href="#阶段二：Optimization（优化-反向传播阶段）" class="headerlink" title="阶段二：Optimization（优化/反向传播阶段）"></a>阶段二：Optimization（优化/反向传播阶段）</h4><p>当收集到一个或一个批次（Batch）的完整”轨迹”后，真正的计算和更新才开始。</p><ol><li><p><strong>计算最终奖励（Reward）</strong>：</p><ul><li>将完整的”<code>Prompt</code> + <code>回答</code>“序列输入到<strong>奖励模型（Reward Model）</strong>中，得到一个<strong>唯一的、总的奖励分数 <code>R</code></strong></li><li>这个 <code>R</code> 是对整个回答的评价</li></ul></li><li><p><strong>计算优势函数（Advantage）</strong>：</p><ul><li>这是最关键的一步。我们不能简单地把总奖励 <code>R</code> 归功于最后一个 token</li><li>我们需要为<strong>每一个 token</strong>的生成行为分配合理的”功劳”或”过失”</li><li>这通常使用<strong>通用优势估计（Generalized Advantage Estimation, GAE）</strong>技术来完成</li></ul></li></ol><h3 id="优势函数的详细计算"><a href="#优势函数的详细计算" class="headerlink" title="优势函数的详细计算"></a>优势函数的详细计算</h3><h4 id="GAE（通用优势估计）算法"><a href="#GAE（通用优势估计）算法" class="headerlink" title="GAE（通用优势估计）算法"></a>GAE（通用优势估计）算法</h4><p>GAE 是 PPO 中计算优势函数的核心技术。对于序列中的每个位置 <code>t</code>，优势函数定义为：</p><script type="math/tex; mode=display">A_t = \delta_t + \gamma \lambda \delta_{t+1} + \gamma^2 \lambda^2 \delta_{t+2} + ... + \gamma^{T-t} \lambda^{T-t} \delta_T</script><p>其中：</p><ul><li>$\delta_t = r_t + \gamma V_{t+1} - V_t$ 是时序差分误差</li><li>$\gamma$ 是折扣因子（通常设为 1）</li><li>$\lambda$ 是 GAE 参数（通常设为 0.95）</li><li>$T$ 是序列长度</li></ul><p><strong>GAE 的直观理解</strong>：</p><ul><li>如果 $\lambda = 0$，则 $A_t = \delta_t$，只考虑一步的时序差分</li><li>如果 $\lambda = 1$，则 $A_t = \sum_{k=t}^T \gamma^{k-t} r_k - V_t$，考虑所有未来奖励</li><li>$\lambda$ 在 0 和 1 之间，平衡了偏差和方差</li></ul><h4 id="优势函数的物理意义"><a href="#优势函数的物理意义" class="headerlink" title="优势函数的物理意义"></a>优势函数的物理意义</h4><p>优势函数 $A_t$ 的直观含义是：</p><ul><li>在 <code>t</code> 时刻选择 <code>token_t</code> 这个动作，比 Critic 模型平均预测的要好多少</li><li>如果 <code>A_t &gt; 0</code>，说明这是个”惊喜”的好动作</li><li>如果 <code>A_t &lt; 0</code>，说明这是个”糟糕”的动作</li></ul><h3 id="PPO-损失函数计算"><a href="#PPO-损失函数计算" class="headerlink" title="PPO 损失函数计算"></a>PPO 损失函数计算</h3><p>现在我们有了每一步的 <code>log_probs_t</code>、<code>V_t</code> 和 <code>A_t</code>，可以计算整个序列的总损失：</p><ol><li><p><strong>Actor Loss（策略损失）</strong>：</p><ul><li>目标：最大化优势值为正的动作的概率，同时最小化优势值为负的动作的概率</li><li>公式：$L^{CLIP}(\theta) = \mathbb{E}_t [\min(r_t(\theta) A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) A_t)]$</li><li>其中 $r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}$ 是概率比率</li></ul></li><li><p><strong>Critic Loss（价值损失）</strong>：</p><ul><li>目标：让 Critic 的预测越来越准确</li><li>计算 Critic 的预测值 <code>V_t</code> 和通过 GAE 计算出的”真实”回报之间的均方误差</li><li>公式：$L^{VF} = \mathbb{E}_t [(V_t - V_{target})^2]$</li></ul></li><li><p><strong>总损失</strong>：</p><ul><li>$L_{PPO} = L^{CLIP} - \alpha L^{KL} + \beta L^{VF}$</li><li>其中 $\alpha$ 和 $\beta$ 是权重参数</li></ul></li></ol><h2 id="GRPO-算法详解"><a href="#GRPO-算法详解" class="headerlink" title="GRPO 算法详解"></a>GRPO 算法详解</h2><h3 id="2-1-GRPO-算法背景与动机"><a href="#2-1-GRPO-算法背景与动机" class="headerlink" title="2.1 GRPO 算法背景与动机"></a>2.1 GRPO 算法背景与动机</h3><p>在大语言模型（LLM）的微调过程中，强化学习（RL）扮演着至关重要的角色。传统的近端策略优化（PPO）算法虽然被广泛应用于LLM的微调，但其在处理大规模模型时面临着巨大的计算和存储负担。</p><p><strong>PPO 的主要问题</strong>：</p><ul><li><strong>计算负担重</strong>：PPO 需要维护一个与策略模型大小相当的价值网络来估计优势函数，这在大模型场景下会导致显著的内存占用和计算代价</li><li><strong>训练不稳定</strong>：PPO 算法在更新策略时可能会导致策略分布发生剧烈变化，从而影响训练的稳定性</li><li><strong>扩展性差</strong>：在数十亿甚至千亿参数的语言模型上应用 PPO 时，价值网络的训练和更新会消耗大量的计算资源</li></ul><p>为了解决这些问题，<strong>DeepSeek 提出了一种新的强化学习算法——组相对策略优化（GRPO），旨在减少对价值网络的依赖，同时保持策略更新的稳定性和高效性。</strong></p><h3 id="2-2-GRPO-核心思想"><a href="#2-2-GRPO-核心思想" class="headerlink" title="2.2 GRPO 核心思想"></a>2.2 GRPO 核心思想</h3><p><strong>GRPO 的核心思想是通过组内相对奖励来优化策略模型，而不是依赖传统的批评模型（critic model）</strong>。具体来说，GRPO 会在每个状态下采样一组动作，然后根据这些动作的相对表现来调整策略，而不是依赖一个单独的价值网络来估计每个动作的价值。</p><p><strong>GRPO 的核心优势</strong>：</p><ol><li><strong>减少计算负担</strong>：通过避免维护一个与策略模型大小相当的价值网络，GRPO 显著降低了训练过程中的内存占用和计算代价</li><li><strong>提高训练稳定性</strong>：GRPO 通过组内比较来估计优势函数，减少了策略更新的方差，从而确保了更稳定的学习过程</li><li><strong>增强策略更新的可控性</strong>：GRPO 引入了 KL 散度约束，防止策略更新过于剧烈，从而保持了策略分布的稳定性</li></ol><h3 id="2-3-GRPO-算法流程"><a href="#2-3-GRPO-算法流程" class="headerlink" title="2.3 GRPO 算法流程"></a>2.3 GRPO 算法流程</h3><p>GRPO 算法的流程可以分为以下几个关键步骤：</p><h4 id="步骤一：采样动作组"><a href="#步骤一：采样动作组" class="headerlink" title="步骤一：采样动作组"></a>步骤一：采样动作组</h4><p>对于每个输入状态 $s$，GRPO 从当前策略 $\pi_\theta$ 中采样一组动作 $a_1, a_2, …, a_G$。这些动作的采样基于策略模型的概率分布，确保了多样性。</p><h4 id="步骤二：奖励评估"><a href="#步骤二：奖励评估" class="headerlink" title="步骤二：奖励评估"></a>步骤二：奖励评估</h4><p>每个采样动作 $a_i$ 都会通过奖励函数 $R$ 进行评估，得到对应的奖励值 $r_i$。奖励函数可以根据具体任务设计，例如在数学推理任务中，奖励函数可以基于答案的正确性。</p><h4 id="步骤三：计算相对优势"><a href="#步骤三：计算相对优势" class="headerlink" title="步骤三：计算相对优势"></a>步骤三：计算相对优势</h4><p>将每个动作的奖励值进行归一化处理，得到相对优势 $\tilde{A}_i$。具体来说，相对优势可以通过以下公式计算：</p><script type="math/tex; mode=display">\tilde{A}_i = \frac{r_i - \mu_r}{\sigma_r}</script><p>其中，$\mu_r$ 和 $\sigma_r$ 分别是奖励值的均值和标准差。</p><h4 id="步骤四：策略更新"><a href="#步骤四：策略更新" class="headerlink" title="步骤四：策略更新"></a>步骤四：策略更新</h4><p>根据计算得到的相对优势 $\tilde{A}_i$，更新策略模型参数。GRPO 的目标函数可以表示为：</p><script type="math/tex; mode=display">L_{GRPO}(\theta) = \mathbb{E}_{s,a_1,...,a_G} \left[ \frac{1}{G} \sum_{i=1}^{G} \min \left( r_i(\theta) \tilde{A}_i, \text{clip}(r_i(\theta), 1-\epsilon, 1+\epsilon) \tilde{A}_i \right) \right]</script><p>其中：</p><ul><li>$G$ 是采样动作的组大小</li><li>$r_i(\theta) = \frac{\pi_\theta(a_i|s)}{\pi_{\theta_{old}}(a_i|s)}$ 是概率比率</li><li>$\epsilon$ 是裁剪参数（通常设为 0.2）</li></ul><h3 id="2-4-GRPO-的数学原理"><a href="#2-4-GRPO-的数学原理" class="headerlink" title="2.4 GRPO 的数学原理"></a>2.4 GRPO 的数学原理</h3><p>从数学角度来看，GRPO 的目标是最大化预期累积奖励，同时保持策略更新的稳定性。其目标函数可以表示为：</p><script type="math/tex; mode=display">L_{GRPO} = \mathbb{E}_{s,a_1,...,a_G} \left[ \frac{1}{G} \sum_{i=1}^{G} \log \pi_\theta(a_i|s) \tilde{A}_i \right] - \alpha D_{KL}(\pi_\theta || \pi_{\theta_{old}})</script><p>其中：</p><ul><li><strong>第一项</strong>：策略梯度项，通过相对优势来指导策略更新</li><li><strong>第二项</strong>：KL 散度正则化项，防止策略更新过于剧烈</li><li>$\alpha$ 是正则化权重参数</li></ul><p><strong>相对优势的物理意义</strong>：</p><ul><li>$\tilde{A}_i &gt; 0$：表示动作 $a_i$ 在组内表现较好，应该增加其概率</li><li>$\tilde{A}_i &lt; 0$：表示动作 $a_i$ 在组内表现较差，应该减少其概率</li><li>$\tilde{A}_i = 0$：表示动作 $a_i$ 在组内表现平均，不需要调整</li></ul><h3 id="2-5-GRPO-vs-PPO-的对比"><a href="#2-5-GRPO-vs-PPO-的对比" class="headerlink" title="2.5 GRPO vs PPO 的对比"></a>2.5 GRPO vs PPO 的对比</h3><div class="table-container"><table><thead><tr><th>特性</th><th>PPO</th><th>GRPO</th></tr></thead><tbody><tr><td><strong>价值网络</strong></td><td>需要维护与策略模型大小相当的价值网络</td><td>不需要价值网络，减少计算负担</td></tr><tr><td><strong>优势计算</strong></td><td>基于 GAE 和时序差分误差</td><td>基于组内相对奖励比较</td></tr><tr><td><strong>训练稳定性</strong></td><td>可能因价值网络不准确而不稳定</td><td>通过组内比较提高稳定性</td></tr><tr><td><strong>计算效率</strong></td><td>需要训练两个网络（Actor + Critic）</td><td>只需要训练策略网络</td></tr><tr><td><strong>内存占用</strong></td><td>高（需要存储价值网络）</td><td>低（只需要存储策略网络）</td></tr><tr><td><strong>适用场景</strong></td><td>通用强化学习任务</td><td>特别适合大语言模型微调</td></tr></tbody></table></div><h3 id="2-6-GRPO-的实现细节"><a href="#2-6-GRPO-的实现细节" class="headerlink" title="2.6 GRPO 的实现细节"></a>2.6 GRPO 的实现细节</h3><h4 id="2-6-1-组大小选择"><a href="#2-6-1-组大小选择" class="headerlink" title="2.6.1 组大小选择"></a>2.6.1 组大小选择</h4><p>组大小 $G$ 是 GRPO 算法中的一个重要超参数：</p><ul><li><strong>较小的组</strong>（如 $G=4$）：计算效率高，但相对优势估计可能不够准确</li><li><strong>较大的组</strong>（如 $G=16$）：相对优势估计更准确，但计算成本更高</li><li><strong>推荐值</strong>：通常在 8-16 之间，根据具体任务和计算资源调整</li></ul><h4 id="2-6-2-奖励归一化"><a href="#2-6-2-奖励归一化" class="headerlink" title="2.6.2 奖励归一化"></a>2.6.2 奖励归一化</h4><p>为了确保相对优势计算的稳定性，GRPO 使用以下归一化策略：</p><script type="math/tex; mode=display">\tilde{A}_i = \frac{r_i - \mu_r}{\sigma_r + \epsilon}</script><p>其中 $\epsilon$ 是一个小的常数（如 $10^{-8}$），防止除零错误。</p><h4 id="2-6-3-KL-散度约束"><a href="#2-6-3-KL-散度约束" class="headerlink" title="2.6.3 KL 散度约束"></a>2.6.3 KL 散度约束</h4><p>为了防止策略更新过于剧烈，GRPO 引入了 KL 散度约束：</p><script type="math/tex; mode=display">D_{KL}(\pi_\theta || \pi_{\theta_{old}}) \leq \delta</script><p>其中 $\delta$ 是 KL 散度的目标值（通常设为 0.01）。</p><h3 id="2-7-GRPO-在数学推理任务中的表现"><a href="#2-7-GRPO-在数学推理任务中的表现" class="headerlink" title="2.7 GRPO 在数学推理任务中的表现"></a>2.7 GRPO 在数学推理任务中的表现</h3><p>根据 DeepSeek 的研究，GRPO 在数学推理任务中表现出了显著的优势：</p><ol><li><strong>GSM8K 数据集</strong>：GRPO 相比 PPO 在准确率上有明显提升</li><li><strong>MATH 数据集</strong>：在复杂数学问题上，GRPO 的推理能力更强</li><li><strong>训练稳定性</strong>：GRPO 的训练过程更加稳定，收敛速度更快</li><li><strong>计算效率</strong>：在相同硬件条件下，GRPO 的训练时间更短</li></ol><h3 id="2-8-GRPO-的局限性"><a href="#2-8-GRPO-的局限性" class="headerlink" title="2.8 GRPO 的局限性"></a>2.8 GRPO 的局限性</h3><p>尽管 GRPO 有很多优势，但也存在一些局限性：</p><ol><li><strong>组内比较的局限性</strong>：相对优势的计算依赖于组内其他动作的质量，如果组内动作质量都很差，相对优势可能不够准确</li><li><strong>超参数敏感性</strong>：组大小、KL 散度约束等超参数需要仔细调优</li><li><strong>任务依赖性</strong>：GRPO 的效果可能因具体任务而异，需要根据任务特点进行调整</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>GRPO 算法通过引入分组相对优势计算，成功解决了 PPO 在大语言模型微调中的计算负担和稳定性问题。其核心创新在于：</p><ol><li><strong>消除价值网络依赖</strong>：通过组内相对比较替代传统的价值网络估计</li><li><strong>提高训练稳定性</strong>：通过相对优势和 KL 散度约束确保策略更新的稳定性</li><li><strong>降低计算成本</strong>：减少了一半的网络参数和计算量</li></ol><p>GRPO 算法为大规模语言模型的强化学习微调提供了一个更加高效和稳定的解决方案，特别是在数学推理和代码生成等任务中表现出了显著的优势。随着大语言模型规模的不断增长，GRPO 这类轻量级强化学习算法的重要性将越来越突出。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇博客中，我们详细介绍了 PPO 和 DPO 算法。今天我们来深入探讨 GRPO（Group Relative Policy Optimization）算法，这是 PPO 的一个重要改进版本。GRPO 的核心创新在于改进了优势函数的计算方式，使得训练更加稳定和高效。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="rlhf" scheme="https://murphypei.github.io/tags/rlhf/"/>
    
      <category term="ppo" scheme="https://murphypei.github.io/tags/ppo/"/>
    
      <category term="grpo" scheme="https://murphypei.github.io/tags/grpo/"/>
    
      <category term="advantage" scheme="https://murphypei.github.io/tags/advantage/"/>
    
  </entry>
  
  <entry>
    <title>LLM 推理： KV Cache 原理与优化</title>
    <link href="https://murphypei.github.io//blog/2025/07/kv-cache.html"/>
    <id>https://murphypei.github.io//blog/2025/07/kv-cache.html</id>
    <published>2025-07-01T03:56:52.000Z</published>
    <updated>2025-07-21T11:44:22.914Z</updated>
    
    <content type="html"><![CDATA[<p>继续梳理 LLM 知识，这次写 KV Cache。KV Cache 是大语言模型推理过程中的重要优化技术，能够显著减少计算量，提高推理速度。本文将从 Attention 计算原理出发，详细推导 KV Cache 的数学等价性，并分析其优化效果。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在大语言模型的推理过程中，生成式推理（Generative Inference）是一个自回归过程，模型需要逐个生成token。在这个过程中，大量的计算被重复执行，特别是Attention机制中的Key和Value矩阵计算。KV Cache技术通过缓存这些中间结果，避免了重复计算，从而显著提高了推理效率。</p><p>本文将详细介绍KV Cache的工作原理，从Attention计算的数学原理出发，推导其等价性，并分析其在实际应用中的优化效果。</p><h2 id="Attention机制回顾"><a href="#Attention机制回顾" class="headerlink" title="Attention机制回顾"></a>Attention机制回顾</h2><h3 id="标准Attention计算"><a href="#标准Attention计算" class="headerlink" title="标准Attention计算"></a>标准Attention计算</h3><p>在Transformer的Attention机制中，对于输入序列 $X = [x_1, x_2, …, x_n]$，Attention的计算过程如下：</p><p><strong>1. 线性变换</strong></p><script type="math/tex; mode=display">Q = XW_Q, \quad K = XW_K, \quad V = XW_V</script><p>其中：</p><ul><li>$W_Q, W_K, W_V$ 是查询、键、值的权重矩阵</li><li>$Q, K, V$ 分别是查询、键、值的矩阵表示</li></ul><p><strong>2. Attention计算</strong></p><script type="math/tex; mode=display">\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V</script><p>其中 $d_k$ 是键向量的维度。</p><p><strong>3. 分步展开</strong><br>对于第 $i$ 个位置的输出，可以表示为：</p><script type="math/tex; mode=display">O_i = \sum_{j=1}^{n} \alpha_{ij} v_j</script><p>其中：</p><script type="math/tex; mode=display">\alpha_{ij} = \frac{\exp\left(\frac{q_i^T k_j}{\sqrt{d_k}}\right)}{\sum_{l=1}^{n} \exp\left(\frac{q_i^T k_l}{\sqrt{d_k}}\right)}</script><h3 id="自回归生成过程"><a href="#自回归生成过程" class="headerlink" title="自回归生成过程"></a>自回归生成过程</h3><p>在生成式推理中，模型逐个生成token。假设当前已经生成了 $t$ 个token，要生成第 $t+1$ 个token：</p><p><strong>输入序列</strong>：$X_{1:t} = [x_1, x_2, …, x_t]$</p><p><strong>计算过程</strong>：</p><ol><li>计算 $Q_{1:t}, K_{1:t}, V_{1:t}$</li><li>计算Attention输出</li><li>生成下一个token $x_{t+1}$</li><li>重复上述过程</li></ol><p><strong>问题</strong>：每次生成新token时，都需要重新计算整个序列的 $K$ 和 $V$ 矩阵，这导致了大量的重复计算。</p><h2 id="KV-Cache的核心思想"><a href="#KV-Cache的核心思想" class="headerlink" title="KV Cache的核心思想"></a>KV Cache的核心思想</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>KV Cache的核心思想是：<strong>缓存已经计算过的Key和Value矩阵，避免重复计算</strong>。</p><p><strong>缓存内容</strong>：</p><ul><li>$K_{cache} = [K_1, K_2, …, K_t]$：已生成token的Key矩阵</li><li>$V_{cache} = [V_1, V_2, …, V_t]$：已生成token的Value矩阵</li></ul><p><strong>增量更新</strong>：</p><ul><li>生成新token $x_{t+1}$ 时，只计算 $K_{t+1}$ 和 $V_{t+1}$</li><li>将新的Key和Value追加到缓存中</li><li>使用完整的缓存进行Attention计算</li></ul><h3 id="数学等价性推导"><a href="#数学等价性推导" class="headerlink" title="数学等价性推导"></a>数学等价性推导</h3><h4 id="1-标准计算的数学表示"><a href="#1-标准计算的数学表示" class="headerlink" title="1. 标准计算的数学表示"></a>1. 标准计算的数学表示</h4><p>在标准计算中，生成第 $t+1$ 个token时：</p><p><strong>输入</strong>：$X_{1:t+1} = [x_1, x_2, …, x_t, x_{t+1}]$</p><p><strong>计算过程</strong>：</p><script type="math/tex; mode=display">Q_{1:t+1} = X_{1:t+1}W_Q \\K_{1:t+1} = X_{1:t+1}W_K \\V_{1:t+1} = X_{1:t+1}W_V</script><p><strong>Attention输出</strong>：</p><script type="math/tex; mode=display">O_{t+1} = \sum_{j=1}^{t+1} \alpha_{(t+1)j} v_j</script><p>其中：</p><script type="math/tex; mode=display">\alpha_{(t+1)j} = \frac{\exp\left(\frac{q_{t+1}^T k_j}{\sqrt{d_k}}\right)}{\sum_{l=1}^{t+1} \exp\left(\frac{q_{t+1}^T k_l}{\sqrt{d_k}}\right)}</script><h4 id="2-KV-Cache的计算表示"><a href="#2-KV-Cache的计算表示" class="headerlink" title="2. KV Cache的计算表示"></a>2. KV Cache的计算表示</h4><p>在KV Cache中，生成第 $t+1$ 个token时：</p><p><strong>缓存状态</strong>：</p><ul><li>$K_{cache} = [K_1, K_2, …, K_t]$</li><li>$V_{cache} = [V_1, V_2, …, V_t]$</li></ul><p><strong>增量计算</strong>：</p><script type="math/tex; mode=display">q_{t+1} = x_{t+1}W_Q \\k_{t+1} = x_{t+1}W_K \\v_{t+1} = x_{t+1}W_V</script><p><strong>更新缓存</strong>：</p><script type="math/tex; mode=display">K_{cache}^{new} = [K_{cache}, k_{t+1}] = [K_1, K_2, ..., K_t, K_{t+1}] \\V_{cache}^{new} = [V_{cache}, v_{t+1}] = [V_1, V_2, ..., V_t, V_{t+1}]</script><p><strong>Attention计算</strong>：</p><script type="math/tex; mode=display">O_{t+1} = \sum_{j=1}^{t+1} \alpha_{(t+1)j} v_j</script><p>其中：</p><script type="math/tex; mode=display">\alpha_{(t+1)j} = \frac{\exp\left(\frac{q_{t+1}^T k_j}{\sqrt{d_k}}\right)}{\sum_{l=1}^{t+1} \exp\left(\frac{q_{t+1}^T k_l}{\sqrt{d_k}}\right)}</script><blockquote><p>这里注意重点，$O_{t+1}$，只和 $\alpha_{(t+1)j}$ 以及 $v_{i:t+1}$ 有关。而 $\alpha_{(t+1)j}$ 只和 $q_{t+1}$ 以及 $k_{i:t+1}$ 有关，这也是为何需要 KV  缓存，而不需要 Q 缓存的原因。这是 Attention 计算的核心，也是实现 KV cache 的关键。</p></blockquote><h4 id="3-等价性证明"><a href="#3-等价性证明" class="headerlink" title="3. 等价性证明"></a>3. 等价性证明</h4><p><strong>矩阵运算的线性性质</strong>：</p><p>对于线性变换 $K = XW_K$，由于矩阵乘法的线性性质：</p><script type="math/tex; mode=display">K_{1:t+1} = X_{1:t+1}W_K = [X_{1:t}, x_{t+1}]W_K = [X_{1:t}W_K, x_{t+1}W_K] = [K_{1:t}, K_{t+1}]</script><p>同理：</p><script type="math/tex; mode=display">V_{1:t+1} = [V_{1:t}, V_{t+1}]</script><p><strong>Attention计算的等价性</strong>：</p><p>在标准计算中：</p><script type="math/tex; mode=display">\text{Attention}(Q_{1:t+1}, K_{1:t+1}, V_{1:t+1}) = \text{softmax}\left(\frac{Q_{1:t+1}K_{1:t+1}^T}{\sqrt{d_k}}\right)V_{1:t+1}</script><p>在KV Cache中：</p><script type="math/tex; mode=display">\text{Attention}(q_{t+1}, [K_{cache}, k_{t+1}], [V_{cache}, v_{t+1}]) = \text{softmax}\left(\frac{q_{t+1}[K_{cache}, k_{t+1}]^T}{\sqrt{d_k}}\right)[V_{cache}, v_{t+1}]</script><p>由于：</p><ul><li>$[K_{cache}, k_{t+1}] = K_{1:t+1}$</li><li>$[V_{cache}, v_{t+1}] = V_{1:t+1}$</li><li>$q_{t+1}$ 是 $Q_{1:t+1}$ 的最后一行</li></ul><p>因此，两种计算方式在数学上完全等价。</p><h3 id="计算复杂度分析"><a href="#计算复杂度分析" class="headerlink" title="计算复杂度分析"></a>计算复杂度分析</h3><h4 id="1-标准计算复杂度"><a href="#1-标准计算复杂度" class="headerlink" title="1. 标准计算复杂度"></a>1. 标准计算复杂度</h4><p><strong>第 $t+1$ 步的计算量</strong>：</p><ul><li>线性变换：$O((t+1) \times d_{model} \times d_k)$</li><li>Attention计算：$O((t+1)^2 \times d_k)$</li><li>总复杂度：$O((t+1) \times d_{model} \times d_k + (t+1)^2 \times d_k)$</li></ul><p><strong>累积计算量</strong>（生成 $n$ 个token）：</p><script type="math/tex; mode=display">\sum_{t=1}^{n} O(t \times d_{model} \times d_k + t^2 \times d_k) = O(n^2 \times d_{model} \times d_k + n^3 \times d_k)</script><h4 id="2-KV-Cache计算复杂度"><a href="#2-KV-Cache计算复杂度" class="headerlink" title="2. KV Cache计算复杂度"></a>2. KV Cache计算复杂度</h4><p><strong>第 $t+1$ 步的计算量</strong>：</p><ul><li>线性变换：$O(d_{model} \times d_k)$（只计算新token）</li><li>Attention计算：$O((t+1)^2 \times d_k)$</li><li>总复杂度：$O(d_{model} \times d_k + (t+1)^2 \times d_k)$</li></ul><p><strong>累积计算量</strong>（生成 $n$ 个token）：</p><script type="math/tex; mode=display">\sum_{t=1}^{n} O(d_{model} \times d_k + t^2 \times d_k) = O(n \times d_{model} \times d_k + n^3 \times d_k)</script><h4 id="3-优化效果"><a href="#3-优化效果" class="headerlink" title="3. 优化效果"></a>3. 优化效果</h4><p><strong>计算量减少</strong>：</p><ul><li>线性变换部分：从 $O(n^2 \times d_{model} \times d_k)$ 减少到 $O(n \times d_{model} \times d_k)$</li><li>减少比例：$O(n)$ 倍</li></ul><p><strong>实际效果</strong>：</p><ul><li>对于长序列生成，计算量减少显著</li><li>特别是在生成较长文本时，优化效果明显</li></ul><h2 id="KV-Cache的实现细节"><a href="#KV-Cache的实现细节" class="headerlink" title="KV Cache的实现细节"></a>KV Cache的实现细节</h2><h3 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h3><h4 id="1-缓存结构"><a href="#1-缓存结构" class="headerlink" title="1. 缓存结构"></a>1. 缓存结构</h4><p><strong>缓存格式</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 缓存结构示例</span></span><br><span class="line">kv_cache = &#123;</span><br><span class="line">    <span class="string">'key'</span>: torch.zeros(seq_len, num_layers, num_heads, head_dim),</span><br><span class="line">    <span class="string">'value'</span>: torch.zeros(seq_len, num_layers, num_heads, head_dim)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><strong>内存布局</strong>：</p><ul><li>按层（layer）组织</li><li>每层包含多个注意力头（attention heads）</li><li>支持动态扩展</li></ul><h4 id="2-内存优化策略"><a href="#2-内存优化策略" class="headerlink" title="2. 内存优化策略"></a>2. 内存优化策略</h4><p><strong>预分配策略</strong>：</p><ul><li>根据最大序列长度预分配内存</li><li>避免频繁的内存重新分配</li></ul><p><strong>内存复用</strong>：</p><ul><li>在推理过程中复用缓存空间</li><li>减少内存碎片</li></ul><h3 id="增量更新机制"><a href="#增量更新机制" class="headerlink" title="增量更新机制"></a>增量更新机制</h3><h4 id="1-缓存更新"><a href="#1-缓存更新" class="headerlink" title="1. 缓存更新"></a>1. 缓存更新</h4><p><strong>更新流程</strong>：</p><ol><li>计算新token的Key和Value</li><li>将新的Key和Value追加到缓存</li><li>更新缓存的有效长度</li></ol><p><strong>代码示例</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update_kv_cache</span><span class="params">(kv_cache, new_k, new_v, layer_idx)</span>:</span></span><br><span class="line">    <span class="comment"># 追加新的Key和Value到缓存</span></span><br><span class="line">    kv_cache[<span class="string">'key'</span>][layer_idx] = torch.cat([kv_cache[<span class="string">'key'</span>][layer_idx], new_k], dim=<span class="number">0</span>)</span><br><span class="line">    kv_cache[<span class="string">'value'</span>][layer_idx] = torch.cat([kv_cache[<span class="string">'value'</span>][layer_idx], new_v], dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p><h4 id="2-注意力计算"><a href="#2-注意力计算" class="headerlink" title="2. 注意力计算"></a>2. 注意力计算</h4><p><strong>使用缓存的Attention计算</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_with_cache</span><span class="params">(query, kv_cache, layer_idx)</span>:</span></span><br><span class="line">    <span class="comment"># 获取缓存的Key和Value</span></span><br><span class="line">    cached_k = kv_cache[<span class="string">'key'</span>][layer_idx]</span><br><span class="line">    cached_v = kv_cache[<span class="string">'value'</span>][layer_idx]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算注意力分数</span></span><br><span class="line">    scores = torch.matmul(query, cached_k.transpose(<span class="number">-2</span>, <span class="number">-1</span>)) / math.sqrt(d_k)</span><br><span class="line">    attention_weights = torch.softmax(scores, dim=<span class="number">-1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算输出</span></span><br><span class="line">    output = torch.matmul(attention_weights, cached_v)</span><br><span class="line">    <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure></p><h3 id="多头注意力处理"><a href="#多头注意力处理" class="headerlink" title="多头注意力处理"></a>多头注意力处理</h3><h4 id="1-多头并行计算"><a href="#1-多头并行计算" class="headerlink" title="1. 多头并行计算"></a>1. 多头并行计算</h4><p><strong>缓存组织</strong>：</p><ul><li>每个注意力头独立缓存Key和Value</li><li>支持并行计算</li></ul><p><strong>计算优化</strong>：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_head_attention_with_cache</span><span class="params">(query, kv_cache, layer_idx)</span>:</span></span><br><span class="line">    batch_size, num_heads, seq_len, head_dim = query.shape</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 并行计算所有注意力头</span></span><br><span class="line">    outputs = []</span><br><span class="line">    <span class="keyword">for</span> head_idx <span class="keyword">in</span> range(num_heads):</span><br><span class="line">        head_query = query[:, head_idx, :, :]</span><br><span class="line">        head_k = kv_cache[<span class="string">'key'</span>][layer_idx][:, head_idx, :, :]</span><br><span class="line">        head_v = kv_cache[<span class="string">'value'</span>][layer_idx][:, head_idx, :, :]</span><br><span class="line">        </span><br><span class="line">        head_output = attention_with_cache(head_query, head_k, head_v)</span><br><span class="line">        outputs.append(head_output)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> torch.cat(outputs, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><h4 id="2-内存布局优化"><a href="#2-内存布局优化" class="headerlink" title="2. 内存布局优化"></a>2. 内存布局优化</h4><p><strong>连续内存布局</strong>：</p><ul><li>将多头数据存储在连续内存中</li><li>提高缓存命中率</li></ul><p><strong>批处理优化</strong>：</p><ul><li>支持批量处理多个序列</li><li>减少内存访问开销</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继续梳理 LLM 知识，这次写 KV Cache。KV Cache 是大语言模型推理过程中的重要优化技术，能够显著减少计算量，提高推理速度。本文将从 Attention 计算原理出发，详细推导 KV Cache 的数学等价性，并分析其优化效果。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="KV Cache" scheme="https://murphypei.github.io/tags/KV-Cache/"/>
    
      <category term="Attention" scheme="https://murphypei.github.io/tags/Attention/"/>
    
      <category term="推理优化" scheme="https://murphypei.github.io/tags/%E6%8E%A8%E7%90%86%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>LLM：RAG 中的文本检索技术</title>
    <link href="https://murphypei.github.io//blog/2025/06/text-retriveval.html"/>
    <id>https://murphypei.github.io//blog/2025/06/text-retriveval.html</id>
    <published>2025-06-29T19:19:02.000Z</published>
    <updated>2025-07-01T12:41:19.152Z</updated>
    
    <content type="html"><![CDATA[<p>继续准备 LLM 面试知识，这次写文本检索技术。文本检索是 RAG（检索增强生成）系统的核心组件，也是面试中经常被问到的问题。本文将详细介绍稠密向量检索、稀疏向量检索、BM25算法以及混合检索策略，帮助理解现代文本检索系统的技术原理。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在当今的信息检索领域，随着人工智能和自然语言处理技术的发展，文本检索技术已经从传统的基于关键词匹配的方法，发展到了基于深度学习的语义检索方法。文本检索是RAG（Retrieval-Augmented Generation）系统的核心组件，它负责从大规模文档集合中检索出与用户查询最相关的文档片段，为后续的生成模型提供上下文信息。</p><p>本文将详细介绍三种主要的文本检索方法：<strong>稠密向量检索（Dense Retrieval）</strong>、<strong>稀疏向量检索（Sparse Retrieval）</strong>和<strong>BM25算法</strong>，以及它们的混合使用策略。</p><h2 id="稠密向量检索（Dense-Retrieval）"><a href="#稠密向量检索（Dense-Retrieval）" class="headerlink" title="稠密向量检索（Dense Retrieval）"></a>稠密向量检索（Dense Retrieval）</h2><h3 id="稠密向量检索的基本原理"><a href="#稠密向量检索的基本原理" class="headerlink" title="稠密向量检索的基本原理"></a>稠密向量检索的基本原理</h3><p>稠密向量检索是一种基于深度学习的检索方法，它通过将文本转换为高维空间中的连续向量表示，然后使用向量相似度（如余弦相似度、欧氏距离）来检索相关文档。</p><p><strong>核心思想</strong>：</p><ul><li>将查询和文档都映射到同一个高维向量空间</li><li>通过计算向量间的相似度来衡量相关性</li><li>能够捕捉文本的深层语义信息</li></ul><h3 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h3><h4 id="1-文本编码"><a href="#1-文本编码" class="headerlink" title="1. 文本编码"></a>1. 文本编码</h4><p>稠密向量检索通常使用预训练的语言模型（如BERT、T5、Sentence-BERT等）对文本进行编码：</p><script type="math/tex; mode=display">\mathbf{q} = \text{Encoder}(query) \\\mathbf{d} = \text{Encoder}(document)</script><p>其中：</p><ul><li>$\mathbf{q}$ 是查询的向量表示</li><li>$\mathbf{d}$ 是文档的向量表示</li><li>$\text{Encoder}$ 是预训练的语言模型</li></ul><h4 id="2-相似度计算"><a href="#2-相似度计算" class="headerlink" title="2. 相似度计算"></a>2. 相似度计算</h4><p>常用的相似度计算方法包括：</p><p><strong>余弦相似度</strong>：</p><script type="math/tex; mode=display">\text{sim}(\mathbf{q}, \mathbf{d}) = \frac{\mathbf{q} \cdot \mathbf{d}}{|\mathbf{q}| \cdot |\mathbf{d}|}</script><p><strong>点积相似度</strong>：</p><script type="math/tex; mode=display">\text{sim}(\mathbf{q}, \mathbf{d}) = \mathbf{q} \cdot \mathbf{d}</script><p><strong>欧氏距离</strong>：</p><script type="math/tex; mode=display">\text{dist}(\mathbf{q}, \mathbf{d}) = \sqrt{\sum_{i=1}^{n} (q_i - d_i)^2}</script><h4 id="3-索引和检索"><a href="#3-索引和检索" class="headerlink" title="3. 索引和检索"></a>3. 索引和检索</h4><p><strong>向量索引</strong>：</p><ul><li>使用FAISS、Annoy、HNSW等向量索引库</li><li>支持高效的近似最近邻搜索</li><li>能够处理百万级别的向量检索</li></ul><p><strong>检索流程</strong>：</p><ol><li>将查询编码为向量</li><li>在向量索引中搜索最相似的文档向量</li><li>返回相似度最高的文档</li></ol><h3 id="稠密向量检索的优势和局限性"><a href="#稠密向量检索的优势和局限性" class="headerlink" title="稠密向量检索的优势和局限性"></a>稠密向量检索的优势和局限性</h3><p><strong>优势</strong>：</p><ol><li><strong>语义理解能力强</strong>：能够理解查询和文档的深层语义</li><li><strong>处理同义词和近义词</strong>：即使词汇不完全匹配，也能找到相关文档</li><li><strong>支持复杂查询</strong>：能够处理自然语言形式的查询</li></ol><p><strong>局限性</strong>：</p><ol><li><strong>计算成本高</strong>：需要深度学习模型进行编码</li><li><strong>索引规模限制</strong>：在大规模数据集上可能遇到性能瓶颈</li><li><strong>对训练数据敏感</strong>：检索效果依赖于编码模型的训练质量</li></ol><h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li><strong>智能问答系统</strong>：从知识库中检索相关答案</li><li><strong>推荐系统</strong>：基于内容相似性推荐相关文档</li><li><strong>语义搜索</strong>：理解用户意图的搜索引擎</li></ul><h2 id="稀疏向量检索（Sparse-Retrieval）"><a href="#稀疏向量检索（Sparse-Retrieval）" class="headerlink" title="稀疏向量检索（Sparse Retrieval）"></a>稀疏向量检索（Sparse Retrieval）</h2><h3 id="稀疏向量检索的基本原理"><a href="#稀疏向量检索的基本原理" class="headerlink" title="稀疏向量检索的基本原理"></a>稀疏向量检索的基本原理</h3><p>稀疏向量检索是基于传统信息检索模型的方法，它使用词袋模型（Bag of Words）将文本表示为稀疏向量，并通过计算词频-逆文档频率（TF-IDF）来评估文档与查询的相关性。</p><p><strong>核心思想</strong>：</p><ul><li>将文本表示为高维稀疏向量</li><li>每个维度对应词汇表中的一个词</li><li>通过统计方法计算词的重要性</li></ul><h3 id="技术实现-1"><a href="#技术实现-1" class="headerlink" title="技术实现"></a>技术实现</h3><h4 id="1-TF-IDF计算"><a href="#1-TF-IDF计算" class="headerlink" title="1. TF-IDF计算"></a>1. TF-IDF计算</h4><p><strong>词频（Term Frequency, TF）</strong>：</p><script type="math/tex; mode=display">\text{TF}(t, d) = \frac{\text{词 } t \text{ 在文档 } d \text{ 中的出现次数}}{\text{文档 } d \text{ 的总词数}}</script><p><strong>逆文档频率（Inverse Document Frequency, IDF）</strong>：</p><script type="math/tex; mode=display">\text{IDF}(t) = \log \frac{\text{总文档数}}{\text{包含词 } t \text{ 的文档数}}</script><p><strong>TF-IDF权重</strong>：</p><script type="math/tex; mode=display">\text{TF-IDF}(t, d) = \text{TF}(t, d) \times \text{IDF}(t)</script><h4 id="2-向量构建"><a href="#2-向量构建" class="headerlink" title="2. 向量构建"></a>2. 向量构建</h4><p>文档向量 $\mathbf{d}$ 的构建：</p><script type="math/tex; mode=display">\mathbf{d} = [\text{TF-IDF}(t_1, d), \text{TF-IDF}(t_2, d), ..., \text{TF-IDF}(t_n, d)]</script><p>其中 $t_1, t_2, …, t_n$ 是词汇表中的所有词。</p><h4 id="3-相似度计算"><a href="#3-相似度计算" class="headerlink" title="3. 相似度计算"></a>3. 相似度计算</h4><p><strong>余弦相似度</strong>：</p><script type="math/tex; mode=display">\text{sim}(\mathbf{q}, \mathbf{d}) = \frac{\mathbf{q} \cdot \mathbf{d}}{|\mathbf{q}| \cdot |\mathbf{d}|}</script><p><strong>点积相似度</strong>：</p><script type="math/tex; mode=display">\text{sim}(\mathbf{q}, \mathbf{d}) = \mathbf{q} \cdot \mathbf{d}</script><h3 id="稀疏向量检索的优势和局限性"><a href="#稀疏向量检索的优势和局限性" class="headerlink" title="稀疏向量检索的优势和局限性"></a>稀疏向量检索的优势和局限性</h3><p><strong>优势</strong>：</p><ol><li><strong>计算效率高</strong>：基于统计方法，计算速度快</li><li><strong>可解释性强</strong>：能够明确知道哪些词贡献了相关性</li><li><strong>处理大规模数据</strong>：能够高效处理大规模文档集合</li></ol><p><strong>局限性</strong>：</p><ol><li><strong>语义理解能力弱</strong>：无法处理同义词和近义词</li><li><strong>词汇匹配限制</strong>：需要查询词在文档中实际出现</li><li><strong>无法处理语义相似性</strong>：无法理解词汇的深层含义</li></ol><h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li><strong>传统搜索引擎</strong>：基于关键词的网页搜索</li><li><strong>文档检索系统</strong>：从文档库中检索相关文档</li><li><strong>信息过滤</strong>：基于关键词的信息过滤</li></ul><h2 id="BM25算法"><a href="#BM25算法" class="headerlink" title="BM25算法"></a>BM25算法</h2><h3 id="BM25算法的基本原理"><a href="#BM25算法的基本原理" class="headerlink" title="BM25算法的基本原理"></a>BM25算法的基本原理</h3><p>BM25（Best Matching 25）是一种经典的信息检索算法，它是TF-IDF算法的改进版，通过引入词频（TF）和文档频率（DF）的函数来计算文档与查询的相关性得分。</p><p><strong>核心思想</strong>：</p><ul><li>在TF-IDF基础上引入文档长度归一化</li><li>使用词频饱和函数处理高频词</li><li>通过参数调整优化检索效果</li></ul><h3 id="数学公式"><a href="#数学公式" class="headerlink" title="数学公式"></a>数学公式</h3><p>BM25算法的核心公式：</p><script type="math/tex; mode=display">\text{BM25}(Q, D) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{f(q_i, D) \cdot (k_1 + 1)}{f(q_i, D) + k_1 \cdot (1 - b + b \cdot \frac{|D|}{\text{avgdl}})}</script><p>其中：</p><ul><li>$Q$ 是查询，包含词 $q_1, q_2, …, q_n$</li><li>$D$ 是文档</li><li>$f(q_i, D)$ 是词 $q_i$ 在文档 $D$ 中的词频</li><li>$|D|$ 是文档 $D$ 的长度</li><li>$\text{avgdl}$ 是文档集合的平均长度</li><li>$k_1$ 和 $b$ 是调节参数</li></ul><p><strong>IDF计算</strong>：</p><script type="math/tex; mode=display">\text{IDF}(q_i) = \log \frac{N - n(q_i) + 0.5}{n(q_i) + 0.5}</script><p>其中：</p><ul><li>$N$ 是文档集合的总文档数</li><li>$n(q_i)$ 是包含词 $q_i$ 的文档数</li></ul><h3 id="参数调节"><a href="#参数调节" class="headerlink" title="参数调节"></a>参数调节</h3><p><strong>$k_1$ 参数</strong>：</p><ul><li>控制词频饱和程度</li><li>通常设置为 1.2-2.0</li><li>值越大，词频的影响越线性</li></ul><p><strong>$b$ 参数</strong>：</p><ul><li>控制文档长度归一化程度</li><li>取值范围为 0-1</li><li>$b=0$ 表示不进行长度归一化</li><li>$b=1$ 表示完全归一化</li></ul><h3 id="BM25算法的优势"><a href="#BM25算法的优势" class="headerlink" title="BM25算法的优势"></a>BM25算法的优势</h3><ol><li><strong>理论基础扎实</strong>：基于概率检索模型</li><li><strong>参数可调节</strong>：能够适应不同的数据集和需求</li><li><strong>计算效率高</strong>：基于统计方法，计算速度快</li><li><strong>效果稳定</strong>：在许多基准测试中表现优异</li></ol><h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><ul><li><strong>搜索引擎</strong>：Google、Bing等搜索引擎的核心算法</li><li><strong>文档检索</strong>：企业文档管理系统</li><li><strong>学术搜索</strong>：学术论文检索系统</li></ul><h2 id="混合检索策略"><a href="#混合检索策略" class="headerlink" title="混合检索策略"></a>混合检索策略</h2><h3 id="混合检索的基本原理"><a href="#混合检索的基本原理" class="headerlink" title="混合检索的基本原理"></a>混合检索的基本原理</h3><p>混合检索结合了稠密向量检索、稀疏向量检索和BM25算法的优势，通过多路召回和结果融合来提高检索系统的整体性能。</p><p><strong>核心思想</strong>：</p><ul><li>使用多种检索方法并行检索</li><li>通过融合算法合并检索结果</li><li>平衡准确性和召回率</li></ul><h3 id="混合检索的优势"><a href="#混合检索的优势" class="headerlink" title="混合检索的优势"></a>混合检索的优势</h3><ol><li><strong>互补性</strong>：不同方法各有优势，相互补充</li><li><strong>提高准确性</strong>：通过多路召回提高检索准确性</li><li><strong>提升召回率</strong>：增加检索结果的覆盖面</li><li><strong>适应性</strong>：能够适应不同的查询类型和场景</li></ol><h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h3><h4 id="1-多路召回"><a href="#1-多路召回" class="headerlink" title="1. 多路召回"></a>1. 多路召回</h4><p><strong>稠密向量检索</strong>：</p><ul><li>使用语义相似性进行检索</li><li>适合处理语义相关的查询</li></ul><p><strong>稀疏向量检索</strong>：</p><ul><li>使用关键词匹配进行检索</li><li>适合处理精确匹配的查询</li></ul><p><strong>BM25检索</strong>：</p><ul><li>使用传统信息检索方法</li><li>适合处理结构化查询</li></ul><h4 id="2-结果融合"><a href="#2-结果融合" class="headerlink" title="2. 结果融合"></a>2. 结果融合</h4><p><strong>RRF（Reciprocal Rank Fusion）</strong>：</p><script type="math/tex; mode=display">\text{RRF}(d) = \sum_{i=1}^{n} \frac{1}{k + \text{rank}_i(d)}</script><p>其中：</p><ul><li>$\text{rank}_i(d)$ 是文档 $d$ 在第 $i$ 个检索方法中的排名</li><li>$k$ 是调节参数，通常设置为 60</li></ul><p><strong>加权融合</strong>：</p><script type="math/tex; mode=display">\text{Score}(d) = \sum_{i=1}^{n} w_i \cdot \text{score}_i(d)</script><p>其中：</p><ul><li>$w_i$ 是第 $i$ 个检索方法的权重</li><li>$\text{score}_i(d)$ 是文档 $d$ 在第 $i$ 个检索方法中的得分</li></ul><h4 id="3-动态权重调整"><a href="#3-动态权重调整" class="headerlink" title="3. 动态权重调整"></a>3. 动态权重调整</h4><p>根据查询类型动态调整不同检索方法的权重：</p><ul><li><strong>语义查询</strong>：增加稠密向量检索的权重</li><li><strong>关键词查询</strong>：增加稀疏向量检索和BM25的权重</li><li><strong>混合查询</strong>：平衡各种方法的权重</li></ul><h3 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h3><p><strong>查询处理层</strong>：</p><ul><li>查询解析和预处理</li><li>查询类型识别</li><li>参数选择</li></ul><p><strong>检索层</strong>：</p><ul><li>多路并行检索</li><li>结果初步排序</li><li>去重和合并</li></ul><p><strong>融合层</strong>：</p><ul><li>结果融合算法</li><li>最终排序</li><li>结果返回</li></ul><h2 id="性能评估指标"><a href="#性能评估指标" class="headerlink" title="性能评估指标"></a>性能评估指标</h2><h3 id="检索性能指标"><a href="#检索性能指标" class="headerlink" title="检索性能指标"></a>检索性能指标</h3><p><strong>准确率（Precision）</strong>：</p><script type="math/tex; mode=display">\text{Precision} = \frac{\text{相关文档数}}{\text{检索文档数}}</script><p><strong>召回率（Recall）</strong>：</p><script type="math/tex; mode=display">\text{Recall} = \frac{\text{相关文档数}}{\text{总相关文档数}}</script><p><strong>F1分数</strong>：</p><script type="math/tex; mode=display">\text{F1} = \frac{2 \times \text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}</script><p><strong>平均精度（MAP）</strong>：</p><script type="math/tex; mode=display">\text{MAP} = \frac{1}{|Q|} \sum_{q \in Q} \text{AP}(q)</script><p>其中 $\text{AP}(q)$ 是查询 $q$ 的平均精度。</p><h3 id="效率指标"><a href="#效率指标" class="headerlink" title="效率指标"></a>效率指标</h3><p><strong>检索延迟</strong>：从查询到返回结果的时间<br><strong>吞吐量</strong>：单位时间内处理的查询数<br><strong>索引大小</strong>：索引占用的存储空间</p><h2 id="实际应用中的优化策略"><a href="#实际应用中的优化策略" class="headerlink" title="实际应用中的优化策略"></a>实际应用中的优化策略</h2><h3 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h3><p><strong>倒排索引</strong>：</p><ul><li>为每个词建立文档列表</li><li>支持快速的关键词查找</li><li>优化存储和查询效率</li></ul><p><strong>向量索引</strong>：</p><ul><li>使用HNSW、IVF等算法</li><li>支持高效的近似最近邻搜索</li><li>平衡精度和速度</li></ul><h3 id="查询优化"><a href="#查询优化" class="headerlink" title="查询优化"></a>查询优化</h3><p><strong>查询扩展</strong>：</p><ul><li>使用同义词扩展查询</li><li>基于用户反馈调整查询</li><li>利用查询日志优化</li></ul><p><strong>查询重写</strong>：</p><ul><li>将自然语言查询转换为结构化查询</li><li>使用查询模板提高效率</li><li>基于历史查询进行优化</li></ul><h3 id="缓存策略"><a href="#缓存策略" class="headerlink" title="缓存策略"></a>缓存策略</h3><p><strong>结果缓存</strong>：</p><ul><li>缓存热门查询的结果</li><li>使用LRU等策略管理缓存</li><li>提高响应速度</li></ul><p><strong>索引缓存</strong>：</p><ul><li>将常用索引加载到内存</li><li>使用分层缓存策略</li><li>优化内存使用</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;继续准备 LLM 面试知识，这次写文本检索技术。文本检索是 RAG（检索增强生成）系统的核心组件，也是面试中经常被问到的问题。本文将详细介绍稠密向量检索、稀疏向量检索、BM25算法以及混合检索策略，帮助理解现代文本检索系统的技术原理。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="RAG" scheme="https://murphypei.github.io/tags/RAG/"/>
    
      <category term="文本检索" scheme="https://murphypei.github.io/tags/%E6%96%87%E6%9C%AC%E6%A3%80%E7%B4%A2/"/>
    
      <category term="向量检索" scheme="https://murphypei.github.io/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/"/>
    
      <category term="BM25" scheme="https://murphypei.github.io/tags/BM25/"/>
    
  </entry>
  
  <entry>
    <title>LLM 幻觉与重复问题</title>
    <link href="https://murphypei.github.io//blog/2025/06/llm-hallucination-repetition.html"/>
    <id>https://murphypei.github.io//blog/2025/06/llm-hallucination-repetition.html</id>
    <published>2025-06-27T00:31:30.000Z</published>
    <updated>2025-07-01T12:40:54.832Z</updated>
    
    <content type="html"><![CDATA[<p>LLM 的幻觉和重复问题是 LLM 应用中的核心挑战，也是面试中经常被问到的问题。本文将从底层机理出发，深入分析这两个问题的成因，并探讨有效的解决方案。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>大语言模型（LLM）在近年来取得了巨大的成功，但同时也面临着两个关键问题：<strong>幻觉（Hallucination）</strong>和<strong>重复（Repetition）</strong>。这些问题不仅影响了模型的实用性，也阻碍了其在关键领域的应用。本文将从底层机理出发，深入分析这两个问题的成因，并探讨有效的解决方案。</p><h2 id="幻觉问题（Hallucination）"><a href="#幻觉问题（Hallucination）" class="headerlink" title="幻觉问题（Hallucination）"></a>幻觉问题（Hallucination）</h2><h3 id="幻觉的基本概念"><a href="#幻觉的基本概念" class="headerlink" title="幻觉的基本概念"></a>幻觉的基本概念</h3><p>幻觉是指LLM生成的内容与事实不符，包括：</p><ul><li><strong>事实性幻觉</strong>：生成错误的事实信息</li><li><strong>逻辑性幻觉</strong>：推理过程存在逻辑错误</li><li><strong>引用性幻觉</strong>：虚构不存在的引用或来源</li></ul><h3 id="幻觉产生的底层机理"><a href="#幻觉产生的底层机理" class="headerlink" title="幻觉产生的底层机理"></a>幻觉产生的底层机理</h3><h4 id="1-训练数据质量问题"><a href="#1-训练数据质量问题" class="headerlink" title="1. 训练数据质量问题"></a>1. 训练数据质量问题</h4><p><strong>数据噪声与错误</strong></p><ul><li>训练数据中本身就包含错误信息</li><li>网络爬取的数据质量参差不齐</li><li>标注错误导致模型学习到错误的知识</li></ul><p><strong>数据分布偏差</strong></p><ul><li>某些领域的数据过于稀少</li><li>时间性信息过时（如2023年之前的数据）</li><li>地域性偏见导致知识覆盖不均</li></ul><h4 id="2-Attention机制的局限性"><a href="#2-Attention机制的局限性" class="headerlink" title="2. Attention机制的局限性"></a>2. Attention机制的局限性</h4><p>根据<a href="https://arxiv.org/html/2504.04600v1" target="_blank" rel="noopener">Attention理论</a>，Attention机制本质上是一个2体相互作用系统：</p><script type="math/tex; mode=display">\mathcal{P}(\mathbf{x}) = \mathbf{N}^{(0)}\mathsf{W}_V\mathbf{x}^{\mathrm{T}}</script><p>其中：</p><ul><li>$\mathbf{N}^{(0)}$ 是上下文向量</li><li>$\mathsf{W}_V$ 是Value投影矩阵</li><li>$\mathbf{x}$ 是词汇表中的token</li></ul><p><strong>Attention机制的固有问题</strong>：</p><ol><li><strong>局部性限制</strong>：Attention主要关注局部相关性，难以捕捉全局一致性</li><li><strong>缺乏事实验证</strong>：模型无法验证生成内容的真实性</li><li><strong>过度依赖训练数据</strong>：当遇到训练数据中未覆盖的情况时，容易产生幻觉</li></ol><p><strong>物理机制解释</strong>：</p><p>从物理学的角度来看，Attention机制类似于一个自旋浴系统：</p><ul><li><strong>自旋状态</strong>：每个token对应一个自旋向量 $\mathbf{S}_i$</li><li><strong>相互作用</strong>：通过2体相互作用计算注意力权重</li><li><strong>相位分离</strong>：在特定条件下，系统会出现”好”与”坏”内容的相位分离</li></ul><p>这种物理机制解释了为什么模型在某些情况下会倾向于生成不准确的内容。</p><h4 id="3-训练目标与事实性不匹配"><a href="#3-训练目标与事实性不匹配" class="headerlink" title="3. 训练目标与事实性不匹配"></a>3. 训练目标与事实性不匹配</h4><p><strong>最大似然估计的局限性</strong></p><ul><li>训练目标是最小化预测下一个token的损失</li><li>这个目标并不直接优化事实准确性</li><li>模型可能为了流畅性而牺牲准确性</li></ul><p><strong>缺乏事实性监督</strong></p><ul><li>训练过程中没有明确的事实性约束</li><li>模型无法区分事实性内容和创造性内容</li></ul><h3 id="缓解和消除幻觉的方法"><a href="#缓解和消除幻觉的方法" class="headerlink" title="缓解和消除幻觉的方法"></a>缓解和消除幻觉的方法</h3><h4 id="1-数据层面的改进"><a href="#1-数据层面的改进" class="headerlink" title="1. 数据层面的改进"></a>1. 数据层面的改进</h4><p><strong>高质量数据收集</strong></p><ul><li>结合多个高质量数据源</li><li>使用事实性强的数据（如维基百科、学术论文）</li><li>建立数据质量评估体系</li></ul><p><strong>数据清洗与验证</strong></p><ul><li>自动检测和移除错误数据</li><li>使用外部知识库验证数据准确性</li><li>建立数据版本控制机制</li></ul><p><strong>知识注入技术</strong></p><ul><li>将结构化知识（如知识图谱）注入训练数据</li><li>使用检索增强生成（RAG）技术</li><li>结合外部知识库进行训练</li></ul><h4 id="2-模型架构的改进"><a href="#2-模型架构的改进" class="headerlink" title="2. 模型架构的改进"></a>2. 模型架构的改进</h4><p><strong>改进的Attention机制</strong></p><ul><li>引入多步推理机制</li><li>使用思维链（Chain-of-Thought）提示</li><li>实现推理过程的显式建模</li></ul><p><strong>事实性约束</strong></p><ul><li>在Attention中加入事实性约束</li><li>使用外部知识库指导注意力分配</li><li>实现事实性验证的端到端训练</li></ul><p><strong>检索增强生成（RAG）</strong></p><ul><li>在生成过程中实时检索相关信息</li><li>使用向量数据库存储知识</li><li>实现检索与生成的联合优化</li></ul><h4 id="3-训练策略的改进"><a href="#3-训练策略的改进" class="headerlink" title="3. 训练策略的改进"></a>3. 训练策略的改进</h4><p><strong>事实性监督</strong></p><ul><li>设计专门的事实性损失函数</li><li>使用外部知识库计算事实性得分</li><li>在训练中平衡流畅性和事实性</li></ul><p><strong>对比学习</strong></p><ul><li>使用对比学习区分事实性和非事实性内容</li><li>训练模型识别和避免幻觉</li></ul><p><strong>强化学习优化</strong></p><ul><li>设计基于事实准确性的奖励函数</li><li>使用PPO等算法优化事实性</li><li>实现事实性与流畅性的平衡</li></ul><h4 id="4-推理阶段的改进"><a href="#4-推理阶段的改进" class="headerlink" title="4. 推理阶段的改进"></a>4. 推理阶段的改进</h4><p><strong>后处理验证</strong></p><ul><li>使用外部工具验证生成内容的真实性</li><li>实现自动的事实性评分</li><li>对低置信度的内容进行标记</li></ul><p><strong>多模型验证</strong></p><ul><li>使用多个模型交叉验证</li><li>实现模型集成提高准确性</li></ul><p><strong>不确定性量化</strong></p><ul><li>为生成内容提供置信度分数</li><li>实现不确定性量化</li><li>帮助用户判断内容的可靠性</li></ul><h2 id="重复问题（Repetition）"><a href="#重复问题（Repetition）" class="headerlink" title="重复问题（Repetition）"></a>重复问题（Repetition）</h2><h3 id="重复问题的基本概念"><a href="#重复问题的基本概念" class="headerlink" title="重复问题的基本概念"></a>重复问题的基本概念</h3><p>重复问题表现为：</p><ul><li><strong>词汇重复</strong>：同一个词或短语反复出现</li><li><strong>结构重复</strong>：相似的句子结构重复使用</li><li><strong>内容重复</strong>：相同的信息多次表达</li></ul><h3 id="重复产生的底层机理"><a href="#重复产生的底层机理" class="headerlink" title="重复产生的底层机理"></a>重复产生的底层机理</h3><h4 id="1-训练数据的重复模式"><a href="#1-训练数据的重复模式" class="headerlink" title="1. 训练数据的重复模式"></a>1. 训练数据的重复模式</h4><p><strong>数据中的重复模式</strong></p><ul><li>训练数据中存在大量重复内容</li><li>某些表达方式在数据中频繁出现</li><li>模型学习到了这些重复模式</li></ul><p><strong>注意力机制的偏好</strong></p><ul><li>模型倾向于关注高频出现的模式</li><li>重复内容往往具有较高的注意力权重</li></ul><h4 id="2-生成策略的影响"><a href="#2-生成策略的影响" class="headerlink" title="2. 生成策略的影响"></a>2. 生成策略的影响</h4><p><strong>贪婪解码的局限性</strong></p><ul><li>每次都选择概率最高的token</li><li>容易陷入局部最优，导致重复</li></ul><p><strong>缺乏多样性约束</strong></p><ul><li>没有明确的多样性目标</li><li>模型倾向于选择”安全”的重复模式</li></ul><h4 id="3-上下文窗口的限制"><a href="#3-上下文窗口的限制" class="headerlink" title="3. 上下文窗口的限制"></a>3. 上下文窗口的限制</h4><p><strong>长距离依赖问题</strong></p><ul><li>模型难以记住之前生成的内容</li><li>在生成长文本时容易重复</li></ul><p><strong>注意力衰减</strong></p><ul><li>随着序列长度增加，注意力权重衰减</li><li>导致模型”忘记”之前的内容</li></ul><h3 id="缓解和消除重复的方法"><a href="#缓解和消除重复的方法" class="headerlink" title="缓解和消除重复的方法"></a>缓解和消除重复的方法</h3><h4 id="1-解码策略的改进"><a href="#1-解码策略的改进" class="headerlink" title="1. 解码策略的改进"></a>1. 解码策略的改进</h4><p><strong>多样性解码</strong></p><p><strong>核采样（Nucleus Sampling）</strong></p><ul><li>只从累积概率达到阈值的token中采样</li><li>避免选择过于保守的token</li><li>在保持质量的同时增加多样性</li></ul><p><strong>温度调节</strong></p><ul><li>使用温度参数控制采样的随机性</li><li>在生成过程中动态调整温度</li><li>平衡创造性和一致性</li></ul><p><strong>重复惩罚</strong></p><ul><li>对重复出现的token进行惩罚</li><li>使用n-gram级别的重复检测</li><li>实现自适应的重复惩罚机制</li></ul><p><strong>长度惩罚</strong></p><ul><li>对过长的重复序列进行惩罚</li><li>鼓励模型生成更简洁的内容</li></ul><h4 id="2-模型架构的改进-1"><a href="#2-模型架构的改进-1" class="headerlink" title="2. 模型架构的改进"></a>2. 模型架构的改进</h4><p><strong>改进的注意力机制</strong></p><p><strong>相对位置编码</strong></p><ul><li>使用相对位置编码代替绝对位置编码</li><li>更好地处理长序列</li><li>减少位置相关的重复</li></ul><p><strong>稀疏注意力</strong></p><ul><li>使用稀疏注意力减少计算复杂度</li><li>提高长文本的处理能力</li><li>减少注意力衰减问题</li></ul><p><strong>记忆机制</strong></p><ul><li>使用外部记忆存储重要信息</li><li>实现长期依赖的建模</li><li>减少重复生成相同内容</li></ul><p><strong>分层记忆</strong></p><ul><li>实现短期和长期记忆的分离</li><li>使用不同的记忆机制处理不同时间尺度的信息</li></ul><h4 id="3-训练策略的改进-1"><a href="#3-训练策略的改进-1" class="headerlink" title="3. 训练策略的改进"></a>3. 训练策略的改进</h4><p><strong>多样性训练</strong></p><p><strong>多样性损失</strong></p><ul><li>在训练中加入多样性损失</li><li>鼓励模型生成多样化的内容</li><li>平衡一致性和创造性</li></ul><p><strong>对抗训练</strong></p><ul><li>使用对抗训练提高多样性</li><li>训练判别器识别重复内容</li><li>实现生成器和判别器的博弈</li></ul><p><strong>课程学习</strong></p><ul><li>从简单任务开始，逐步增加复杂度</li><li>在训练过程中引入多样性约束</li><li>实现更好的泛化能力</li></ul><h4 id="4-推理阶段的改进-1"><a href="#4-推理阶段的改进-1" class="headerlink" title="4. 推理阶段的改进"></a>4. 推理阶段的改进</h4><p><strong>动态调整</strong></p><p><strong>自适应解码</strong></p><ul><li>根据上下文动态调整解码策略</li><li>实现智能的重复检测和避免</li><li>使用机器学习优化解码参数</li></ul><p><strong>多候选生成</strong></p><ul><li>生成多个候选序列</li><li>使用多样性指标选择最佳序列</li><li>实现更好的内容质量</li></ul><p><strong>后处理优化</strong></p><ul><li>使用规则或机器学习方法检测重复</li><li>自动移除或改写重复内容</li><li>实现智能的内容优化</li></ul><p><strong>风格一致性</strong></p><ul><li>保持生成内容的风格一致性</li><li>避免风格上的重复</li><li>实现更自然的文本生成</li></ul><h2 id="幻觉与重复问题的关系"><a href="#幻觉与重复问题的关系" class="headerlink" title="幻觉与重复问题的关系"></a>幻觉与重复问题的关系</h2><h3 id="共同根源"><a href="#共同根源" class="headerlink" title="共同根源"></a>共同根源</h3><p><strong>训练数据问题</strong></p><ul><li>数据质量差是幻觉和重复的共同原因</li><li>数据分布不均匀导致模型学习到错误的模式</li></ul><p><strong>Attention机制的局限性</strong></p><ul><li>2体相互作用的限制</li><li>难以处理复杂的全局关系</li></ul><p><strong>训练目标的不完善</strong></p><ul><li>缺乏对事实性和多样性的直接优化</li><li>过度依赖局部最优</li></ul><h3 id="相互影响"><a href="#相互影响" class="headerlink" title="相互影响"></a>相互影响</h3><p><strong>幻觉导致重复</strong></p><ul><li>当模型不确定时，倾向于重复”安全”的内容</li><li>幻觉内容可能被模型认为是正确的，从而重复生成</li></ul><p><strong>重复加剧幻觉</strong></p><ul><li>重复生成错误内容会强化幻觉</li><li>缺乏多样性限制了模型的探索能力</li></ul><h3 id="联合解决方案"><a href="#联合解决方案" class="headerlink" title="联合解决方案"></a>联合解决方案</h3><p><strong>统一的数据策略</strong></p><ul><li>同时提高数据的准确性和多样性</li><li>建立综合的数据质量评估体系</li></ul><p><strong>改进的模型架构</strong></p><ul><li>设计同时解决幻觉和重复的架构</li><li>引入全局一致性和多样性约束</li></ul><p><strong>综合的训练目标</strong></p><ul><li>平衡事实性、流畅性和多样性</li><li>使用多目标优化方法</li></ul><h2 id="未来发展方向"><a href="#未来发展方向" class="headerlink" title="未来发展方向"></a>未来发展方向</h2><h3 id="理论突破"><a href="#理论突破" class="headerlink" title="理论突破"></a>理论突破</h3><p><strong>3体Attention机制</strong><br>根据物理学理论，当前的Attention是2体相互作用，未来可能发展出3体Attention机制，能够更好地处理复杂的关系和依赖。</p><p><strong>量子计算的应用</strong><br>量子计算可能为Attention机制提供新的计算范式，实现更高效的注意力计算。</p><h3 id="技术融合"><a href="#技术融合" class="headerlink" title="技术融合"></a>技术融合</h3><p><strong>多模态融合</strong><br>结合视觉、听觉等多种模态信息，提高模型的理解能力和生成质量。</p><p><strong>知识图谱集成</strong><br>深度集成知识图谱，实现更准确的事实性生成。</p><h3 id="评估体系"><a href="#评估体系" class="headerlink" title="评估体系"></a>评估体系</h3><p><strong>标准化评估</strong><br>建立标准化的幻觉和重复评估体系，为模型改进提供客观指标。</p><p><strong>实时监控</strong><br>实现生成过程的实时监控，及时发现和纠正问题。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>LLM的幻觉和重复问题是当前AI发展面临的重要挑战。通过深入理解其底层机理，我们可以从数据、模型架构、训练策略和推理优化等多个层面来缓解这些问题。随着技术的不断进步，我们有理由相信这些问题将得到更好的解决，推动LLM技术向更高水平发展。</p><p><strong>关键要点</strong>：</p><ol><li><strong>幻觉问题</strong>：主要由训练数据质量、Attention机制局限性和训练目标不匹配导致</li><li><strong>重复问题</strong>：主要由训练数据重复模式、生成策略局限性和上下文窗口限制导致</li><li><strong>解决方案</strong>：需要从数据、架构、训练和推理多个层面综合改进</li><li><strong>未来方向</strong>：3体Attention、多模态融合、标准化评估体系</li></ol><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://arxiv.org/html/2504.04600v1" target="_blank" rel="noopener">Capturing AI’s Attention: Physics of Repetition, Hallucination, Bias and Beyond</a></li><li><a href="https://zhuanlan.zhihu.com/p/677935286" target="_blank" rel="noopener">大语言模型幻觉问题研究综述</a></li><li><a href="https://www.secrss.com/articles/73856" target="_blank" rel="noopener">LLM幻觉问题的深度分析</a></li><li><a href="https://zhuanlan.zhihu.com/p/682647518" target="_blank" rel="noopener">大语言模型重复问题解决方案</a></li><li><a href="https://zhuanlan.zhihu.com/p/1897569693658744522" target="_blank" rel="noopener">Attention机制的物理基础</a></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;LLM 的幻觉和重复问题是 LLM 应用中的核心挑战，也是面试中经常被问到的问题。本文将从底层机理出发，深入分析这两个问题的成因，并探讨有效的解决方案。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="幻觉" scheme="https://murphypei.github.io/tags/%E5%B9%BB%E8%A7%89/"/>
    
      <category term="重复" scheme="https://murphypei.github.io/tags/%E9%87%8D%E5%A4%8D/"/>
    
      <category term="Attention机制" scheme="https://murphypei.github.io/tags/Attention%E6%9C%BA%E5%88%B6/"/>
    
      <category term="模型训练" scheme="https://murphypei.github.io/tags/%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/"/>
    
  </entry>
  
  <entry>
    <title>LLM 训练：PPO 和 DPO</title>
    <link href="https://murphypei.github.io//blog/2025/06/llm-ppo-dpo.html"/>
    <id>https://murphypei.github.io//blog/2025/06/llm-ppo-dpo.html</id>
    <published>2025-06-24T12:44:51.000Z</published>
    <updated>2025-07-23T09:37:09.810Z</updated>
    
    <content type="html"><![CDATA[<p>已经接近 3 年没有更新博客了。今天立下一个 flag，开始准备 LLM 面试知识，主要是八股文为主，想到哪写到哪。第一篇没想到写啥，觉得对 PPO 和 DPO 比较了解，就先直接写这个吧。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>在大语言模型（LLM）的训练过程中，RLHF（Reinforcement Learning from Human Feedback）是一个重要的技术，它通过人类反馈来优化模型的行为。在 RLHF 中，PPO（Proximal Policy Optimization）和 DPO（Direct Preference Optimization）是两种主流的算法。本文将详细介绍这两种算法的工作原理、数学推导以及它们之间的区别。</p><h2 id="PPO（Proximal-Policy-Optimization）"><a href="#PPO（Proximal-Policy-Optimization）" class="headerlink" title="PPO（Proximal Policy Optimization）"></a>PPO（Proximal Policy Optimization）</h2><h3 id="PPO-基本原理"><a href="#PPO-基本原理" class="headerlink" title="PPO 基本原理"></a>PPO 基本原理</h3><p>PPO 是一种基于策略梯度的强化学习算法，它的核心思想是通过限制策略更新的步长来保证训练的稳定性。在 RLHF 中，PPO 被用来优化语言模型，使其生成更符合人类偏好的回答。</p><h3 id="PPO-的数学推导"><a href="#PPO-的数学推导" class="headerlink" title="PPO 的数学推导"></a>PPO 的数学推导</h3><h4 id="1-策略梯度定理"><a href="#1-策略梯度定理" class="headerlink" title="1. 策略梯度定理"></a>1. 策略梯度定理</h4><p>首先，我们回顾一下策略梯度定理。对于策略 $\pi_\theta$，目标函数为：</p><script type="math/tex; mode=display">J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} [R(\tau)]</script><p>其中 $\tau$ 是轨迹，$R(\tau)$ 是轨迹的奖励。</p><p><strong>策略梯度定理</strong>是强化学习中的一个核心定理，它告诉我们如何直接优化策略参数 $\theta$ 来最大化期望奖励。这个定理的重要性在于：</p><ol><li><strong>直接优化策略</strong>：不像价值函数方法需要先学习价值函数再推导策略，策略梯度方法直接优化策略参数</li><li><strong>理论基础</strong>：为所有基于策略的强化学习算法提供了数学基础</li><li><strong>适用性广</strong>：适用于连续动作空间和离散动作空间</li></ol><p>策略梯度定理告诉我们：</p><script type="math/tex; mode=display">\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} [\nabla_\theta \log \pi_\theta(\tau) R(\tau)]</script><p>这个公式的含义是：</p><ul><li><strong>左侧</strong>：目标函数 $J(\theta)$ 关于参数 $\theta$ 的梯度</li><li><strong>右侧</strong>：策略对数概率的梯度与奖励的乘积的期望</li></ul><p><strong>直观理解</strong>：</p><ul><li>如果某个轨迹 $\tau$ 的奖励 $R(\tau)$ 很高，我们就增加这个轨迹的概率</li><li>如果某个轨迹 $\tau$ 的奖励 $R(\tau)$ 很低，我们就减少这个轨迹的概率</li><li>$\nabla_\theta \log \pi_\theta(\tau)$ 告诉我们在参数空间中应该朝哪个方向移动</li></ul><p><strong>实际应用中的问题</strong>：</p><ol><li><strong>高方差</strong>：直接使用这个公式会导致训练不稳定</li><li><strong>样本效率低</strong>：需要大量样本来估计期望</li><li><strong>更新步长难以控制</strong>：可能导致策略更新过大或过小</li></ol><p>这就是为什么需要 PPO 等改进算法的原因。</p><h4 id="2-PPO-的目标函数"><a href="#2-PPO-的目标函数" class="headerlink" title="2. PPO 的目标函数"></a>2. PPO 的目标函数</h4><p>PPO 通过引入一个比率项来限制策略更新的幅度：</p><script type="math/tex; mode=display">r_t(\theta) = \frac{\pi_\theta(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}</script><p><strong>比率项的含义</strong>：</p><ul><li>$\pi_{\theta_{old}}(a_t|s_t)$ 是旧策略（更新前）在状态 $s_t$ 下选择动作 $a_t$ 的概率</li><li>$\pi_\theta(a_t|s_t)$ 是新策略（更新后）在状态 $s_t$ 下选择动作 $a_t$ 的概率</li><li>比率 $r_t(\theta)$ 衡量了新策略相对于旧策略的变化程度</li></ul><p><strong>为什么需要限制策略更新幅度</strong>：</p><ol><li><strong>防止策略崩溃</strong>：如果策略更新过大，可能导致某些动作的概率变为 0，失去探索能力</li><li><strong>保证训练稳定性</strong>：过大的更新步长会导致训练不稳定，甚至发散</li><li><strong>避免灾难性遗忘</strong>：防止新策略完全偏离旧策略，丢失之前学到的有用知识</li></ol><p>PPO 的目标函数为：</p><script type="math/tex; mode=display">L^{CLIP}(\theta) = \mathbb{E}_t [\min(r_t(\theta) A_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon) A_t)]</script><p>这个公式的核心思想是：</p><ul><li>如果 $A_t &gt; 0$（好的动作），我们希望增加这个动作的概率，但最多只能增加到 $(1+\epsilon)$ 倍</li><li>如果 $A_t &lt; 0$（坏的动作），我们希望减少这个动作的概率，但最多只能减少到 $(1-\epsilon)$ 倍</li><li>$\epsilon$ 通常设置为 0.2，意味着策略更新幅度被限制在 ±20% 以内</li></ul><p>其中：</p><ul><li>$A_t$ 是优势函数（Advantage function）</li><li>$\epsilon$ 是裁剪参数，通常设置为 0.2</li><li>$\text{clip}(x, a, b)$ 函数将 $x$ 限制在 $[a, b]$ 范围内</li></ul><h4 id="3-优势函数"><a href="#3-优势函数" class="headerlink" title="3. 优势函数"></a>3. 优势函数</h4><p>优势函数衡量了某个动作相对于平均水平的优势：</p><script type="math/tex; mode=display">A_t = Q(s_t, a_t) - V(s_t)</script><p>其中 $Q(s_t, a_t)$ 是动作价值函数，$V(s_t)$ 是状态价值函数。</p><p><strong>价值函数的基本概念</strong>：</p><p>在强化学习中，价值函数用于评估状态或状态-动作对的价值，帮助我们做出更好的决策。</p><p><strong>状态价值函数 $V(s_t)$</strong>：</p><ul><li><strong>定义</strong>：在状态 $s_t$ 下，遵循策略 $\pi$ 的期望累积奖励</li><li><strong>数学表达式</strong>：<script type="math/tex; mode=display">V^\pi(s_t) = \mathbb{E}_{\pi} [\sum_{k=0}^{\infty} \gamma^k R_{t+k} | S_t = s_t]</script></li><li><strong>含义</strong>：表示从状态 $s_t$ 开始，按照策略 $\pi$ 行动，能够获得的期望总奖励</li><li><strong>特点</strong>：只依赖于状态，不依赖于具体动作</li></ul><p><strong>动作价值函数 $Q(s_t, a_t)$</strong>：</p><ul><li><strong>定义</strong>：在状态 $s_t$ 下采取动作 $a_t$，然后遵循策略 $\pi$ 的期望累积奖励</li><li><strong>数学表达式</strong>：<script type="math/tex; mode=display">Q^\pi(s_t, a_t) = \mathbb{E}_{\pi} [\sum_{k=0}^{\infty} \gamma^k R_{t+k} | S_t = s_t, A_t = a_t]</script></li><li><strong>含义</strong>：表示在状态 $s_t$ 下采取动作 $a_t$，然后按照策略 $\pi$ 行动，能够获得的期望总奖励</li><li><strong>特点</strong>：依赖于状态和动作的组合</li></ul><p><strong>优势函数 $A_t$ 的作用</strong>：</p><ul><li><strong>相对评估</strong>：优势函数衡量了某个动作相对于该状态下所有动作平均水平的优势</li><li><strong>决策指导</strong>：<ul><li>如果 $A_t &gt; 0$，说明动作 $a_t$ 比平均水平好，应该增加其概率</li><li>如果 $A_t &lt; 0$，说明动作 $a_t$ 比平均水平差，应该减少其概率</li><li>如果 $A_t = 0$，说明动作 $a_t$ 处于平均水平</li></ul></li></ul><p><strong>在 PPO 中的重要性</strong>：</p><ol><li><strong>减少方差</strong>：相比直接使用奖励，优势函数提供了更稳定的学习信号</li><li><strong>基线作用</strong>：状态价值函数作为基线，减少了策略梯度的方差</li><li><strong>相对比较</strong>：通过相对比较而不是绝对奖励，使得训练更加稳定</li></ol><p><strong>实际计算中的挑战</strong>：</p><ul><li>真实的价值函数通常是未知的，需要通过神经网络来估计</li><li>这就是为什么 PPO 需要 Critic 模型来估计状态价值函数</li><li>优势函数通常通过时序差分（TD）方法或其他技术来估计</li></ul><h3 id="PPO-在-RLHF-中的应用"><a href="#PPO-在-RLHF-中的应用" class="headerlink" title="PPO 在 RLHF 中的应用"></a>PPO 在 RLHF 中的应用</h3><p>在 RLHF 中，PPO 需要四个模型：</p><ol><li><strong>Actor Model</strong>：被训练的策略模型</li><li><strong>Critic Model</strong>：价值函数模型，用于估计状态价值</li><li><strong>Reward Model</strong>：奖励模型，用于计算即时奖励</li><li><strong>Reference Model</strong>：参考模型，用于防止策略偏离太远</li></ol><p>关于这 4 个模型，可以参考我之前的文章：<a href="https://murphypei.github.io/blog/2024/07/llm-rlhf-ppo.html">大模型 RLHF 训练中的 PPO 算法细节</a></p><p><strong>四个模型的作用和特点</strong>：</p><p><strong>Actor Model（策略模型）</strong>：</p><ul><li>这是我们要训练的主要模型，最终用于实际应用</li><li>接收 prompt，生成 response</li><li>在训练过程中，其参数会不断更新以优化策略</li></ul><p><strong>Critic Model（价值函数模型）</strong>：</p><ul><li>用于估计状态价值函数 $V(s_t)$</li><li>通常用 Reward Model 初始化，架构与 Actor 相似</li><li>在最后一层增加 Value Head，输出单一的价值估计</li><li>需要更新参数，因为价值估计能力需要不断提升</li></ul><p><strong>Reward Model（奖励模型）</strong>：</p><ul><li>计算即时奖励 $R_t$，评估当前 response 的好坏</li><li>参数固定不更新，作为客观的评估标准</li><li>只关心当前 response 的质量，不考虑长期影响</li></ul><p><strong>Reference Model（参考模型）</strong>：</p><ul><li>通常用 SFT 模型初始化，参数冻结</li><li>主要作用是防止 Actor”训歪”，避免过拟合到高分但无意义的回答</li><li>通过 KL 散度约束，确保新策略与参考策略的输出分布相似</li></ul><p><strong>为什么需要四个模型</strong>：</p><ol><li><strong>Actor</strong>：学习生成符合人类偏好的回答</li><li><strong>Critic</strong>：评估整体价值，减少训练方差</li><li><strong>Reward</strong>：提供客观的即时评估标准</li><li><strong>Reference</strong>：防止策略偏离太远，保持语言能力</li></ol><p>PPO 的损失函数包括三个部分：</p><script type="math/tex; mode=display">L_{PPO} = L^{CLIP} - \alpha L^{KL} + \beta L^{VF}</script><p>其中：</p><ul><li>$L^{CLIP}$ 是 PPO 的主要损失，通过裁剪机制限制策略更新</li><li>$L^{KL}$ 是 KL 散度损失，用于限制与参考模型的差异</li><li>$L^{VF}$ 是价值函数损失，用于训练 Critic 模型</li><li>$\alpha$ 和 $\beta$ 是权重参数，平衡不同损失项的重要性</li></ul><p><strong>训练流程</strong>：</p><ol><li>Actor 接收 prompt，生成 response</li><li>Reward Model 计算即时奖励</li><li>Critic Model 估计状态价值</li><li>计算优势函数 $A_t = R_t - V_t$</li><li>使用 PPO 损失函数更新 Actor 和 Critic 参数</li><li>通过 KL 散度约束确保与 Reference Model 的相似性</li></ol><h2 id="DPO（Direct-Preference-Optimization）"><a href="#DPO（Direct-Preference-Optimization）" class="headerlink" title="DPO（Direct Preference Optimization）"></a>DPO（Direct Preference Optimization）</h2><h3 id="DPO-基本原理"><a href="#DPO-基本原理" class="headerlink" title="DPO 基本原理"></a>DPO 基本原理</h3><p>DPO 是一种更直接的方法，它不需要显式的奖励模型，而是直接通过人类偏好数据来优化策略。DPO 的核心思想是将偏好学习问题转化为一个分类问题。</p><p><strong>DPO 的核心创新</strong>：</p><ol><li><strong>消除奖励模型</strong>：不需要单独训练奖励模型，简化了训练流程</li><li><strong>直接偏好学习</strong>：直接从人类偏好数据中学习，避免了奖励建模的误差</li><li><strong>理论等价性</strong>：证明了 DPO 与基于奖励模型的 RLHF 在理论上是等价的</li></ol><h3 id="DPO-的数学推导"><a href="#DPO-的数学推导" class="headerlink" title="DPO 的数学推导"></a>DPO 的数学推导</h3><h4 id="1-偏好学习问题"><a href="#1-偏好学习问题" class="headerlink" title="1. 偏好学习问题"></a>1. 偏好学习问题</h4><p>给定一个提示 $x$ 和两个回答 $y_w$（获胜）和 $y_l$（失败），我们的目标是学习一个策略 $\pi_\theta$，使得：</p><script type="math/tex; mode=display">P(y_w \succ y_l | x) > P(y_l \succ y_w | x)</script><p><strong>偏好数据的含义</strong>：</p><ul><li>$y_w \succ y_l$ 表示在提示 $x$ 下，回答 $y_w$ 比 $y_l$ 更受人类偏好</li><li>这种偏好关系反映了人类的价值判断，是 RLHF 的核心数据</li></ul><h4 id="2-Bradley-Terry-模型"><a href="#2-Bradley-Terry-模型" class="headerlink" title="2. Bradley-Terry 模型"></a>2. Bradley-Terry 模型</h4><p>DPO 使用 Bradley-Terry 模型来建模偏好。这个模型假设偏好概率与奖励函数之间存在以下关系：</p><script type="math/tex; mode=display">P(y_w \succ y_l | x) = \frac{\exp(r_\theta(x, y_w))}{\exp(r_\theta(x, y_w)) + \exp(r_\theta(x, y_l))}</script><p>其中 $r_\theta(x, y)$ 是奖励函数。</p><p><strong>Bradley-Terry 模型的特点</strong>：</p><ul><li><strong>单调性</strong>：奖励越高，被偏好的概率越大</li><li><strong>对称性</strong>：$P(y_w \succ y_l | x) + P(y_l \succ y_w | x) = 1$</li><li><strong>温度控制</strong>：可以通过调整指数函数的温度参数来控制偏好强度</li></ul><h4 id="3-从奖励函数到策略的映射"><a href="#3-从奖励函数到策略的映射" class="headerlink" title="3. 从奖励函数到策略的映射"></a>3. 从奖励函数到策略的映射</h4><p>DPO 的关键洞察是：我们可以将奖励函数表示为策略与参考策略的比值：</p><script type="math/tex; mode=display">r_\theta(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}</script><p>其中：</p><ul><li>$\pi_{ref}$ 是参考策略（通常是 SFT 模型）</li><li>$\beta$ 是温度参数，控制奖励的强度</li></ul><p><strong>这个映射的物理意义</strong>：</p><ul><li>如果 $\pi_\theta(y|x) &gt; \pi_{ref}(y|x)$，说明新策略更倾向于生成回答 $y$，奖励为正</li><li>如果 $\pi_\theta(y|x) &lt; \pi_{ref}(y|x)$，说明新策略不太倾向于生成回答 $y$，奖励为负</li><li>$\beta$ 控制奖励的敏感度，值越大，策略差异对奖励的影响越明显</li></ul><h4 id="4-DPO-的目标函数"><a href="#4-DPO-的目标函数" class="headerlink" title="4. DPO 的目标函数"></a>4. DPO 的目标函数</h4><p>将奖励函数代入 Bradley-Terry 模型，得到 DPO 的目标函数：</p><script type="math/tex; mode=display">L_{DPO} = -\mathbb{E}_{(x, y_w, y_l) \sim D} \left[\log \sigma\left(\beta \log \frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}\right)\right]</script><p>其中：</p><ul><li>$\sigma$ 是 sigmoid 函数：$\sigma(x) = \frac{1}{1 + e^{-x}}$</li><li>$\beta$ 是温度参数，通常设置为 0.1-0.5</li><li>$\pi_{ref}$ 是参考策略（通常是 SFT 模型）</li></ul><p><strong>目标函数的直观理解</strong>：</p><ul><li>我们希望最大化偏好数据的对数似然</li><li>对于偏好对 $(y_w, y_l)$，我们希望 $P(y_w \succ y_l | x)$ 尽可能大</li><li>这等价于让 $\beta \log \frac{\pi_\theta(y_w|x)}{\pi_{ref}(y_w|x)} - \beta \log \frac{\pi_\theta(y_l|x)}{\pi_{ref}(y_l|x)}$ 尽可能大</li><li>即让获胜回答相对于参考策略的提升幅度大于失败回答</li></ul><h4 id="5-奖励函数的推导"><a href="#5-奖励函数的推导" class="headerlink" title="5. 奖励函数的推导"></a>5. 奖励函数的推导</h4><p>通过 DPO 的训练，我们可以推导出隐含的奖励函数：</p><script type="math/tex; mode=display">r_\theta(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}</script><p>这个公式表明，DPO 实际上是在学习一个相对于参考策略的奖励函数。</p><p><strong>奖励函数的性质</strong>：</p><ol><li><strong>相对性</strong>：奖励是相对于参考策略定义的，不是绝对奖励</li><li><strong>可解释性</strong>：奖励直接反映了策略相对于参考策略的偏好程度</li><li><strong>一致性</strong>：与人类偏好数据保持一致</li></ol><h3 id="DPO-的训练过程"><a href="#DPO-的训练过程" class="headerlink" title="DPO 的训练过程"></a>DPO 的训练过程</h3><p><strong>训练步骤</strong>：</p><ol><li><strong>数据准备</strong>：收集人类偏好数据 $(x, y_w, y_l)$</li><li><strong>策略初始化</strong>：用 SFT 模型初始化 $\pi_\theta$ 和 $\pi_{ref}$</li><li><strong>前向传播</strong>：计算 $\pi_\theta(y_w|x)$ 和 $\pi_\theta(y_l|x)$</li><li><strong>损失计算</strong>：使用 DPO 损失函数计算梯度</li><li><strong>参数更新</strong>：只更新 $\pi_\theta$，保持 $\pi_{ref}$ 固定</li></ol><p><strong>关键超参数</strong>：</p><ul><li><strong>$\beta$（温度参数）</strong>：控制策略更新的强度，值越大更新越激进</li><li><strong>学习率</strong>：控制参数更新的步长</li><li><strong>批次大小</strong>：影响训练的稳定性和效率</li></ul><h3 id="DPO-损失计算的具体步骤"><a href="#DPO-损失计算的具体步骤" class="headerlink" title="DPO 损失计算的具体步骤"></a>DPO 损失计算的具体步骤</h3><p>为了更好地理解 DPO 的训练过程，我们来详细拆解针对一个具体样本的损失计算步骤。整个过程的核心思想是：<strong>直接利用偏好数据（哪个回答更好，哪个更差）来调整模型，让模型生成”更好”回答的概率变高，生成”更差”回答的概率变低。</strong></p><p>为了实现这个目标，DPO 的训练过程涉及两个模型：</p><ol><li><strong>策略模型 ($\pi_{\theta}$)</strong>：我们正在训练和优化的模型。它的参数在训练中会不断更新。</li><li><strong>参考模型 ($\pi_{ref}$)</strong>：一个固定的、不参与训练的模型。通常是策略模型在 DPO 训练开始前的初始版本（比如，经过 SFT 监督微调后的模型）。它的作用是作为一把”尺子”，防止策略模型在学习偏好的过程中偏离太远，忘掉其原有的语言能力。</li></ol><p>假设我们有以下一个训练样本：</p><ul><li><strong>Prompt (x)</strong>: “请介绍一下长城”</li><li><strong>Chosen (y_w)</strong>: “长城是古代中国为抵御侵略而修筑的军事工程。” (被标注为更好的回答)</li><li><strong>Rejected (y_l)</strong>: “长城是个墙，在中国。” (被标注为更差的回答)</li></ul><h4 id="第一步：计算两个回答在两个模型下的概率"><a href="#第一步：计算两个回答在两个模型下的概率" class="headerlink" title="第一步：计算两个回答在两个模型下的概率"></a>第一步：计算两个回答在两个模型下的概率</h4><p>模型处理的是 token 序列，而不是文字。假设经过分词后，两个回答的 token 序列如下：</p><ul><li><strong>y_w</strong>: <code>[&quot;长城&quot;, &quot;是&quot;, &quot;古代&quot;, &quot;中国&quot;, &quot;为&quot;, ...]</code></li><li><strong>y_l</strong>: <code>[&quot;长城&quot;, &quot;是&quot;, &quot;个&quot;, &quot;墙&quot;, &quot;，&quot;, ...]</code></li></ul><p>对于一个自回归语言模型来说，一个完整序列的概率是该序列中每个 token 的条件概率的乘积。在实际计算中，为了数值稳定性，我们通常使用对数概率（log probabilities）的加和。</p><p><strong>计算过程：</strong></p><ol><li><p><strong>对于 “Chosen” 回答 (y_w):</strong></p><ul><li>将 <code>Prompt (x)</code> 和 <code>Chosen (y_w)</code> 拼接起来，输入给<strong>策略模型 ($\pi_{\theta}$)</strong>。</li><li>模型会为 <code>y_w</code> 中的每一个 token 计算其生成的对数概率。例如，计算 P(“是” | “长城”)，P(“古代” | “长城是”)，以此类推。</li><li>将 <code>y_w</code> 序列中所有 token 的对数概率相加，得到<strong>策略模型</strong>认为生成 <code>y_w</code> 的总对数概率：$logP_{\pi_{\theta}}(y_w|x)$。</li><li>用同样的方法，将 <code>Prompt (x)</code> 和 <code>Chosen (y_w)</code> 输入给<strong>参考模型 ($\pi_{ref}$)</strong>，计算出<strong>参考模型</strong>认为生成 <code>y_w</code> 的总对数概率：$logP_{\pi_{ref}}(y_w|x)$。</li></ul></li><li><p><strong>对于 “Rejected” 回答 (y_l):</strong></p><ul><li>同样地，将 <code>Prompt (x)</code> 和 <code>Rejected (y_l)</code> 拼接后，分别输入给<strong>策略模型 ($\pi_{\theta}$)</strong> 和<strong>参考模型 ($\pi_{ref}$)</strong>。</li><li>计算出策略模型生成 <code>y_l</code> 的总对数概率：$logP_{\pi_{\theta}}(y_l|x)$。</li><li>计算出参考模型生成 <code>y_l</code> 的总对数概率：$logP_{\pi_{ref}}(y_l|x)$。</li></ul></li></ol><p>经过这一步，我们就得到了四个核心的对数概率值。</p><h4 id="第二步：计算隐式奖励-Implicit-Reward-或偏好度"><a href="#第二步：计算隐式奖励-Implicit-Reward-或偏好度" class="headerlink" title="第二步：计算隐式奖励 (Implicit Reward) 或偏好度"></a>第二步：计算隐式奖励 (Implicit Reward) 或偏好度</h4><p>DPO 的精髓在于，它证明了模型的偏好程度可以被一个简单的公式表示，这个公式衡量了策略模型相对于参考模型的改进程度。</p><ol><li><p><strong>计算 “Chosen” 回答的偏好度：</strong><br>这个值反映了策略模型相比于参考模型，有多”倾向于”生成那个更好的回答。</p><script type="math/tex; mode=display">r_w = \beta \cdot (logP_{\pi_{\theta}}(y_w|x) - logP_{\pi_{ref}}(y_w|x))</script><p>其中 $\beta$ 是一个超参数（通常设为 0.1），用来控制策略模型与参考模型之间的差异程度。</p></li><li><p><strong>计算 “Rejected” 回答的偏好度：</strong><br>同理，这个值反映了策略模型相比于参考模型，有多”倾向于”生成那个更差的回答。</p><script type="math/tex; mode=display">r_l = \beta \cdot (logP_{\pi_{\theta}}(y_l|x) - logP_{\pi_{ref}}(y_l|x))</script></li></ol><h4 id="第三步：计算最终的-DPO-损失"><a href="#第三步：计算最终的-DPO-损失" class="headerlink" title="第三步：计算最终的 DPO 损失"></a>第三步：计算最终的 DPO 损失</h4><p>DPO 的损失函数目标是最大化”Chosen”回答的偏好度与”Rejected”回答的偏好度之间的差距。</p><ol><li><p><strong>计算偏好度差异：</strong></p><script type="math/tex; mode=display">\text{diff} = r_w - r_l</script><p>将第二步的公式代入，得到：</p><script type="math/tex; mode=display">\text{diff} = \beta \cdot [(logP_{\pi_{\theta}}(y_w|x) - logP_{\pi_{ref}}(y_w|x)) - (logP_{\pi_{\theta}}(y_l|x) - logP_{\pi_{ref}}(y_l|x))]</script></li><li><p><strong>应用 Sigmoid 函数和负对数：</strong><br>DPO 将这个差异值传入一个 <code>log-sigmoid</code> 函数中来构造最终的损失。</p><script type="math/tex; mode=display">\text{Loss} = -log(\sigma(\text{diff}))</script><p>其中 $\sigma$ 是 Sigmoid 函数。</p></li></ol><p><strong>这个损失函数的直观理解是：</strong></p><ul><li>如果偏好度差异 <code>diff</code> 很大（即策略模型非常明确地更喜欢 <code>y_w</code> 而不是 <code>y_l</code>），那么 $\sigma(\text{diff})$ 的值会趋近于 1，$log(\sigma(\text{diff}))$ 会趋近于 0，最终的损失值 <code>Loss</code> 也就很小。这表示模型已经学习得很好了，不需要太多调整。</li><li>如果偏好度差异 <code>diff</code> 很小甚至是负数（即策略模型对 <code>y_w</code> 和 <code>y_l</code> 的偏好不明显，甚至搞反了），那么 $\sigma(\text{diff})$ 的值会小于 1，$log(\sigma(\text{diff}))$ 会是一个负数，最终的损失值 <code>Loss</code> 就会是一个较大的正数。这个较大的损失会通过反向传播来更新<strong>策略模型</strong>的参数。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>通过这个损失函数进行梯度下降，模型参数的更新会朝着以下目标进行：</p><ul><li><strong>提高</strong> $logP_{\pi_{\theta}}(y_w|x)$ (增加生成 Chosen 回答的概率)</li><li><strong>降低</strong> $logP_{\pi_{\theta}}(y_l|x)$ (降低生成 Rejected 回答的概率)</li></ul><p>同时，由于参考模型 $logP_{\pi_{ref}}$ 的存在，这个过程又被施加了一个约束，确保策略模型不会为了迎合偏好而产生乱七八糟、不合语法的回答，从而保证了训练的稳定性。这就是 DPO 针对一个 token 序列（样本）计算输出和损失的全过程。</p><h3 id="DPO-的优势和局限性"><a href="#DPO-的优势和局限性" class="headerlink" title="DPO 的优势和局限性"></a>DPO 的优势和局限性</h3><p><strong>优势</strong>：</p><ol><li><strong>训练简单</strong>：只需要两个模型，训练流程简单</li><li><strong>数据效率高</strong>：直接使用偏好数据，避免了奖励建模的误差</li><li><strong>理论保证</strong>：在理论上与基于奖励的 RLHF 等价</li><li><strong>计算效率高</strong>：单轮训练，不需要复杂的优势估计</li></ol><p><strong>局限性</strong>：</p><ol><li><strong>依赖参考策略</strong>：奖励函数是相对于参考策略定义的</li><li><strong>偏好数据质量</strong>：对偏好数据的质量要求较高</li><li><strong>探索能力有限</strong>：可能无法探索到远离参考策略的新策略</li><li><strong>温度参数敏感</strong>：$\beta$ 的选择对性能影响较大</li></ol><h3 id="DPO-与-PPO-的理论联系"><a href="#DPO-与-PPO-的理论联系" class="headerlink" title="DPO 与 PPO 的理论联系"></a>DPO 与 PPO 的理论联系</h3><p><strong>等价性的核心前提</strong>：</p><p>DPO 与 PPO 等价的核心前提是：<strong>奖励函数必须满足特定的形式</strong>。具体来说，奖励函数必须能够表示为：</p><script type="math/tex; mode=display">r(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}</script><p>这个前提条件意味着：</p><ol><li><strong>奖励函数与策略的耦合</strong>：奖励函数不能是任意的，必须与当前策略 $\pi_\theta$ 和参考策略 $\pi_{ref}$ 相关</li><li><strong>相对性</strong>：奖励是相对于参考策略定义的，不是绝对奖励</li><li><strong>策略依赖性</strong>：奖励函数会随着策略的更新而变化</li></ol><p><strong>为什么这个前提很重要</strong>：</p><p>在实际的 RLHF 中，奖励函数通常是独立训练的，其形式为 $r(x, y) = f_\phi(x, y)$，其中 $f_\phi$ 是一个独立的神经网络。这种形式的奖励函数与 DPO 假设的形式完全不同。</p><p><strong>等价性的假设前提</strong>：</p><p>DPO 与 PPO 的等价性是在以下关键假设下成立的：</p><ol><li><strong>奖励函数假设</strong>：奖励函数必须满足 $r(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}$ 的形式</li><li><strong>优势函数简化</strong>：忽略价值函数，直接使用奖励作为优势函数，即 $A_t = r_t$</li><li><strong>策略约束方式</strong>：使用 KL 散度约束而不是 PPO 的裁剪约束</li><li><strong>单步优化</strong>：假设每次更新都是单步的，不考虑多步交互</li></ol><p><strong>理论背景</strong>：</p><p>这个等价性来自于<strong>奖励函数与策略之间的对偶关系</strong>。在强化学习中，存在一个重要的理论结果：对于任何奖励函数 $r(x, y)$，都存在一个最优策略 $\pi^*(y|x)$，使得：</p><script type="math/tex; mode=display">\pi^*(y|x) \propto \pi_{ref}(y|x) \exp(\frac{r(x, y)}{\beta})</script><p>这个关系表明，奖励函数和策略之间存在一一对应的关系。DPO 的关键洞察是：如果我们直接学习策略，就可以隐式地学习到对应的奖励函数。</p><p><strong>等价性证明的局限性</strong>：</p><p>需要注意的是，这种等价性有以下局限性：</p><ol><li><strong>奖励函数形式限制</strong>：只有在特定形式的奖励函数下才成立</li><li><strong>忽略价值函数</strong>：实际 PPO 中价值函数的作用被简化了</li><li><strong>约束方式不同</strong>：PPO 的裁剪约束和 DPO 的 KL 散度约束在理论上不等价</li><li><strong>训练稳定性</strong>：虽然理论等价，但实际训练中的稳定性可能不同</li></ol><p><strong>实际应用中的差异</strong>：</p><p>尽管在理论上存在等价性，但在实际应用中：</p><ol><li><strong>PPO</strong>：通过显式奖励模型提供更直接的监督信号</li><li><strong>DPO</strong>：通过偏好数据提供相对比较信号</li><li><strong>训练稳定性</strong>：PPO 的裁剪机制可能提供更好的训练稳定性</li><li><strong>探索能力</strong>：PPO 可能具有更好的探索能力</li></ol><p><strong>等价性证明</strong>：<br>DPO 可以看作是 PPO 在特定条件下的简化版本。当 PPO 中的：</p><ul><li>奖励模型 $r(x, y) = \beta \log \frac{\pi_\theta(y|x)}{\pi_{ref}(y|x)}$</li><li>优势函数 $A_t = r_t$（忽略价值函数）</li><li>策略约束通过 KL 散度实现</li></ul><p>此时，PPO 的损失函数就退化为 DPO 的形式。</p><p><strong>主要区别</strong>：</p><ol><li><strong>奖励建模</strong>：PPO 需要显式奖励模型，DPO 隐含在策略中</li><li><strong>优势估计</strong>：PPO 需要复杂的优势估计，DPO 直接使用奖励</li><li><strong>约束方式</strong>：PPO 使用裁剪约束，DPO 使用 KL 散度约束</li></ol><h2 id="PPO-和-DPO-的区别"><a href="#PPO-和-DPO-的区别" class="headerlink" title="PPO 和 DPO 的区别"></a>PPO 和 DPO 的区别</h2><h3 id="1-训练复杂度"><a href="#1-训练复杂度" class="headerlink" title="1. 训练复杂度"></a>1. 训练复杂度</h3><ul><li><strong>PPO</strong>：需要四个模型（Actor、Critic、Reward、Reference），训练过程复杂</li><li><strong>DPO</strong>：只需要两个模型（策略模型和参考模型），训练过程简单</li></ul><h3 id="2-数据需求"><a href="#2-数据需求" class="headerlink" title="2. 数据需求"></a>2. 数据需求</h3><ul><li><strong>PPO</strong>：需要显式的奖励信号或奖励模型</li><li><strong>DPO</strong>：只需要偏好数据（哪个更好），不需要显式奖励</li></ul><h3 id="3-计算效率"><a href="#3-计算效率" class="headerlink" title="3. 计算效率"></a>3. 计算效率</h3><ul><li><strong>PPO</strong>：需要多轮交互和复杂的优势估计</li><li><strong>DPO</strong>：单轮训练，计算效率更高</li></ul><h3 id="4-稳定性"><a href="#4-稳定性" class="headerlink" title="4. 稳定性"></a>4. 稳定性</h3><ul><li><strong>PPO</strong>：通过裁剪机制保证训练稳定性</li><li><strong>DPO</strong>：通过 KL 散度约束保证稳定性</li></ul><h3 id="5-适用场景"><a href="#5-适用场景" class="headerlink" title="5. 适用场景"></a>5. 适用场景</h3><ul><li><strong>PPO</strong>：适用于有明确奖励信号或可以训练奖励模型的场景</li><li><strong>DPO</strong>：适用于只有人类偏好数据的场景</li></ul><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>PPO 和 DPO 都是 RLHF 中的重要算法，它们各有优缺点：</p><ul><li><strong>PPO</strong> 更加成熟和稳定，但训练复杂度高</li><li><strong>DPO</strong> 更加简单和高效，但可能在某些场景下效果不如 PPO</li></ul><p>选择哪种算法主要取决于具体的应用场景和可用的数据。在实际应用中，可以根据需求选择合适的算法，或者将两种算法结合使用。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Schulman, J., et al. “Proximal policy optimization algorithms.” arXiv preprint arXiv:1707.06347 (2017).</li><li>Rafailov, R., et al. “Direct preference optimization: Your language model is secretly a reward model.” arXiv preprint arXiv:2305.18290 (2023).</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;已经接近 3 年没有更新博客了。今天立下一个 flag，开始准备 LLM 面试知识，主要是八股文为主，想到哪写到哪。第一篇没想到写啥，觉得对 PPO 和 DPO 比较了解，就先直接写这个吧。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="rlhf" scheme="https://murphypei.github.io/tags/rlhf/"/>
    
      <category term="ppo" scheme="https://murphypei.github.io/tags/ppo/"/>
    
      <category term="dpo" scheme="https://murphypei.github.io/tags/dpo/"/>
    
  </entry>
  
  <entry>
    <title>图像生成基础：DDPM</title>
    <link href="https://murphypei.github.io//blog/2024/07/aigc-ddpm.html"/>
    <id>https://murphypei.github.io//blog/2024/07/aigc-ddpm.html</id>
    <published>2024-07-31T09:44:51.000Z</published>
    <updated>2025-07-21T11:29:15.401Z</updated>
    
    <content type="html"><![CDATA[<p>目前所采用的扩散模型大都是来自于 2020 年的工作 DDPM。DDPM 对之前的扩散模型进行了简化，并通过变分推断（variational inference）来进行建模，这主要是因为扩散模型也是一个隐变量模型（latent variable model），相比 VAE 这样的隐变量模型，扩散模型的隐变量是和原始数据是同维度的，而且推理过程（即扩散过程）往往是固定的。</p><a id="more"></a><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>扩散模型包括两个过程：前向过程（forward process）和反向过程（reverse process），其中前向过程又称为扩散过程（diffusion process），如下图所示。无论是前向过程还是反向过程都是一个参数化的马尔可夫链（Markov chain），其中反向过程可以用来生成数据，这里我们将通过变分推断来进行建模和求解。</p><p><img src="/images/posts/aigc/ddpm/1.webp" alt></p><h3 id="前向扩散过程（Forward-Diffusion-Process）"><a href="#前向扩散过程（Forward-Diffusion-Process）" class="headerlink" title="前向扩散过程（Forward Diffusion Process）"></a>前向扩散过程（Forward Diffusion Process）</h3><p>解释扩散之前先介绍一个基本的数学表示：</p><script type="math/tex; mode=display">\mathcal{N}(x_t; \mu, \Sigma)</script><p>一个正态分布，其中 $\mu$ 是均值，$\Sigma$ 是协方差矩阵。在这个过程中，$x_t$ 服从一个 $\mu$ 为均值、$\Sigma$ 为协方差矩阵的正态分布。</p><p>扩散就是对图像数据进行加噪声的过程，<strong>最核心的数学公式</strong>表示如下：</p><script type="math/tex; mode=display">q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t} x_{t-1}, \beta_t \mathbf{I})</script><p>$x_0$ 是原始数据，$x_t$ 是在 $t$ 时刻的样本，$\mathcal{N}$ 表示正态分布，$\beta_t$ 表示在第 $t$ 步的方差（噪音量），它是一个介于 0 和 1 之间的值，$\sqrt{1 - \beta_t}$ 表示输入数据的缩放系数，$\beta_t \mathbf{I}$ 表示加的噪音的方差。</p><p>这个公式表示，给定 $x_{t-1}$ 的情况下，$x_t$ 是以 $\sqrt{1 - \beta_t} x_{t-1}$ 为均值、$\beta_t \mathbf{I}$ 为协方差矩阵的正态分布。可以简单理解为，$x_t$ 是 $x_{t-1}$ 加上高斯噪音后的结果。</p><p>前向过程就是这么简单。当我们逐渐加大 $\beta_t$ 时，$x_t$ 逐渐变得模糊，最终变成一个高斯噪声图像。</p><script type="math/tex; mode=display">q(x_T|x_0) \approx \mathcal{N}(0, I)</script><p>这里也有一个推导，就是通过 $x_0$，可以直接表示 $x_T$，因为高斯分布可以直接相加。</p><h3 id="逆向生成过程（Reverse-Generation-Process）"><a href="#逆向生成过程（Reverse-Generation-Process）" class="headerlink" title="逆向生成过程（Reverse Generation Process）"></a>逆向生成过程（Reverse Generation Process）</h3><p>训练过程中，DDPM 学习从噪声生成数据的逆向过程。我们<strong>假设逆向过程也是一个高斯过程</strong>，但参数未知：</p><script type="math/tex; mode=display">p_\theta(x_{t-1}|x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \sigma_\theta^2(x_t, t) I)</script><p>这里，模型的任务是学习 $\mu_\theta$ 和 $\sigma_\theta$ 的参数化形式，使得可以从噪声生成逼真的数据样本。</p><h3 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h3><p>训练的目标是最小化前向过程和逆向过程之间的差异。具体来说，训练目标可以表示为以下 KL 散度的和：</p><script type="math/tex; mode=display">L = \sum_{t=1}^{T} D_{KL}\left(q(x_{t-1}|x_t, x_0) \| p_\theta(x_{t-1}|x_t)\right)</script><p>每一个 KL 项衡量在第 $t$ 个时间步长上真实分布和模型估计分布之间的差异。</p><h3 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h3><p>为了简化训练过程，我们可以<strong>重参数化</strong>损失函数为一个去噪过程的预测任务。目标变为预测加入噪声的程度（噪声项）的均值和方差。</p><blockquote><p>这里重参数的推导很长，可以网上找一下。</p></blockquote><script type="math/tex; mode=display">L = \mathbb{E}_{q(x_0, \epsilon)} \left[\|\epsilon - \epsilon_\theta(x_t, t)\|^2\right]</script><p>其中 $\epsilon$ 是在前向过程加入的数据噪声，$\epsilon_\theta$ 是通过神经网络预测的噪声。所以神经网络的任务就是抽取一个 $t$（1~$T$ 之间），通过 $x_0$ 和加噪过程，计算得到 $x_t$，然后神经网络预测噪声，计算预测的噪声和实际噪声的分布差异。</p><h3 id="训练步骤"><a href="#训练步骤" class="headerlink" title="训练步骤"></a>训练步骤</h3><ol><li><strong>采样数据 $x_0$</strong> 从真实数据分布中。</li><li><strong>采样噪声 $\epsilon$</strong> 从标准正态分布中。</li><li><strong>计算 $x_t$</strong> 通过前向扩散过程，将噪声加入数据。</li><li><strong>计算预测的噪声 $\epsilon_\theta(x_t, t)$</strong> 使用神经网络。</li><li><strong>计算损失 $L$</strong> 并通过反向传播更新模型参数。</li></ol><h3 id="生成步骤"><a href="#生成步骤" class="headerlink" title="生成步骤"></a>生成步骤</h3><p>生成数据时，从标准正态分布中采样 $x_T$，然后逐步通过逆向生成过程去噪，生成数据 $x_0$。</p><p>在 DDPM 中，会将原始图像的像素值从 [0, 255] 范围归一化到 [-1, 1]，像素值属于离散化值。</p><h3 id="背后原理"><a href="#背后原理" class="headerlink" title="背后原理"></a>背后原理</h3><p>DDPM 通过一个称为”马尔科夫链”的过程，逐步将噪声转化为数据。其核心思想是分阶段进行去噪，每个阶段只去除一小部分噪声，使得每一步的去噪过程更为简单和稳定。</p><p>总的来说，DDPM 在生成任务中表现出色，特别是生成图像和其他复杂结构的数据类型。这是因为它通过多步生成过程有效地捕捉了数据的复杂结构和细节。</p><p>DDPM 的推导过程中，最重要的就是重参数技巧，这个技巧在很多生成模型中都有应用，比如 VAE、GAN 等。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前所采用的扩散模型大都是来自于 2020 年的工作 DDPM。DDPM 对之前的扩散模型进行了简化，并通过变分推断（variational inference）来进行建模，这主要是因为扩散模型也是一个隐变量模型（latent variable model），相比 VAE 这样的隐变量模型，扩散模型的隐变量是和原始数据是同维度的，而且推理过程（即扩散过程）往往是固定的。&lt;/p&gt;
    
    </summary>
    
      <category term="AIGC" scheme="https://murphypei.github.io/categories/AIGC/"/>
    
    
      <category term="AIGC" scheme="https://murphypei.github.io/tags/AIGC/"/>
    
      <category term="DDPM" scheme="https://murphypei.github.io/tags/DDPM/"/>
    
      <category term="图像生成" scheme="https://murphypei.github.io/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"/>
    
  </entry>
  
  <entry>
    <title>大模型 RLHF 训练中的 PPO 算法细节</title>
    <link href="https://murphypei.github.io//blog/2024/07/llm-rlhf-ppo.html"/>
    <id>https://murphypei.github.io//blog/2024/07/llm-rlhf-ppo.html</id>
    <published>2024-07-25T09:15:51.000Z</published>
    <updated>2025-07-21T11:41:47.156Z</updated>
    
    <content type="html"><![CDATA[<p>虽然了解大模型训练中的 RLHF 训练，但是都是有点不够深刻，特别是 PPO 算法的细节。</p><a id="more"></a><p>看到一篇好文章，转载并重新编辑，加入个人理解，以便日后查阅。有兴趣可以参考<a href="https://zhuanlan.zhihu.com/p/677607581" target="_blank" rel="noopener">原文</a></p><h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p>强化学习属于机器学习的一个分支，区别于有监督学习。关键点在于：</p><ol><li>无监督，没有标签，通过试错和奖励来优化行为和策略。</li><li>与环境有交互。（抽象概念，不要深究）</li><li>没有明确的反馈（无标签），反馈是通过奖励信号传递的，可以是延迟的，需要考虑长期回报。</li></ol><p>强化学习的简化图：<br><img src="/images/posts/llm/ppo/rl.webp" alt></p><p>强化学习的两个实体：<strong>智能体（Agent）</strong>与<strong>环境（Environment）</strong>。强化学习中两个实体的交互：</p><ul><li><strong>状态空间 S</strong>：S 即为 State，指环境中所有可能状态的集合</li><li><strong>动作空间 A</strong>：A 即为 Action，指智能体所有可能动作的集合</li><li><strong>奖励 R</strong>：R 即为 Reward，指智能体在环境的某一状态下所获得的奖励。</li></ul><p>一个交互过程可以表示为：</p><ol><li>在 $t$ 时刻，智能体处于状态 $S_t$，在该状态下，得到的奖励为 $R_t$；</li><li>根据 $S_t$、$R_t$ 以及策略智能体选择动作 $A_t$；</li><li>执行动作 $A_t$ 后环境转移到状态 $S_{t+1}$，智能体获得奖励 $R_{t+1}$。</li></ol><p>智能体在这个过程中学习，它的最终目标是：<strong>找到一个策略，这个策略根据当前观测到的环境状态和奖励反馈，来选择最佳的动作</strong>。</p><h3 id="价值函数"><a href="#价值函数" class="headerlink" title="价值函数"></a>价值函数</h3><p>奖励 $R$ 是一个标量，但是在实际问题中，一个动作，既有即时奖励，也要考虑<strong>长期回报</strong>。为了解决这个问题，引入了<strong>价值函数</strong>的概念。</p><script type="math/tex; mode=display">V_t = R_t + \gamma V_{t+1}</script><p>其中：</p><ul><li>$V_t$：表示在 $t$ 时刻的状态 $S_t$ 下的价值（包含了即时和未来的奖励）。</li><li>$R_t$：$t$ 时刻的即时收益。</li><li>$\gamma$：是折扣因子，用于平衡当前奖励和未来奖励。</li></ul><p>这里最需要注意的是：$V_{t+1}$ 同样包含了现在和未来的奖励，但是对于 $V_{t}$ 来说，它就相当于未来潜在收益。</p><h2 id="NLP-和强化学习"><a href="#NLP-和强化学习" class="headerlink" title="NLP 和强化学习"></a>NLP 和强化学习</h2><p><img src="/images/posts/llm/ppo/nlp-rl.webp" alt></p><p>这里的 NLP 是特质生成模型。</p><p>生成模型的推理执行过程：给模型一个 prompt，让模型能生成符合人类喜好的 response。再回想一下 GPT 模型做推理的过程：每个时刻 $t$ 只产生一个 token，即 token 是一个一个蹦出来的，先有上一个 token，再有下一个 token。</p><p>结合上面的图，分解一下这个过程：</p><ol><li>智能体就是生成模型。</li><li>在 $t$ 时刻，有上下文 context（$S_t$），模型产出一个 token，对应 RL 中的动作，记为 $A_t$。动作空间就是词表。</li><li>在 $t$ 时刻，有了 $A_t$ 动作，<strong>即时</strong>收益为 $R_t$，总收益为 $V_t$（注意二者不一样）。对于生成模型，收益是什么？人类喜好。</li><li>状态变化，$S_{t+1}$ 变为 $S_t$ 和新生成的 token。</li><li><strong>忽略图中的下表，主要理解过程和对应的东西</strong>。</li></ol><p>$A_t$ 是产出一个新 token，$S_t$ 是词表空间，$R_t$ 和 $V_t$ 是什么？答案是通过模型产生的分数，这里不要在意命名，你叫评价模型，叫奖励模型都行，只不过是两个打分模型而已。</p><p>记住，到此已经有了<strong>3 个模型</strong>了啊，$A_t$ 模型表示智能体的动作，$R_t$ 和 $V_t$ 是两个打分模型，分别表示即时奖励和未来长期奖励。</p><p>还有一个重要的点：不是生成一个 token，也就是有一个动作，我们就要计算奖励、打分，可以等生成模型回答完毕（也就是 EOS token）再打分。</p><h2 id="RLHF-中的-4-个模型"><a href="#RLHF-中的-4-个模型" class="headerlink" title="RLHF 中的 4 个模型"></a>RLHF 中的 4 个模型</h2><p>OpenAI 的示意图：</p><p><img src="/images/posts/llm/ppo/ppo.png" alt></p><p>RLHF 中使用的模型示意图：</p><p><img src="/images/posts/llm/ppo/rlhf.webp" alt></p><p>现在大家都知道 PPO 有 4 个模型，上面我们说了 3 个，还有 1 个，这里将 4 个模型都列出来：</p><ul><li><strong>Actor Model</strong>：PPO 训练的模型，也是我们最终要用于应用的模型。</li><li><strong>Critic Model</strong>：即时收益 $V_t$，反映的是当前输出的潜在价值。</li><li><strong>Reward Model</strong>：整体收益的打分模型，也是上面的 $R_t$。</li><li><strong>Reference Model</strong>：这个模型是额外增加的，主要是在 RLHF 阶段给语言模型增加一些”约束”，防止语言模型训歪（朝不受控制的方向更新，效果可能越来越差）。这个看 Loss 就能明白了。</li></ul><h3 id="哪些模型需要更新参数？"><a href="#哪些模型需要更新参数？" class="headerlink" title="哪些模型需要更新参数？"></a>哪些模型需要更新参数？</h3><p>Actor Model 和 Critic Model。Actor 肯定是很好理解的，所以不多说了，Critic Model 为什么也要更新？主要是这里存在一个难点：怎么评估总体收益呢？我们自己随口一说评估总体收益，但是这个是很难的，因为没有真的标签（有监督）。所以我们需要通过一个模型来判断，而且更重要的是，这个判断模型的能力，<strong>要不断提升能力</strong>，才能做好这件事。</p><h3 id="Actor-Model"><a href="#Actor-Model" class="headerlink" title="Actor Model"></a>Actor Model</h3><p><img src="/images/posts/llm/ppo/actor.webp" alt></p><p>我们的最终目的是让 Actor 模型能产生符合人类喜好的 response。所以我们的策略是，先喂给 Actor 一条 prompt（这里假设 batch_size = 1，所以是 1 条 prompt），让它生成对应的 response。然后，我们再将”prompt + response”送入我们的”奖励-loss”计算体系中去算得最后的 loss，用于更新 actor。</p><h3 id="Reference-Model"><a href="#Reference-Model" class="headerlink" title="Reference Model"></a>Reference Model</h3><p>Reference Model 一般也用 SFT 阶段得到的 SFT 模型做初始化，在训练过程中，它的参数是冻结的。Ref 模型的主要作用是防止 Actor”训歪”，那么它具体是怎么做到这一点的呢？</p><p><img src="/images/posts/llm/ppo/ref.webp" alt></p><p>“防止模型训歪”换一个更详细的解释是：我们希望训练出来的 Actor 模型既能达到符合人类喜好的目的，又尽量让它和 SFT 模型不要差异太大。简言之，我们希望两个模型的输出分布尽量相似。那什么指标能用来衡量输出分布的相似度呢？我们自然而然想到了<strong>KL 散度</strong>。</p><blockquote><p>简单来说就是防止模型”高分低能”，过拟合到乱七八糟但是得分高的回答上。</p></blockquote><p>关于 KL 散度和 ref 模型的计算，这里不需要展开，网上资料特别多。</p><p>Reference Model 输入和 Actor Model 一致，输出是一个参考答案。</p><h3 id="Critic-Model"><a href="#Critic-Model" class="headerlink" title="Critic Model"></a>Critic Model</h3><p><img src="/images/posts/llm/ppo/critic.webp" alt></p><p>前面已经讲了这个模型的作用以及为什么要更新参数。简单讲一下这个模型怎么训练的：一般都是采用了 Reward 模型作为它的初始化，所以这里我们也按 Reward 模型的架构来简单画画它。你可以简单理解成，Reward/Critic 模型和 Actor 模型的架构是很相似的（毕竟输入都一样），同时，它在最后一层增加了一个 Value Head 层，该层是个简单的线形层，用于将原始输出结果映射成单一的 $V_t$ 值。</p><p><strong>特别要注意</strong>：</p><ul><li>价值函数是一个计算 Actor Model 在生成过程中每个 token 的价值（一个标量）。那么它的输入就是当前的问题 + Actor Model 当前的输出（并非完整的答案）</li><li>价值标量是怎么得到的呢？将最后一个 token（认为包含了整个序列 token 的注意力）的隐藏层（4096 维）输入到一个 1 维的 FC 层，就输出一个标量。</li></ul><h3 id="Reward-Model"><a href="#Reward-Model" class="headerlink" title="Reward Model"></a>Reward Model</h3><p><img src="/images/posts/llm/ppo/reward.webp" alt></p><p>计算整体奖励，也没啥好讲的，提前训练好的（RLHF 第二阶段做的事情），这里重点讲一下为啥 reward 模型不需要更新参数呢？</p><p>其实我觉得不要深入去纠结，我感觉 PPO 这么做的原因就是为了引入一个客观的、绝对的标准。这个模型最重要的区别在于，<strong>它只关心当前这个 response 的好坏</strong>。Critic 隐含了综合考虑所有 response 的好坏的含义（需要才需要更新参数）。</p><p><strong>特别要注意</strong>：</p><ul><li>奖励函数是一个计算 Actor Model 在生成的完整的答案的奖励，所以输入是当前的问题 + 完整的答案，得到一个标量奖励。</li><li>奖励的标量是怎么得到的呢？将输入的最后一个 token（认为包含了整个序列 token 的注意力）的隐藏层（4096 维）输入到一个 1 维的 FC 层，就输出一个标量。</li></ul><h2 id="RLHF-的-Loss-计算"><a href="#RLHF-的-Loss-计算" class="headerlink" title="RLHF 的 Loss 计算"></a>RLHF 的 Loss 计算</h2><p>我已经看过太多次了，所以不想重新写这个了，直接看原文或者网上搜一下就知道了。注意每一项对应 ref、critic、reward 模型，结合前面讲解的各个模型的作用，应该能很好地理解这个 Loss 的含义。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;虽然了解大模型训练中的 RLHF 训练，但是都是有点不够深刻，特别是 PPO 算法的细节。&lt;/p&gt;
    
    </summary>
    
      <category term="LLM" scheme="https://murphypei.github.io/categories/LLM/"/>
    
    
      <category term="LLM" scheme="https://murphypei.github.io/tags/LLM/"/>
    
      <category term="RLHF" scheme="https://murphypei.github.io/tags/RLHF/"/>
    
      <category term="PPO" scheme="https://murphypei.github.io/tags/PPO/"/>
    
      <category term="大模型" scheme="https://murphypei.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>STL 旋转序列算法 rotate</title>
    <link href="https://murphypei.github.io//blog/2022/12/stl-rotate.html"/>
    <id>https://murphypei.github.io//blog/2022/12/stl-rotate.html</id>
    <published>2022-12-07T03:35:51.000Z</published>
    <updated>2025-06-25T02:00:04.078Z</updated>
    
    <content type="html"><![CDATA[<p>最近开发需要不管刷新缓冲区，发现了一个有用的 STL 算法。</p><a id="more"></a><p>先说明应用场景：我有一块缓冲区 vector，不断接收数据和消费数据（生产消费模型），接收数据就放在末尾，消费头部数据，消费完删除。之前用 realloc 和 memmove 来操作，改为 vector 之后如果每次搬移数据就很麻烦了，查了一下发现 <a href="https://en.cppreference.com/w/cpp/algorithm/rotate" target="_blank" rel="noopener">rotate</a> 配合 resize 可以搞定。</p><p>std::rotate() 的第一个参数是这个序列的开始迭代器；第二个参数是指向新的第一个元素的迭代器，<strong>它必定在序列之内</strong>。第三个参数是这个序列的结束迭代器。意思是将第二个参数的元素旋转到第一个参数的位置，旋转的序列是第一个参数到第三个参数的范围。</p><p>你可以想象第一个参数 ~ 第三个参数之间的元素序列组成一个圆盘，左转就是逆时针旋转，直到第二个参数转到第一个参数的位置，旋转结束。</p><p>可以参数<a href="http://c.biancheng.net/view/609.html" target="_blank" rel="noopener">图解</a></p><p>旋转完成后，头部就变到 vector 末尾了，用 resize 可以标记删除掉这些元素。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近开发需要不管刷新缓冲区，发现了一个有用的 STL 算法。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="STL" scheme="https://murphypei.github.io/tags/STL/"/>
    
      <category term="stl" scheme="https://murphypei.github.io/tags/stl/"/>
    
      <category term="rotate" scheme="https://murphypei.github.io/tags/rotate/"/>
    
  </entry>
  
  <entry>
    <title>vscode C++ 开发之使用 clangd、C/C++、clang-format</title>
    <link href="https://murphypei.github.io//blog/2022/12/vscode-clang-format.html"/>
    <id>https://murphypei.github.io//blog/2022/12/vscode-clang-format.html</id>
    <published>2022-12-07T03:25:55.000Z</published>
    <updated>2025-06-25T02:00:04.082Z</updated>
    
    <content type="html"><![CDATA[<p>最近比较忙，废话少说，vscode 开发 C/C++ 需要很繁琐的配置，之前也说过 launch 和 tasks 的配置。这篇文章主要结合自身使用经历讲讲 C++ 相关插件。</p><a id="more"></a><p>vscode 最常用的几个 C++ 插件（不包含 cmake）就是微软的 C/C++、LLVM 的 clangd，以前我也使用 C/C++，但是智能补全和提示、include 路径都太差劲了，转投 clangd 了，确实好用。所以不废话，直接推荐使用 clangd，不过 C/C++ 也在用，为了二者不冲突，需要配置如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">"C_Cpp.autocomplete": "Disabled",</span><br><span class="line">"C_Cpp.clang_format_fallbackStyle": "Visual Studio",</span><br><span class="line">"C_Cpp.clang_format_sortIncludes": true,</span><br><span class="line">"C_Cpp.clang_format_style": "file",</span><br><span class="line">"C_Cpp.default.compilerPath": "/usr/bin/g++",</span><br><span class="line">"C_Cpp.default.configurationProvider": "ms-vscode.cmake-tools",</span><br><span class="line">"C_Cpp.default.cppStandard": "c++11",</span><br><span class="line">"C_Cpp.default.cStandard": "c99",</span><br><span class="line">"C_Cpp.default.intelliSenseMode": "gcc-x64",</span><br><span class="line">"C_Cpp.errorSquiggles": "Disabled",</span><br><span class="line">"C_Cpp.intelliSenseEngine": "Disabled",</span><br><span class="line">"clangd.arguments": [</span><br><span class="line">// 在后台自动分析文件（基于complie_commands)</span><br><span class="line">"--background-index",</span><br><span class="line">"--compile-commands-dir=$&#123;workspaceFolder&#125;/build",</span><br><span class="line">"-j=8",</span><br><span class="line">// 支持 .clangd 配置</span><br><span class="line">"--enable-config",</span><br><span class="line">"--clang-tidy",</span><br><span class="line">"--clang-tidy-checks=performance-*,bugprone-*",</span><br><span class="line">"--log=verbose",</span><br><span class="line">"--pretty",</span><br><span class="line">// 全局补全（会自动补充头文件）</span><br><span class="line">"--all-scopes-completion",</span><br><span class="line">// 更详细的补全内容</span><br><span class="line">"--completion-style=detailed",</span><br><span class="line">// 补充头文件的形式</span><br><span class="line">"--header-insertion=iwyu",</span><br><span class="line">// pch优化的位置</span><br><span class="line">"--pch-storage=memory",</span><br><span class="line">"--function-arg-placeholders",</span><br><span class="line">],</span><br></pre></td></tr></table></figure><p>clangd 的 include 可以通过如下配置：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">"clangd.fallbackFlags": [</span><br><span class="line">    "-std=c++11",</span><br><span class="line">    "-I/usr/include/c++/9",</span><br><span class="line">    "-I/usr/include/opencv4",</span><br><span class="line">    "-I$&#123;workspaceFolder&#125;/src/",</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>clangd 虽然很香，但是有个明显的缺点，就是它一定要使用自身的 clang-format 来格式化，而且无法配置使用 .clang-format 文件。为此，需要安装另一个插件 xaver clang-format。安装完成后配置格式化的程序：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">"[cpp]": &#123;</span><br><span class="line">// "editor.defaultFormatter": "llvm-vs-code-extensions.vscode-clangd"</span><br><span class="line">"editor.defaultFormatter": "xaver.clang-format"</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure><p>这个插件可以直接调用项目根目录下的 .clang-format 文件来格式化。</p><p>最后，有条件的推荐使用 clion 来开发和调试 C++。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近比较忙，废话少说，vscode 开发 C/C++ 需要很繁琐的配置，之前也说过 launch 和 tasks 的配置。这篇文章主要结合自身使用经历讲讲 C++ 相关插件。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="vscode" scheme="https://murphypei.github.io/tags/vscode/"/>
    
      <category term="clangd" scheme="https://murphypei.github.io/tags/clangd/"/>
    
      <category term="clang-format" scheme="https://murphypei.github.io/tags/clang-format/"/>
    
  </entry>
  
  <entry>
    <title>golang select 机制和超时</title>
    <link href="https://murphypei.github.io//blog/2022/06/go-select-timeout.html"/>
    <id>https://murphypei.github.io//blog/2022/06/go-select-timeout.html</id>
    <published>2022-06-25T06:24:59.000Z</published>
    <updated>2025-06-25T02:00:04.078Z</updated>
    
    <content type="html"><![CDATA[<p>golang 中的协程使用非常方便，但是协程什么时候结束是一个控制问题，可以用 select 配合使用。</p><a id="more"></a><p>首先声明，golang 使用并不熟悉，本文仅仅是记录使用过程中遇到的一些坑。</p><p>子协程和父协程的通信通常用 context 或者 chan。我遇到一个通常的使用场景，在子协程中尝试多次处理，父协程等待一段时间超时，我选择用 chan 实现。我以为 select 和 C++ 中 switch 类似，所以最开始代码类似如下：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">            <span class="comment">// process ctx done</span></span><br><span class="line">        <span class="keyword">case</span> &lt;-time.After(time.Second * <span class="number">3</span>):</span><br><span class="line">            <span class="comment">// process after</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="comment">// process code</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试发现无法实现 timeout，又仔细查看文档，才发现 golang 中 select 另有玄机。废话少说，直接总结要点：</p><ul><li>select 中的 case 必须是进行 chan 的手法操作，也就是只能在 case 中操作 chan，并且是<strong>非阻塞接收</strong>。</li><li>select 中的 case 是同时监听的，多个 case 同时操作，并未 switch 中一个个顺序判断。如果多个 case 满足要求，随机执行一个，如果一个没有则阻塞当前的协程（没有 default 情况下）。<strong>很类似 Linux 文件符操作的 select 语义</strong>。</li><li>上面说的阻塞是没有 default 的情况下，如果有 default，则执行 default，然后退出 select，也就是不会阻塞当前协程。</li></ul><p>回到上述代码，我这个 select 会一直不断的执行 default，<code>time.After</code> 生成的 chan 并不会被阻塞判断，所以根本无法完成我想要的效果。理解了之后重新修改代码：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">done := <span class="built_in">make</span>(char <span class="keyword">int</span>)</span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(c <span class="keyword">chan</span> <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="comment">// process code</span></span><br><span class="line">        <span class="keyword">if</span> &#123;</span><br><span class="line">            c &lt;- <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    c &lt;- <span class="number">0</span></span><br><span class="line">&#125;(done)</span><br><span class="line"></span><br><span class="line"><span class="keyword">select</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">        <span class="comment">// process ctx done</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-time.After(time.Second * <span class="number">3</span>):</span><br><span class="line">        <span class="comment">// process after</span></span><br><span class="line">    <span class="keyword">case</span> &lt;-done:</span><br><span class="line">        <span class="comment">// process code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>开一个新的协程去不断尝试，在外的三个 case 有一个满足，则会执行。但是这里有一个问题非常需要注意：<strong>子协程什么时候退出？</strong>。</p><p>因为 gorountine 不能被强制 kill，所以在上述超时的情况下，select 语句执行 <code>case time.After</code> 之后退出，<code>done</code> 这个 chan 已经没有接受方了，因此既没有接受者，又没有缓冲区，结合 chan 的特性，则子协程会一直阻塞无法退出，所以本质上这个实现会导致子协程累积下去，也就是<strong>协程泄露</strong>，可能会使资源耗尽。</p><p>如何避免上述问题呢？一个很简单的想法就是提供缓冲区，<code>done := make(char int, 1)</code>，这样即使没有接收方，子协程也能完成发送，不会被阻塞。</p><p>还要一种办法，上面说了，select 操作 chan，并且可以指定 default，那是不是有思路了呢？</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> &#123;</span><br><span class="line">    <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> done &lt;- <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们尝试往 chan 中发送，如果发不出去，则就退出，也实现了目的。</p><p>最后总结一下，goroutine 泄露的防范条例：</p><ul><li>创建 goroutine 时就要想好该 goroutine 该如何结束。</li><li>使用 chan 时，要考虑到 chan 阻塞时协程可能的行为。</li><li>实现循环语句时注意循环的退出条件，避免死循环。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;golang 中的协程使用非常方便，但是协程什么时候结束是一个控制问题，可以用 select 配合使用。&lt;/p&gt;
    
    </summary>
    
      <category term="Golang" scheme="https://murphypei.github.io/categories/Golang/"/>
    
    
      <category term="select" scheme="https://murphypei.github.io/tags/select/"/>
    
      <category term="golang" scheme="https://murphypei.github.io/tags/golang/"/>
    
      <category term="case" scheme="https://murphypei.github.io/tags/case/"/>
    
      <category term="timeout" scheme="https://murphypei.github.io/tags/timeout/"/>
    
      <category term="after" scheme="https://murphypei.github.io/tags/after/"/>
    
      <category term="chan" scheme="https://murphypei.github.io/tags/chan/"/>
    
  </entry>
  
  <entry>
    <title>C++ 链接一个不需要的库(--no-as-needed)</title>
    <link href="https://murphypei.github.io//blog/2022/04/link-noneed-lib.html"/>
    <id>https://murphypei.github.io//blog/2022/04/link-noneed-lib.html</id>
    <published>2022-04-18T09:16:49.000Z</published>
    <updated>2025-06-25T02:00:04.074Z</updated>
    
    <content type="html"><![CDATA[<p>使用 libtorch 的 C++ 动态链接库遇到了一个非常诡异的问题…</p><a id="more"></a><p>我使用 libtorch 的库编译了一个语音识别程序，使用 CPU 推理，能够完美运行，然后在 go 中对这个程序封装了一层 GRPC，也都 OK。</p><p>但是当我想用 GPU 推理的时候，我直接下载了 libtorch 的 <a href="https://download.pytorch.org/libtorch/cu113/libtorch-cxx11-abi-shared-with-deps-1.11.0%2Bcu113.zip" target="_blank" rel="noopener">GPU 库</a>，然后直接编译语音程序（需要修改 <code>torch::Device</code>），可以直接跑在 GPU 上了，很开心。</p><p>但是我用第二次编译出来的库放到 go 程序中，则出现了诡异的错误，运行加载模型的时候，<code>model-&gt;to_device</code>，而且 <code>device_count</code> 为 0，很明显，程序没找到 GPU。</p><p>利用 ldd 查看 go 编译出来的可执行文件，发现没有链接到 <code>torch_cuda_*</code> 这些库，怎么会这么奇怪呢？我明明把这些库放到编译的 flags 中了。为此我反复调整了链接的 flag，包括库的顺序，库的路径等等，但是都无济于事。</p><p>几经辗转，终于找到一个和我类似的错误了。<a href="https://github.com/pytorch/pytorch/issues/72396" target="_blank" rel="noopener">https://github.com/pytorch/pytorch/issues/72396</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">Could not run &apos;aten::empty_strided&apos; with arguments from the &apos;CUDA&apos; backend. This could be because the operator doesn&apos;t exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. &apos;aten::empty_strided&apos; is only available for these backends: [CPU, Meta, BackendSelect, Python, Named, Conjugate, Negative, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, UNKNOWN_TENSOR_TYPE_ID, Autocast, Batched, VmapMode].</span><br><span class="line"></span><br><span class="line">CPU: registered at aten\src\ATen\RegisterCPU.cpp:18433 [kernel]</span><br><span class="line">Meta: registered at aten\src\ATen\RegisterMeta.cpp:12703 [kernel]</span><br><span class="line">BackendSelect: registered at aten\src\ATen\RegisterBackendSelect.cpp:665 [kernel]</span><br><span class="line">Python: registered at ..\..\aten\src\ATen\core\PythonFallbackKernel.cpp:47 [backend fallback]</span><br><span class="line">Named: registered at ..\..\aten\src\ATen\core\NamedRegistrations.cpp:7 [backend fallback]</span><br><span class="line">Conjugate: fallthrough registered at ..\..\aten\src\ATen\ConjugateFallback.cpp:22 [kernel]</span><br><span class="line">Negative: fallthrough registered at ..\..\aten\src\ATen\native\NegateFallback.cpp:22 [kernel]</span><br><span class="line">ADInplaceOrView: fallthrough registered at ..\..\aten\src\ATen\core\VariableFallbackKernel.cpp:64 [backend fallback]</span><br><span class="line">AutogradOther: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradCPU: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradCUDA: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradXLA: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradLazy: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradXPU: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradMLC: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradHPU: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradNestedTensor: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradPrivateUse1: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradPrivateUse2: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">AutogradPrivateUse3: registered at ..\..\torch\csrc\autograd\generated\VariableType_2.cpp:10483 [autograd kernel]</span><br><span class="line">Tracer: registered at ..\..\torch\csrc\autograd\generated\TraceType_2.cpp:11423 [kernel]</span><br><span class="line">UNKNOWN_TENSOR_TYPE_ID: fallthrough registered at ..\..\aten\src\ATen\autocast_mode.cpp:466 [backend fallback]</span><br><span class="line">Autocast: fallthrough registered at ..\..\aten\src\ATen\autocast_mode.cpp:305 [backend fallback]</span><br><span class="line">Batched: registered at ..\..\aten\src\ATen\BatchingRegistrations.cpp:1016 [backend fallback]</span><br><span class="line">VmapMode: fallthrough registered at ..\..\aten\src\ATen\VmapModeRegistrations.cpp:33 [backend fallback]</span><br><span class="line"></span><br><span class="line">Exception raised from reportError at ..\..\aten\src\ATen\core\dispatch\OperatorEntry.cpp:431 (most recent call first):</span><br><span class="line">00007FFEE7CAA29200007FFEE7CAA230 c10.dll!c10::Error::Error [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFEE7C843C500007FFEE7C84350 c10.dll!c10::NotImplementedError::NotImplementedError [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F015C7100007FFD5F015AA0 torch_cpu.dll!c10::impl::OperatorEntry::reportError [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F6C6AF000007FFD5F66DBB0 torch_cpu.dll!at::_ops::xlogy_Tensor::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8E73F100007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8E3F7400007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F6EB6E800007FFD5F6EB520 torch_cpu.dll!at::_ops::empty_strided::call [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5EF259CB00007FFD5EF258D0 torch_cpu.dll!at::empty_strided [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F2C24D100007FFD5F2C2130 torch_cpu.dll!at::native::_to_copy [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FA7C3D600007FFD5FA7BF10 torch_cpu.dll!at::compositeexplicitautograd::xlogy_ [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FA5A8FB00007FFD5FA3F310 torch_cpu.dll!at::compositeexplicitautograd::bitwise_xor_outf [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F4EB5AD00007FFD5F45B290 torch_cpu.dll!at::TensorMaker::make_tensor [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8DED7700007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F8E36EB00007FFD5F8CF610 torch_cpu.dll!at::_ops::zeros_out::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F4EB5AD00007FFD5F45B290 torch_cpu.dll!at::TensorMaker::make_tensor [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F56326800007FFD5F563190 torch_cpu.dll!at::_ops::_to_copy::redispatch [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD60A27F0000007FFD60A27A30 torch_cpu.dll!at::redispatch::_thnn_fused_lstm_cell_backward [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD60A4031D00007FFD60A34930 torch_cpu.dll!torch::jit::Node::c_ [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F50C12B00007FFD5F50BF70 torch_cpu.dll!at::_ops::_to_copy::call [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F2C2E7900007FFD5F2C2BD0 torch_cpu.dll!at::native::to_dense_backward [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F2C2B0C00007FFD5F2C29E0 torch_cpu.dll!at::native::to [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FB6A66800007FFD5FB63F10 torch_cpu.dll!at::compositeimplicitautograd::where [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5FB4DB5D00007FFD5FB1BE50 torch_cpu.dll!at::compositeimplicitautograd::broadcast_to [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5F7E6F4600007FFD5F7E6D70 torch_cpu.dll!at::_ops::to_dtype_layout::call [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5EF4AA8800007FFD5EF4A970 torch_cpu.dll!at::Tensor::to [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFD5EF9EAE900007FFD5EF9E9F0 torch_cpu.dll!at::tensor [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FF7714295A200007FF7714294B0 SplinterlandsSimulator.exe!main [C:\Users\xargo\source\repos\SplinterlandsSimulator\SplinterlandsSimulator\SplinterlandsSimulator.cpp @ 390]</span><br><span class="line">00007FF77144164C00007FF771441540 SplinterlandsSimulator.exe!__scrt_common_main_seh [d:\a01\_work\20\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl @ 288]</span><br><span class="line">00007FFF47C554E000007FFF47C554D0 KERNEL32.DLL!BaseThreadInitThunk [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br><span class="line">00007FFF48DA485B00007FFF48DA4830 ntdll.dll!RtlUserThreadStart [&lt;unknown file&gt; @ &lt;unknown line number&gt;]</span><br></pre></td></tr></table></figure><p>上述报错跟我的很像，而且从下面的回复来看，也是没能链接到 cuda 相应的库。下面的回复给我了启发：<strong>如果我的 go 程序没用到 libtorch 的 cuda 接口，是不是不会主动链接到 libtorch 相应的 cuda 的库</strong>？</p><p>前面说了，ldd 查看的确实没有，那怎么让编译器强制链接到 libtorch 的 cuda 相应的库呢？显然是的，编译器默认使用了 <code>--as-needed</code> 编译参数，这也是合理的，我们没必要链接所有的动态库，动态库本来就是按需链接，但是在我们的这个使用场景中，会遇到这种特殊情况，使用 <code>--no-as-needed</code> 强制链接到 libtorch cuda 的相应库，结果就没有问题了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">--as-needed</span><br><span class="line">--no-as-needed</span><br><span class="line">This option affects ELF DT_NEEDED tags for dynamic libraries mentioned on the command line after the --as-needed option. Normally the linker will add a DT_NEEDED tag for each dynamic library mentioned on the command line, regardless of whether the library is actually needed or not. --as-needed causes a DT_NEEDED tag to only be emitted for a library that satisfies an undefined symbol reference from a regular object file or, if the library is not found in the DT_NEEDED lists of other libraries linked up to that point, an undefined symbol reference from another dynamic library. --no-as-needed restores the default behaviour.</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 libtorch 的 C++ 动态链接库遇到了一个非常诡异的问题…&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="link" scheme="https://murphypei.github.io/tags/link/"/>
    
      <category term="no-as-needed" scheme="https://murphypei.github.io/tags/no-as-needed/"/>
    
      <category term="undef" scheme="https://murphypei.github.io/tags/undef/"/>
    
  </entry>
  
  <entry>
    <title>shared_ptr 和 unique_ptr 深入探秘</title>
    <link href="https://murphypei.github.io//blog/2022/03/shared-unique-ptr.html"/>
    <id>https://murphypei.github.io//blog/2022/03/shared-unique-ptr.html</id>
    <published>2022-03-24T02:52:47.000Z</published>
    <updated>2025-06-25T02:00:04.070Z</updated>
    
    <content type="html"><![CDATA[<p>C++ 中 <code>shared_ptr</code> 和 <code>unique_ptr</code> 是 C++11 之后被广泛使用的两个智能指针，但是其实他们在使用上还是有一些“秘密”的，我根据平时遇到的两个问题，总结记录一些知识。</p><a id="more"></a><h3 id="为什么-unique-ptr-需要明确知道类型的析构函数"><a href="#为什么-unique-ptr-需要明确知道类型的析构函数" class="headerlink" title="为什么 unique_ptr 需要明确知道类型的析构函数"></a>为什么 unique_ptr 需要明确知道类型的析构函数</h3><p>这个问题是我写 <code>unique_ptr</code> 调试接口的时候才注意到的，之前确实不知道。为什么会这样呢？首先我们必须要知道 <code>unique_ptr</code> 到底封装了什么？通常 <code>unique_ptr</code> 就是简单的对裸指针封装，并且禁用拷贝和赋值：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">T</span>,</span></span><br><span class="line"><span class="class">    <span class="title">class</span> <span class="title">Deleter</span> = <span class="title">std</span>:</span>:default_delete&lt;T&gt;</span><br><span class="line">&gt; <span class="class"><span class="keyword">class</span> <span class="title">unique_ptr</span>;</span></span><br></pre></td></tr></table></figure><p>可以看到，<code>Deleter</code> 的类型是 <code>unique_ptr</code> 类型的一部分。在 <code>unique_ptr</code> 内部会保存类型为 <code>T*</code> 和 <code>Deleter</code> 的成员 ，分别表示保存的裸指针和删除器。假设内部是这么实现的 (一般会运用空基类优化把 <code>Deleter</code> 的空间优化掉，<code>libstdc++</code> 里把他们放进了一个 tuple。这里是简化了)：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    T* p;</span><br><span class="line">    Deleter del;</span><br></pre></td></tr></table></figure><p>然后析构的时候就会这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~<span class="built_in">unique_ptr</span>()</span><br><span class="line">&#123;</span><br><span class="line">    del(p);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当 <code>Deleter</code> 是默认的 <code>std::default_delete</code> 时，<code>del(p)</code> 就会 <code>delete p</code>，<code>delete</code> 会调用析构函数。而 <code>delete</code> 一个不完整类型的指针是 ub(undefined behavior)。在典型的实现中都会在 <code>delete</code> 前通过 <code>static_assert(sizeof(T) &gt; 0)</code> 做检查。 <code>sizeof</code> 对 incomplete type 求值会直接编译出错。</p><blockquote><p>incomplete type 是指当定义一个变量的时候，不知道应该分配多少内存。C++ 声明和定义最大的区别就是是否发生内存分配，当发生内存分配的时候，必须知道要分配多少内存，通常一个未定义的 struct，未指定长度的数组类型，都会引发 incomplete type 的问题。参考：<a href="https://docs.microsoft.com/en-us/cpp/c-language/incomplete-types?view=msvc-170" target="_blank" rel="noopener">https://docs.microsoft.com/en-us/cpp/c-language/incomplete-types?view=msvc-170</a></p></blockquote><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">student</span>;</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="keyword">sizeof</span>(student) &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br></pre></td></tr></table></figure><p>上述代码执行会报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">prog.cc:17:18: error: invalid application of &apos;sizeof&apos; to an incomplete type &apos;student&apos;</span><br><span class="line">    std::cout &lt;&lt; sizeof(student) &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure><p>只声明了结构体 <code>student</code>，但是并没有定义，所以是一个 incomplete type，所以 <code>sizeof</code> 无法执行。</p><p>回到 <code>unique_ptr</code>，现在我们知道 <code>unique_ptr</code> 的报错链路是 <code>unique_ptr</code>-&gt;<code>delete</code>-&gt;<code>sizoef</code>，也就是 <code>sizeof</code> 才是罪魁祸首。所以当 <code>Deleter</code> 非默认时，就不一定需要知道类型的析构函数。比如下面这样：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A is incomplete type</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>;</span></span><br><span class="line"><span class="keyword">auto</span> Del = [] (A*) &#123; &#125;;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">unique_ptr</span>&lt;A, <span class="keyword">decltype</span>(Del)&gt; ptr;</span><br></pre></td></tr></table></figure><p>因此可以对这个问题做定性：<strong>并不是 <code>unique_ptr</code> 需要知道析构函数，而是 <code>unique_ptr</code> 的默认删除器 <code>Deleter</code> 需要明确知道类型的析构函数</strong>。</p><p>继续深挖一下，这个问题会出现在 <code>shared_ptr</code> 吗？答案是<strong>不会</strong>。这又引入了另一个问题，shared_ptr 和 unique_ptr 的封装有什么不同？</p><h3 id="shared-ptr-的封装"><a href="#shared-ptr-的封装" class="headerlink" title="shared_ptr 的封装"></a>shared_ptr 的封装</h3><p>按理说 <code>shared_ptr.reset</code> 的时候需要 <code>delete</code> ptr 就需要 ptr 的类型（错了请指正），而 <code>shared_ptr</code> 的 template type 可以是 incomplete type（错误请指正）。cppreference 是这么描述的：</p><blockquote><p><code>std::shared_ptr</code> may be used with an incomplete typeT. However, the constructor from a raw pointer (template<class y> shared_ptr(Y<em>)) and the template<class y>void reset(Y</class></em>) member function may only be called with a pointer to a complete type (note that std::unique_ptr may be constructed from a raw pointer to an incomplete type).</class></p></blockquote><p><code>reset</code> 的时候需要类型完整。默认构造的时候允许是不完整类型。为什么会这样呢？<code>shared_ptr</code> 怎么处理 <code>Deleter</code> 呢？(还记得吧， Deleter 就是智能指针析构时候的删除操作)</p><p>在常见编译器的实现里，<code>shared_ptr</code> 把 <code>Deleter</code>（包括默认情况下的 operator delete）放进一个叫做 <strong>control block</strong> 的结构里，相当于做了一次 type erasure，把 <code>Deleter</code> 的类型从 <code>shared_ptr</code> 类型本身里面擦下去。<code>Deleter</code> 的类型在 control block 的具体类型上，<code>shared_ptr</code> 本身只<strong>持有一个 <code>control block</code> 基类的指针</strong>，通过虚函数来调用 <code>Deleter</code>。而因为 <code>shared_ptr</code> 构造的时候要求必须是 complete type，control block已经知道怎么析构了，<code>shared_ptr</code> 析构的时候就调用个虚函数，具体事情它不管的。</p><p>这下我们明白了，<code>unique_ptr</code> 的封装太简单了，没有 control block，<code>Deleter</code>（包括默认的std::default_delete）直接做在 <code>unique_ptr</code> 一起了，这就导致 <code>unique_ptr</code> 的析构函数需要亲手析构被管理的类型，因此析构函数必须看到 complete type。然而反过来，因为<strong>构建的时候只需要保存下指针，所以 <code>unique_ptr</code> 构造的时候不需要看到 complete type</strong>。这俩正好是反的。C++ 标准并没有规定这些实现细节，但是规定函数签名和特性的时候，是考虑着比较合理的实现方式来写标准的，到最后标准落下来之后也差不多只能这么实现了。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li><code>unique_ptr</code> 只保存了类型指针 ptr 和这个指针的析构方法，调用 delete ptr，就需要ptr的完整类型，为了防止这个问题出现，直接通过 assert sizeof 排除掉了这种风险。<strong><code>unique_ptr</code> 相当于在编译时绑定了删除器</strong>。</li><li><code>shared_ptr</code> 保存的是一个控制块的指针。控制块包含的就是一个引用计数和一个原来对象的裸指针。控制块中初始化的指针是 <code>nullptr</code>，在运行时为其赋值，也可以通过 <code>reset</code> 修改。类似于虚函数，<strong><code>shared_ptr</code> 相当于在运行时绑定了删除器</strong>。</li></ul><p>虽然只是一个小小的知识点，但是也帮助我深入理解了 <code>shared_ptr</code> 和 <code>unique_ptr</code> 在设计上的区别，对于不同使用场景下选择不同智能指针的体会也更加深刻。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;C++ 中 &lt;code&gt;shared_ptr&lt;/code&gt; 和 &lt;code&gt;unique_ptr&lt;/code&gt; 是 C++11 之后被广泛使用的两个智能指针，但是其实他们在使用上还是有一些“秘密”的，我根据平时遇到的两个问题，总结记录一些知识。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="delete" scheme="https://murphypei.github.io/tags/delete/"/>
    
      <category term="c++" scheme="https://murphypei.github.io/tags/c/"/>
    
      <category term="shared_ptr" scheme="https://murphypei.github.io/tags/shared-ptr/"/>
    
      <category term="unique_ptr" scheme="https://murphypei.github.io/tags/unique-ptr/"/>
    
      <category term="template" scheme="https://murphypei.github.io/tags/template/"/>
    
  </entry>
  
  <entry>
    <title>使用 pyenv 搭建任意 python 环境</title>
    <link href="https://murphypei.github.io//blog/2022/01/pyenv-virtualenv.html"/>
    <id>https://murphypei.github.io//blog/2022/01/pyenv-virtualenv.html</id>
    <published>2022-01-13T02:47:20.000Z</published>
    <updated>2025-06-25T02:00:04.070Z</updated>
    
    <content type="html"><![CDATA[<p>开发和部署的过程中，常常遇到 python 版本和环境导致的冲突不兼容问题，pyenv 能够完美解决。</p><a id="more"></a><p>virtualenv 可以搭建虚拟且独立的 python 环境，可以使每个项目环境与其他项目独立开来，保持环境的干净，解决包冲突问题。但是这个依赖于已安装的 python 版本，相当于<strong>同一版本的不同环境</strong>。</p><p>pyenv 可以帮助你在一台开发机上建立多个版本的 python 环境，并提供方便的切换方法，可以搭配 virtualenv，完美解决 python 环境冲突，自由搭建任意版本的 python 环境。</p><h3 id="pyenv-安装"><a href="#pyenv-安装" class="headerlink" title="pyenv 安装"></a>pyenv 安装</h3><p><strong>安装 pyenv 之前建议卸载本机的 virtualenv 和 virtualenvwrapper 等相关虚拟环境</strong>，因为我从没用过 conda， 所以不清楚 conda 是否需要卸载。</p><ul><li><p>下载最新 pyenv </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/yyuu/pyenv.git ~/.pyenv</span><br></pre></td></tr></table></figure></li><li><p>配置环境变量</p></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.bashrc</span><br><span class="line">echo 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><blockquote><p>用 zsh 的改为 ~/.zshrc，下同</p></blockquote><ul><li>添加 pyenv 初始化到你的 shell</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 'eval "$(pyenv init -)"' &gt;&gt; ~/.bashrc</span><br></pre></td></tr></table></figure><ul><li>重新启动你的 shell 使更改生效</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">exec $SHELL</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><h3 id="安装某个版本的-python"><a href="#安装某个版本的-python" class="headerlink" title="安装某个版本的 python"></a>安装某个版本的 python</h3><p>首先我们可以查看一下有哪些版本的 python 可以安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv install --list</span><br></pre></td></tr></table></figure><p>一般情况下，几乎所有的 python 版本都可以安装，这也是 pyenv 强大之处。</p><ul><li>安装指定版本：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv install -v 3.9.9</span><br></pre></td></tr></table></figure><ul><li>安装完成后可以查看安装情况：</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv versions</span><br></pre></td></tr></table></figure><p>一般输出如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* system (set by ~/.pyenv/version)</span><br><span class="line">3.9.9</span><br></pre></td></tr></table></figure><p>system 代表当前系统的 python 版本, 3.9.9 是我们用pyenv安装的, *表示当前的 python 版本， 可以看到，我们还在使用的是默认的 system 自带的 python 版本。</p><ul><li>切换 python 版本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pyenv global 3.9.9</span><br><span class="line"><span class="meta">#</span><span class="bash"> pyenv <span class="built_in">local</span> 3.9.9</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> pyenv shell 3.9.9</span></span><br></pre></td></tr></table></figure><p>上面三条命令都可以切换 python 版本，区别简单解释如下：</p><ul><li><code>pyenv global</code> 读写 <code>~/.python-version</code> 文件，基本来说你在当前 shell 和今后打开的 shell 中，默认都是用这个版本的 python。</li><li><code>pyenv local</code> 读写<strong>当前目录</strong>的 <code>.python-version</code> 文件，相当于覆盖了 <code>~/.python-version</code> 的版本。</li><li><code>pyenv shell</code> 指定当前 shell 使用的 python 版本，相当于覆盖了前面两个。</li></ul><p>此外设置 <code>PYENV_VERSION</code> 变量也可以修改 python 版本，看上去很杂很乱，但是多用几次就明白了。详细命令文档看这里：<a href="https://github.com/pyenv/pyenv/blob/master/COMMANDS.md" target="_blank" rel="noopener">pyenv commands</a></p><ul><li>卸载 python 版本</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv uninstall 3.9.9</span><br></pre></td></tr></table></figure><h3 id="pyenv-中使用-virtualenv"><a href="#pyenv-中使用-virtualenv" class="headerlink" title="pyenv 中使用 virtualenv"></a>pyenv 中使用 virtualenv</h3><p>pyenv virtualenv 是 pyenv 的插件，为 UNIX 系统提供 pyenv virtualenv 命令。</p><ul><li>安装 pyenv-virtualenv</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv</span><br><span class="line">echo 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.bashrc</span><br><span class="line">source ~/.bashrc</span><br></pre></td></tr></table></figure><ul><li>创建虚拟环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv virtualenv 3.9.9 env399</span><br></pre></td></tr></table></figure><blockquote><p>创建虚拟环境的 python 版本需要提前装好</p></blockquote><ul><li>激活环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv activate env399</span><br></pre></td></tr></table></figure><p>切换后查看一下 python 版本：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">  system</span><br><span class="line">  3.9.9</span><br><span class="line">  3.9.9/envs/env399</span><br><span class="line">* env399 (set by PYENV_VERSION environment variable)</span><br></pre></td></tr></table></figure><ul><li>退出虚拟环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pyenv deactivate</span><br></pre></td></tr></table></figure><ul><li>删除虚拟环境</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf ~/.pyenv/versions/env399</span><br></pre></td></tr></table></figure><h3 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h3><ul><li>安装依赖</li></ul><p>自己谷歌查依赖的安装，我测试没遇到过。</p><ul><li>activate 激活不生效</li></ul><p>简单来说就是激活后 <code>pyenv versions</code> 显示生效了，<code>python version</code> 还是系统版本，暂时没找到具体原因，手动指定激活可以解决 <code>source ~/.pyenv/version/env399/bin/activate</code>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开发和部署的过程中，常常遇到 python 版本和环境导致的冲突不兼容问题，pyenv 能够完美解决。&lt;/p&gt;
    
    </summary>
    
      <category term="Python" scheme="https://murphypei.github.io/categories/Python/"/>
    
    
      <category term="python" scheme="https://murphypei.github.io/tags/python/"/>
    
      <category term="virtualenv" scheme="https://murphypei.github.io/tags/virtualenv/"/>
    
      <category term="pyenv" scheme="https://murphypei.github.io/tags/pyenv/"/>
    
      <category term="activate" scheme="https://murphypei.github.io/tags/activate/"/>
    
  </entry>
  
  <entry>
    <title>SSH 穿越多个跳板机的连接方法</title>
    <link href="https://murphypei.github.io//blog/2021/12/ssh-proxyjump.html"/>
    <id>https://murphypei.github.io//blog/2021/12/ssh-proxyjump.html</id>
    <published>2021-12-27T02:40:42.000Z</published>
    <updated>2025-06-25T02:00:04.066Z</updated>
    
    <content type="html"><![CDATA[<p>鉴于安全原因，工作需要使用跳板机登录；鉴于服务器环境老旧，我需要在服务器上使用 docker 来搞个开发环境，所以需要有一种方法穿越层层阻隔，让我的 vscode 直接连过去。</p><a id="more"></a><h2 id="SSH-公钥和私钥"><a href="#SSH-公钥和私钥" class="headerlink" title="SSH 公钥和私钥"></a>SSH 公钥和私钥</h2><ul><li>首先搞清楚一些基本关系，一般使用密钥登录，<code>ssh-keygen -t rsa</code> 运行此命令产生公钥私钥（id_rsa 和 id_rsa.pub），一路回车可以不设置保护密码，假设要登录的机器是 server，登录的终端是 client，那么将公钥 id_rsa.pub 的内容记录在 server 的 authorized_keys 中，然后 client 使用私钥 id_rsa 登录。</li><li>每一个被登录的机器都开启的 ssh 服务，并配置了 ssh 密钥登录功能。对于我的需求来说，公司的跳板机和服务器一定是已经配置的，否则无法登录服务器，因此我还需要在 docker 中配置 ssh 密钥登录服务。</li><li>client 设置登录的层层专跳（这是重点）</li></ul><blockquote><p>ssh 相关的文件如果没有特殊说明，都是在 <code>~/.ssh</code> 文件夹中，ssh 服务的配置文件在 <code>/etc/ssh/sshd_config</code> 中。</p></blockquote><h2 id="openssh-的-ProxyJump"><a href="#openssh-的-ProxyJump" class="headerlink" title="openssh 的 ProxyJump"></a>openssh 的 ProxyJump</h2><p>在 openssh7.5 之后（ubuntu18.04），支持 ProxyJump 语句，非常方便。windows 不支持。</p><p>假设我们登录路径是这样的：</p><p>client-&gt;jump_server-&gt;server-&gt;dev_docker</p><p>那么 client 的 <code>~/.ssh/config</code> 文件应该如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Host jump</span><br><span class="line">    HostName &lt;jump_server ip&gt;</span><br><span class="line">    Port &lt;jump_server port&gt;</span><br><span class="line">    User &lt;jump_server username&gt;</span><br><span class="line">    IdentityFile &lt;jump_server id_rsa&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Host server</span><br><span class="line">    HostName &lt;server ip&gt;</span><br><span class="line">    Port &lt;server port&gt;</span><br><span class="line">    User &lt;server username&gt;</span><br><span class="line">    IdentityFile &lt;server id_rsa&gt;</span><br><span class="line">    ProxyJump jump</span><br><span class="line"></span><br><span class="line">Host dev_docker</span><br><span class="line">    HostName &lt;dev_docker ip&gt;</span><br><span class="line">    Port &lt;dev_docker port&gt;</span><br><span class="line">    User &lt;dev_docker username&gt;</span><br><span class="line">    IdentityFile &lt;dev_docker id_rsa&gt;</span><br><span class="line">    ProxyJump server</span><br></pre></td></tr></table></figure><p>然后在 client 中，直接使用 <code>ssh dev_docker</code> 命令，ssh 就会一步步登录过去。使用 <code>-v</code> 可以看到每一步的登录过程。</p><p>vscode 会自动读取 config 文件，就可以直接打开 docker 中的文件夹了。真的很方便。</p><p>还有两个比较实用的配置，同样是配置在客户端：</p><ul><li><code>ServerAliveInterval 60</code>：每隔 60s 服务器发送一个包看客户端是否有响应。</li><li><code>ServerAliveCountMax 600</code>：服务器发出请求后客户端没有响应的次数达到一定值，就自动断开，正常情况下，客户端不会不响应。</li></ul><p>这两个配置组合就可以保持 ssh 的长连接了，不用一直手动连接。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;鉴于安全原因，工作需要使用跳板机登录；鉴于服务器环境老旧，我需要在服务器上使用 docker 来搞个开发环境，所以需要有一种方法穿越层层阻隔，让我的 vscode 直接连过去。&lt;/p&gt;
    
    </summary>
    
      <category term="Linux" scheme="https://murphypei.github.io/categories/Linux/"/>
    
    
      <category term="linux" scheme="https://murphypei.github.io/tags/linux/"/>
    
      <category term="ssh" scheme="https://murphypei.github.io/tags/ssh/"/>
    
      <category term="proxy" scheme="https://murphypei.github.io/tags/proxy/"/>
    
      <category term="proxyjump" scheme="https://murphypei.github.io/tags/proxyjump/"/>
    
      <category term="jump" scheme="https://murphypei.github.io/tags/jump/"/>
    
  </entry>
  
  <entry>
    <title>C++ 使用 protobuf 踩坑的一次记录</title>
    <link href="https://murphypei.github.io//blog/2021/12/protobuf-debug.html"/>
    <id>https://murphypei.github.io//blog/2021/12/protobuf-debug.html</id>
    <published>2021-12-01T02:40:42.000Z</published>
    <updated>2025-06-25T02:00:04.062Z</updated>
    
    <content type="html"><![CDATA[<p>之前用 protobuf 都比较随意，直到用 protobuf 发布 SDK，遇到了一个坑，恰好遇到了手机的一些问题，导致连环坑。</p><a id="more"></a><h2 id="坑1："><a href="#坑1：" class="headerlink" title="坑1："></a>坑1：</h2><p>这个坑很常见，不仅仅对于我，大概情况如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[libprotobuf ERROR /home/murphy/code/github/protobuf/src/google/protobuf/descriptor_database.cc:58] File already exists <span class="keyword">in</span> database: speech_ai.capt.proto[libprotobuf FATAL /home/murphy/code/github/protobuf/src/google/protobuf/descriptor.cc:1358] CHECK failed: GeneratedDatabase()-&gt;Add(encoded_file_descriptor, size): terminating with uncaught exception of <span class="built_in">type</span> google::protobuf::FatalException: CHECK failed: GeneratedDatabase()-&gt;Add(encoded_file_descriptor, size)</span><br></pre></td></tr></table></figure><p>这个错误原因是因为在两个编译目标（共享库或者可执行文件）中都引入了相同的 <code>*.pb.cc</code> 文件。举个例子：</p><ul><li>我们有个 <code>example.proto</code>，生成了 <code>example.pb.h</code> 和 <code>example.pb.cc</code> 两个文件。</li><li>首先编译一个共享库 <code>A.so</code>，编译的时候需要加入 <code>example.pb.cc</code> 文件，因为其中包含了函数定义。</li><li>编译一个可执行文件 <code>B.out</code>，用来测试 <code>A.so</code> 的接口是否合适，因为 <code>B.out</code> 中也用到了 <code>example.pb.cc</code> 中的函数定义，所以按照常规的想法，也需要加入到其中编译（不然会报 undefined reference 错误），并且 <code>B.out</code> 需要链接 <code>A.so</code>。</li></ul><p>如果这种常规做法，就会报上面类似的错误，我查询的原因可以总结如下（也怪我学艺不精，不太了解 protobuf 的内部机制）：<strong>protobuf 本身有一个 global 的 registry。每个 message type 都需要去那里注册一下，而且不能重复注册</strong>。上述的 <code>Add</code> 错误就是因为注册失败，原因就是因为 <code>A.so</code> 和 <code>B.out</code> 中重复注册了（两份 <code>pb.cc</code> 实现）。</p><ul><li>据说换成 protobuf-lite 就能避免这个问题，但是 Google 官方并没有对此表态。</li></ul><p>最常规的解决办法就是把所有 <code>pb.cc</code> 文件编译成一个共享库 <code>p.so</code>，然后 <code>A.so</code> 和 <code>B.out</code> 都去链接这个共享库。这里需要注意，编译的时候需要设置 <code>visibility=default</code>，把符号都打开（一般 SDK 都会隐藏符号）。</p><h2 id="坑2："><a href="#坑2：" class="headerlink" title="坑2："></a>坑2：</h2><p>这个坑很奇怪，大概如下：我使用 ndk 和 protobuf v3.6.1 编译了 android 的 <code>libprotobuf.so</code>，然后用这个共享库编译 android native 测序程序，运行遇到 Version verification failed，大概如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[libprotobuf FATAL /home/murphy/code/github/protobuf/src/google/protobuf/stubs/common.cc:79] This program was compiled against version 3.0.0 of the Protocol Buffer runtime library, <span class="built_in">which</span> is not compatible with the installed version (3.6.1).  Contact the program author <span class="keyword">for</span> an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed <span class="keyword">in</span> <span class="string">"external/protobuf/src/google/protobuf/any.pb.cc"</span>.)terminating with uncaught exception of <span class="built_in">type</span> google::protobuf::FatalException: This program was compiled against version 3.0.0 of the Protocol Buffer runtime library, <span class="built_in">which</span> is not compatible with the installed version (3.6.1).  Contact the program author <span class="keyword">for</span> an update.  If you compiled the program yourself, make sure that your headers are from the same version of Protocol Buffers as your link-time library.  (Version verification failed <span class="keyword">in</span> <span class="string">"external/protobuf/src/google/protobuf/any.pb.cc"</span>.)</span><br></pre></td></tr></table></figure><p>在 android 使用 gdbserver 调试发现（<a href="https://murphypei.github.io/blog/2021/09/android-gdbserver.html">教程</a>），<code>/system/lib64/</code> 下面有个 <code>protobuf.so</code>，这个 so 的版本是 v3.0.0，但是我们编译的程序理论上是用 v3.6.1 编译的。看上去这里运行的时候，链接的是 v3.6.1，但是 v3.6.1 的符号没有覆盖默认的 v3.0.0 的符号，导致 <code>GOOGLE_PROTOBUF_VERSION</code> 这个符号变成了 <code>3000000</code> 而不是 <code>3006001</code>，所以就会失败。</p><p>这个问题没有找到解决方案，我换了一个测试手机，没有复现这个问题，所以猜测可能是之前的测试手机有一些问题，如果遇到这个问题，建议换个测试手机试试。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前用 protobuf 都比较随意，直到用 protobuf 发布 SDK，遇到了一个坑，恰好遇到了手机的一些问题，导致连环坑。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="registry" scheme="https://murphypei.github.io/tags/registry/"/>
    
      <category term="protobuf" scheme="https://murphypei.github.io/tags/protobuf/"/>
    
      <category term="共享库" scheme="https://murphypei.github.io/tags/%E5%85%B1%E4%BA%AB%E5%BA%93/"/>
    
      <category term="protoc" scheme="https://murphypei.github.io/tags/protoc/"/>
    
  </entry>
  
  <entry>
    <title>使用 vscode 调试 C++ 程序</title>
    <link href="https://murphypei.github.io//blog/2021/11/vscode-cpp.html"/>
    <id>https://murphypei.github.io//blog/2021/11/vscode-cpp.html</id>
    <published>2021-11-04T03:00:28.000Z</published>
    <updated>2025-06-25T02:00:04.062Z</updated>
    
    <content type="html"><![CDATA[<p>vscode 远程比 clion 好用太多了，就是 C++ 调试功能不如 clion，不过简单配置一下，也可以实现单步调试，比简陋的 GDB 还是好用多了。</p><a id="more"></a><p>下面的配置是我的某个项目的配置，仅仅作为参考和自己的记录，因为国内大部分的教程都只写单独的文件，没啥参考价值。</p><h3 id="c-cpp-properties-json"><a href="#c-cpp-properties-json" class="headerlink" title="c_cpp_properties.json"></a>c_cpp_properties.json</h3><p>这个文件主要是配置一些头文件路径，不过现在 vscode 对于头文件的支持还是不太行，配置了还有很多波浪线，头疼。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"configurations"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"Linux"</span>,</span><br><span class="line">            <span class="attr">"includePath"</span>: [</span><br><span class="line">                <span class="string">"$&#123;workspaceFolder&#125;/**"</span>,</span><br><span class="line">                <span class="string">"$&#123;workspaceFolder&#125;/build"</span></span><br><span class="line">            ],</span><br><span class="line">            <span class="attr">"defines"</span>: [],</span><br><span class="line">            <span class="attr">"configurationProvider"</span>: <span class="string">"ms-vscode.cmake-tools"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"version"</span>: <span class="number">4</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="tasks-json"><a href="#tasks-json" class="headerlink" title="tasks.json"></a>tasks.json</h3><p>这个文件是执行真正的任务，主要是编译任务。以前我以为只支持 g++ 命令（坑爹的国内教程），后来想通了，这个文件其实就是执行 linux 命令，你可以放 cmake、make 甚至编译脚本的命令，我通常喜欢写一个编译脚本来编译。</p><p>下面的例子，cmake 和 make 执行编译，build 通过脚本编译。make 任务可以不需要 cmake 重新生成（关闭 dependsOn），方便快速增量编译。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"version"</span>: <span class="string">"2.0.0"</span>,</span><br><span class="line">    <span class="attr">"tasks"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"label"</span>: <span class="string">"cmake"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="attr">"options"</span>: &#123;</span><br><span class="line">                <span class="attr">"cwd"</span>: <span class="string">"$&#123;workspaceFolder&#125;/build"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"command"</span>: <span class="string">"cmake -DCMAKE_BUILD_TYPE=Debug -DBUILD_ANDROID=OFF -DBUILD_UNIT_TESTS=ON -DBUILD_SHARED_LIBS=ON -DCUDA_ENABLE=OFF .. "</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"label"</span>: <span class="string">"make"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="attr">"options"</span>: &#123;</span><br><span class="line">                <span class="attr">"cwd"</span>: <span class="string">"$&#123;workspaceFolder&#125;/build"</span></span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"command"</span>: <span class="string">"make -j8"</span>,</span><br><span class="line">            // "dependsOn": [</span><br><span class="line">            //     "cmake"</span><br><span class="line">            // ],</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"label"</span>: <span class="string">"build"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"shell"</span>,</span><br><span class="line">            <span class="attr">"command"</span>: <span class="string">"source $&#123;workspaceFolder&#125;/linux.sh"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="launch-json"><a href="#launch-json" class="headerlink" title="launch.json"></a>launch.json</h3><p>用 GDB 执行可执行文件，没啥说的，注意 preLaunchTask 根据需要选择（tasks.json 中配置的 build 彻底重新编译，make 只编译改动的头文件）。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    // 使用 IntelliSense 了解相关属性。 </span><br><span class="line">    // 悬停以查看现有属性的描述。</span><br><span class="line">    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387</span><br><span class="line">    "version": "0.2.0",</span><br><span class="line">    "configurations": [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"name"</span>: <span class="string">"capt_test"</span>,</span><br><span class="line">            <span class="attr">"type"</span>: <span class="string">"cppdbg"</span>,</span><br><span class="line">            <span class="attr">"request"</span>: <span class="string">"launch"</span>,</span><br><span class="line">            <span class="attr">"program"</span>: <span class="string">"$&#123;workspaceFolder&#125;/build/capt_test"</span>,</span><br><span class="line">            <span class="attr">"args"</span>: [],</span><br><span class="line">            <span class="attr">"stopAtEntry"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"cwd"</span>: <span class="string">"$&#123;workspaceFolder&#125;"</span>,</span><br><span class="line">            <span class="attr">"environment"</span>: [],</span><br><span class="line">            <span class="attr">"externalConsole"</span>: <span class="literal">false</span>,</span><br><span class="line">            <span class="attr">"MIMode"</span>: <span class="string">"gdb"</span>,</span><br><span class="line">            <span class="attr">"setupCommands"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="attr">"description"</span>: <span class="string">"为 gdb 启用整齐打印"</span>,</span><br><span class="line">                    <span class="attr">"text"</span>: <span class="string">"-enable-pretty-printing"</span>,</span><br><span class="line">                    <span class="attr">"ignoreFailures"</span>: <span class="literal">true</span></span><br><span class="line">                &#125;</span><br><span class="line">            ],</span><br><span class="line">            // "preLaunchTask": "make"</span><br><span class="line">            "preLaunchTask": "build"</span><br><span class="line">        &#125;,</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;vscode 远程比 clion 好用太多了，就是 C++ 调试功能不如 clion，不过简单配置一下，也可以实现单步调试，比简陋的 GDB 还是好用多了。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="c++" scheme="https://murphypei.github.io/tags/c/"/>
    
      <category term="vscode" scheme="https://murphypei.github.io/tags/vscode/"/>
    
      <category term="tasks" scheme="https://murphypei.github.io/tags/tasks/"/>
    
      <category term="launch" scheme="https://murphypei.github.io/tags/launch/"/>
    
      <category term="c_cpp_properties" scheme="https://murphypei.github.io/tags/c-cpp-properties/"/>
    
  </entry>
  
  <entry>
    <title>语音识别 FBank 和 MFCC 特征</title>
    <link href="https://murphypei.github.io//blog/2021/10/asr-fbank-mfcc.html"/>
    <id>https://murphypei.github.io//blog/2021/10/asr-fbank-mfcc.html</id>
    <published>2021-10-13T04:21:07.000Z</published>
    <updated>2025-06-25T02:00:04.058Z</updated>
    
    <content type="html"><![CDATA[<p>ASR 流程中，音频特征提取是第一步。和 CV 不同，图片本身的 RGB 数值就是一种特征，但是音频本身无法被用于分析，常常是将一段音频提取 FBank 和 MFCC 特征然后作为模型的输入。</p><a id="more"></a><p>语音参数提取特征的步骤：预增强-&gt;分帧-&gt;加窗-&gt;添加噪声-&gt;FFT-&gt;Mel滤波-&gt;对数运算-&gt;DCT。其中 FFT 和 DCT 是快速傅里叶变换和离散余弦变换。</p><h2 id="音频预处理"><a href="#音频预处理" class="headerlink" title="音频预处理"></a>音频预处理</h2><h3 id="预增强（Pre-Emphasis）"><a href="#预增强（Pre-Emphasis）" class="headerlink" title="预增强（Pre-Emphasis）"></a>预增强（Pre-Emphasis）</h3><p>预增强一般是数字语音信号处理的第一步。语音信号往往会有频谱倾斜（Spectral Tilt）现象，即高频部分的幅度会比低频部分的小，预增强在这里就是起到一个平衡频谱的作用，增大高频部分的幅度。它使用如下的一阶滤波器来实现：</p><script type="math/tex; mode=display">y(t) = x(t) - \alpha * x(t-1), 0.95 < \alpha < 0.99</script><h3 id="分帧（Framing）"><a href="#分帧（Framing）" class="headerlink" title="分帧（Framing）"></a>分帧（Framing）</h3><p>输入的音频信号是一段连续，一般流式的有几百毫秒，非流式的有几秒或者更长，需要将信号分成短时帧。做这一步的原因是：信号中的频率会随时间变化（不稳定的），一些信号处理算法（比如傅里叶变换）通常希望信号是稳定，也就是说对整个信号进行处理是没有意义的，因为信号的频率轮廓会随着时间的推移而丢失。为了避免这种情况，需要对信号进行分帧处理，认为每一帧之内的信号是短时不变的。一般设置帧长取 20ms~40ms，相邻帧之间 50\%（+/-10\%）的覆盖。对于 ASR 而言，通常取帧长为 25ms，帧移为 10ms（不重叠部分）。</p><h3 id="加窗"><a href="#加窗" class="headerlink" title="加窗"></a>加窗</h3><p>在分帧之后，通常需要对每帧的信号进行加窗处理。目的是让帧两端平滑地衰减，这样可以降低后续傅里叶变换后旁瓣的强度，取得更高质量的频谱。常用的窗有：矩形窗、汉明（Hamming）窗、汉宁窗（Hanning），以汉明窗为例，其窗函数为：</p><script type="math/tex; mode=display">w(n)=0.54-0.46cos(\frac{2\pi n}{N-1}), 0\le n\le N-1</script><h3 id="随机添加噪声（可选）"><a href="#随机添加噪声（可选）" class="headerlink" title="随机添加噪声（可选）"></a>随机添加噪声（可选）</h3><p>有时候我们需要进行数据增强，会手动合成一些音频。某些人工合成的音频可能会造成一些数字错误，诸如 underflow 或者 overflow。 这种情况下，通过添加随机噪声可以解决这一类问题。公式如下：</p><script type="math/tex; mode=display">s(n)=s(n)+q∗rand()</script><p>$q$ 用于控制添加噪声的强度，$rand()$ 产生 $[-1.0, 1.0)$ 的随机数。</p><p>注意：Kaldi 中是在分帧之后的下一步添加随机噪声</p><h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p>人耳对声音频谱的响应是非线性的，经验表明：如果我们能够设计一种前端处理算法，以类似于人耳的方式对音频进行处理，可以提高语音识别的性能。FilterBank就是这样的一种算法。FBank 特征提取要在预处理之后进行，这时语音已经分帧，我们需要逐帧提取 FBank 特征。</p><h3 id="快速傅里叶变换（FFT）"><a href="#快速傅里叶变换（FFT）" class="headerlink" title="快速傅里叶变换（FFT）"></a>快速傅里叶变换（FFT）</h3><p>我们分帧之后得到的仍然是时域信号，为了提取 FBank 特征，首先需要<strong>将时域信号转换为频域信号</strong>。傅里叶变换可以将信号从时域转到频域。傅里叶变换可以分为连续傅里叶变换和离散傅里叶变换，因为我们用的是数字音频（而非模拟音频），所以我们用到的是离散傅里叶变换。数学公式如下：</p><script type="math/tex; mode=display">X(k)=\sum_{j=1}^{N} x(j)w_{N}^{(j-1)(k-1)}</script><p>对每一帧加窗后的音频信号做 N 点的 FFT 变换，也称短时傅里叶变换（STFT），N通常取256或512，然后用如下的公式<strong>计算能量谱</strong>：</p><script type="math/tex; mode=display">P=\frac{|FFT(x_i)|^2}{N}</script><h3 id="FBank-Filter-Banks-特征"><a href="#FBank-Filter-Banks-特征" class="headerlink" title="FBank(Filter Banks)特征"></a>FBank(Filter Banks)特征</h3><p>经过上面的步骤之后，在能量谱上应用 Mel 滤波器组，就能提取到FBank特征。</p><p>在介绍Mel滤波器组之前，先介绍一下 Mel 刻度，这是一个能模拟人耳接收声音规律的刻度，人耳在接收声音时呈现非线性状态，对高频的更不敏感，因此 Mel 刻度在低频区分辨度较高，在高频区分辨度较低，与频率之间的换算关系为：</p><script type="math/tex; mode=display">m=2595log_{10}(1+\frac{f}{700})</script><p>Mel 滤波器组就是一系列的三角形滤波器，通常有 40 个或 80 个，在中心频率点响应值为 1，在两边的滤波器中心点线性衰减到 0，如下图：</p><p><img src="/images/posts/asr/fbank_mfcc/mel.jpg" alt></p><p>具体公式就不写了，网上可查。</p><p>在能量谱上应用 Mel 滤波器组，其公式为：</p><script type="math/tex; mode=display">Y_{t}(m)=\sum_{k=1}^{N} H_{m}(k)|X_t(k)|^2</script><p>其中，$k$ 表示 FFT 变换后的编号，$m$ 表示 Mel 滤波器的编号。</p><h3 id="MFCC-Mel-frequency-Cepstral-Coefficients-特征"><a href="#MFCC-Mel-frequency-Cepstral-Coefficients-特征" class="headerlink" title="MFCC(Mel-frequency Cepstral Coefficients)特征"></a>MFCC(Mel-frequency Cepstral Coefficients)特征</h3><p>前面提取到的 FBank 特征，往往是高度相关的。因此可以继续用 DCT 变换，将这些相关的滤波器组系数进行压缩。对于 ASR 来说，通常取 2~13 维，扔掉的信息里面包含滤波器组系数快速变化部分，这些细节信息在 ASR 任务上可能没有帮助。</p><p><strong>DCT 变换其实是逆傅里叶变换的等价替代</strong>：</p><script type="math/tex; mode=display">y_t(n)=\sum_{m=0}^{M-1}log(Y_{t}(m))cos(n(m+0.5)\frac{\pi }{M}), n=0,...,J</script><p>所以 MFCC 名字里面有倒谱（Cepstral）。</p><p>一般对于ASR来说，对 MFCC 进行一个正弦提升（sinusoidal liftering）操作，可以提升在噪声信号中最后的识别率：</p><script type="math/tex; mode=display">MFCC_i^{'}=w_iMFCC_i</script><script type="math/tex; mode=display">w_i=\frac{D}{2}sin(\frac{\pi * i}{D})</script><p>从公式看，猜测原因可能是对频谱做一个平滑，如果 $D$ 取值较大时，会加重高频部分，使得噪声被弱化。</p><h3 id="python-实现"><a href="#python-实现" class="headerlink" title="python 实现"></a>python 实现</h3><p><a href="https://gist.github.com/murphypei/dcae63c9de780586a70a89603bd0f2c2" target="_blank" rel="noopener">https://gist.github.com/murphypei/dcae63c9de780586a70a89603bd0f2c2</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ASR 流程中，音频特征提取是第一步。和 CV 不同，图片本身的 RGB 数值就是一种特征，但是音频本身无法被用于分析，常常是将一段音频提取 FBank 和 MFCC 特征然后作为模型的输入。&lt;/p&gt;
    
    </summary>
    
      <category term="ASR" scheme="https://murphypei.github.io/categories/ASR/"/>
    
    
      <category term="fbank" scheme="https://murphypei.github.io/tags/fbank/"/>
    
      <category term="mfcc" scheme="https://murphypei.github.io/tags/mfcc/"/>
    
      <category term="asr" scheme="https://murphypei.github.io/tags/asr/"/>
    
      <category term="fft" scheme="https://murphypei.github.io/tags/fft/"/>
    
  </entry>
  
  <entry>
    <title>使用 gdbserver 调试 Android Native 程序</title>
    <link href="https://murphypei.github.io//blog/2021/09/android-gdbserver.html"/>
    <id>https://murphypei.github.io//blog/2021/09/android-gdbserver.html</id>
    <published>2021-09-06T09:40:10.000Z</published>
    <updated>2025-06-25T02:00:04.054Z</updated>
    
    <content type="html"><![CDATA[<p>使用 Android NDK 编译得到 Android native program，可以直接 push 到手机上运行，但是没办法直接用 gdb debug。</p><a id="more"></a><p>为此，我们需要使用 gdbserver，也就是 gdb 远程调试功能。原理就不讲了，我自己尝试的过程中发现网上写的教程都是相互转载的，乱七八糟，不知所云。本文写原理（谷歌可查），仅仅记录下我已经确认可行的调试过程。</p><ol><li>首先，把 <code>$NDK/prebuilt/android-arm64/gdbserver/gdbserver</code> 以及要调试的程序 push 到手机上（任意文件夹）。</li><li>在手机上启动 gdbserver。<code>gdbserver :9090 &lt;exec&gt;</code>。其中 <code>:9090</code> 表示 gdbserver 监听手机的 9090 端口。会显示 <code>Listening on port 9090</code> 类似信息。如果有本地 lib，记得设置 <code>LD_LIBRARY_PATH</code> 环境变量。</li><li>设置端口转发。<code>adb forward tcp:9090 tcp:9090</code>，表示将本地 9090 端口转发到手机的 9090 端口。</li><li>本地启动 gdb。<code>$NDK/prebuilt/linux-x86_64/bin/gdb</code>。进入 gdb 调试页面。</li><li>设置调试对象。<code>target remote :9090</code>。调试本地的 9090 端口，同时也是手机的 9090 端口，也就是 gdbserver，连接成功之后， gdbserver 那边会显示 <code>Remote debugging from host 127.0.0.1</code> 字样。</li></ol><p>Android gdbserver 和 Linux gdb 有一些命令不太一样，但是很多还是相同的。启动程序不用 r，用 continue。</p><p>用 vscode 也可以，把上述流程弄到 vscode 的 task.json 中就行，只是觉得更麻烦了，所以没必要。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用 Android NDK 编译得到 Android native program，可以直接 push 到手机上运行，但是没办法直接用 gdb debug。&lt;/p&gt;
    
    </summary>
    
      <category term="C/C++" scheme="https://murphypei.github.io/categories/C-C/"/>
    
    
      <category term="C++" scheme="https://murphypei.github.io/tags/C/"/>
    
      <category term="gdbserver" scheme="https://murphypei.github.io/tags/gdbserver/"/>
    
      <category term="gdb remote" scheme="https://murphypei.github.io/tags/gdb-remote/"/>
    
      <category term="android" scheme="https://murphypei.github.io/tags/android/"/>
    
      <category term="native" scheme="https://murphypei.github.io/tags/native/"/>
    
  </entry>
  
  <entry>
    <title>LRU 缓存算法</title>
    <link href="https://murphypei.github.io//blog/2021/07/lru.html"/>
    <id>https://murphypei.github.io//blog/2021/07/lru.html</id>
    <published>2021-07-07T10:49:24.000Z</published>
    <updated>2025-06-25T02:00:04.054Z</updated>
    
    <content type="html"><![CDATA[<p>看到 lc 上有一道题是设计 LRU 算法，简单了解了一下作为记录。</p><a id="more"></a><p>LRU 算法实际上是让你设计数据结构：首先要接收一个 capacity 参数作为缓存的最大容量，然后实现两个 API，一个是 <code>put(key, val)</code> 方法存入键值对，另一个是 <code>get(key)</code> 方法获取 key 对应的 val，如果 key 不存在则返回 -1。</p><p>注意哦，get 和 put 方法必须都是 O(1) 的时间复杂度，我们举个具体例子来看看 LRU 算法怎么工作。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 缓存容量为 2 */</span></span><br><span class="line">LRUCache cache = <span class="keyword">new</span> LRUCache(<span class="number">2</span>);</span><br><span class="line"><span class="comment">// 你可以把 cache 理解成一个队列</span></span><br><span class="line"><span class="comment">// 假设左边是队头，右边是队尾</span></span><br><span class="line"><span class="comment">// 最近使用的排在队头，久未使用的排在队尾</span></span><br><span class="line"><span class="comment">// 圆括号表示键值对 (key, val)</span></span><br><span class="line"></span><br><span class="line">cache.put(<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="comment">// cache = [(1, 1)]</span></span><br><span class="line">cache.put(<span class="number">2</span>, <span class="number">2</span>);</span><br><span class="line"><span class="comment">// cache = [(2, 2), (1, 1)]</span></span><br><span class="line">cache.get(<span class="number">1</span>);       <span class="comment">// 返回 1</span></span><br><span class="line"><span class="comment">// cache = [(1, 1), (2, 2)]</span></span><br><span class="line"><span class="comment">// 解释：因为最近访问了键 1，所以提前至队头</span></span><br><span class="line"><span class="comment">// 返回键 1 对应的值 1</span></span><br><span class="line">cache.put(<span class="number">3</span>, <span class="number">3</span>);</span><br><span class="line"><span class="comment">// cache = [(3, 3), (1, 1)]</span></span><br><span class="line"><span class="comment">// 解释：缓存容量已满，需要删除内容空出位置</span></span><br><span class="line"><span class="comment">// 优先删除久未使用的数据，也就是队尾的数据</span></span><br><span class="line"><span class="comment">// 然后把新的数据插入队头</span></span><br><span class="line">cache.get(<span class="number">2</span>);       <span class="comment">// 返回 -1 (未找到)</span></span><br><span class="line"><span class="comment">// cache = [(3, 3), (1, 1)]</span></span><br><span class="line"><span class="comment">// 解释：cache 中不存在键为 2 的数据</span></span><br><span class="line">cache.put(<span class="number">1</span>, <span class="number">4</span>);    </span><br><span class="line"><span class="comment">// cache = [(1, 4), (3, 3)]</span></span><br><span class="line"><span class="comment">// 解释：键 1 已存在，把原始值 1 覆盖为 4</span></span><br><span class="line"><span class="comment">// 不要忘了也要将键值对提前到队头</span></span><br></pre></td></tr></table></figure><p>我们分析一下这个实现要求。查询和插入都需要 O(1)，那不用说了，只能是哈希表。C++ 可以用 <code>std::unordered_map</code> 实现。再看这个缓存满的时候，需要删除最久为使用的，所以每个元素必须在每次操作之后保持其顺序。这个实现比较灵活了，但是因为涉及 O(1) 插入，所以 <code>std::list</code> 是最合适的。总结：</p><ul><li>通过 key 查询和插入 O(1)，哈希表，但是哈希表无顺序。</li><li>链表可保持顺序，插入和删除 O(1)，但是查询慢。</li></ul><p>因此就需要将二者结合使用，也就是<strong>哈希链表</strong>。具体实现如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;list&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unordered_map&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    LRUCache(<span class="keyword">int</span> capacity) : capacity(capacity) &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">get</span><span class="params">(<span class="keyword">int</span> key)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hashTable.find(key) == hashTable.end())</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 更新到表头</span></span><br><span class="line">            <span class="keyword">auto</span> iter = hashTable[key]; <span class="comment">// 找到对应地址</span></span><br><span class="line">            cache.splice(cache.begin(), cache, iter); <span class="comment">// 移动到表头</span></span><br><span class="line">            <span class="keyword">return</span> cache.begin()-&gt;second;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">int</span> key, <span class="keyword">int</span> value)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hashTable.find(key) == hashTable.end())</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (cache.size() == capacity)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// 删除表尾</span></span><br><span class="line">                hashTable.erase(cache.back().first);</span><br><span class="line">                cache.pop_back();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 在表头添加</span></span><br><span class="line">            cache.push_front(<span class="built_in">std</span>::make_pair(key, value));</span><br><span class="line">            hashTable[key] = cache.begin();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">auto</span> iter    = hashTable[key];</span><br><span class="line">            iter-&gt;second = value; <span class="comment">// 更新元素</span></span><br><span class="line">            cache.splice(cache.begin(), cache, iter); <span class="comment">// 移动到表头</span></span><br><span class="line">            hashTable[key] = cache.begin(); <span class="comment">// 更新地址</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;<span class="keyword">int</span>, <span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;::iterator&gt; hashTable;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">list</span>&lt;<span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt;&gt;                                    cache; <span class="comment">// key, value</span></span><br><span class="line">    <span class="keyword">int</span>                                                               capacity = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>具体操作就很简单了，无非是哈希表和链表的查询、删除和移动。主要看成员变量 <code>hashTable</code> 和 <code>cache</code>。<code>cache</code> 保存的就是实际数据的 key 和 value，<code>hashTable</code> 保存链表的 key 和地址。</p><p>通过哈希表，我们能够弥补链表查询慢的特点，直取链表中 key 所在节点的位置。而通过链表，我们可以很容易的维持每次操作后元素的顺序。这里有一个需要注意的，<strong>链表中必须也存有 key</strong>，因为哈希表删除是需要 key 的，链表如果只能提供 value，哈希表将无法删除。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;看到 lc 上有一道题是设计 LRU 算法，简单了解了一下作为记录。&lt;/p&gt;
    
    </summary>
    
      <category term="Algorithm" scheme="https://murphypei.github.io/categories/Algorithm/"/>
    
    
      <category term="algorithm" scheme="https://murphypei.github.io/tags/algorithm/"/>
    
      <category term="LRU" scheme="https://murphypei.github.io/tags/LRU/"/>
    
      <category term="缓存" scheme="https://murphypei.github.io/tags/%E7%BC%93%E5%AD%98/"/>
    
      <category term="哈希表" scheme="https://murphypei.github.io/tags/%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    
      <category term="链表" scheme="https://murphypei.github.io/tags/%E9%93%BE%E8%A1%A8/"/>
    
  </entry>
  
</feed>
